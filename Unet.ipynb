{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (Resize, RandomCrop,VerticalFlip, HorizontalFlip, Normalize, Compose, CLAHE, Rotate)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = '0'\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(phase, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)): \n",
    "    list_transforms = [] \n",
    "    if phase == \"train\": \n",
    "        list_transforms.extend( \n",
    "            [ \n",
    "                HorizontalFlip(), \n",
    "                VerticalFlip(),\n",
    "                Rotate(),\n",
    "            ] ) \n",
    "    list_transforms.extend( [Resize(480, 480, interpolation=Image.BILINEAR),CLAHE(), Normalize(mean=mean, std=std, p=1), ToTensor(),] ) \n",
    "    list_trfms = Compose(list_transforms) \n",
    "    return list_trfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImg(im_fn):\n",
    "    im = cv2.imread(im_fn)\n",
    "    if im is None :\n",
    "        tmp = imageio.mimread(im_fn)\n",
    "        if tmp is not None:\n",
    "            im = np.array(tmp)\n",
    "            im = im.transpose(1,2,0)\n",
    "        else:\n",
    "            image = Image.open(im_fn)\n",
    "            im = np.asarray(image)\n",
    "    else:\n",
    "        im = cv2.cvtColor(np.asarray(im), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, name, img_root, gt_root, phase):\n",
    "        super().__init__()\n",
    "        self.inputs = []\n",
    "        self.gts = []\n",
    "        self.transform = get_transforms(phase)\n",
    "        \n",
    "        for root in img_root:\n",
    "            file_list = os.getcwd() + root\n",
    "            list_image = os.listdir(file_list)\n",
    "            list_image.sort()\n",
    "\n",
    "            for i, image_path in enumerate(list_image):\n",
    "                img = os.path.join(file_list,list_image[i])\n",
    "                self.inputs.append(img)\n",
    "                \n",
    "        for root in gt_root:\n",
    "            file_list = os.getcwd() + root\n",
    "            list_image = os.listdir(file_list)\n",
    "            list_image.sort()\n",
    "\n",
    "            for i, image_path in enumerate(list_image):\n",
    "                img = os.path.join(file_list,list_image[i])\n",
    "                self.gts.append(img)\n",
    "\n",
    "        print('Load %s: %d samples for %s'%(name, len(self.inputs),phase))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = readImg(self.inputs[index])\n",
    "        mask = readImg(self.gts[index])\n",
    "        if mask.shape[2] == 3:\n",
    "            mask = mask[:,:,0]\n",
    "            \n",
    "        augmented = self.transform(image=image, mask=mask.squeeze()) \n",
    "        return augmented[\"image\"], augmented[\"mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load DRIVE: 20 samples for train\n",
      "Load DRIVE: 20 samples for test\n",
      "Load STARE: 10 samples for train\n",
      "Load STARE: 10 samples for test\n",
      "Load CHASEDB1: 14 samples for train\n",
      "Load CHASEDB1: 14 samples for test\n",
      "Load HRF: 21 samples for train\n",
      "Load HRF: 24 samples for test\n",
      "Load all: 65 samples for train\n",
      "Load all: 68 samples for test\n"
     ]
    }
   ],
   "source": [
    "# DRIVE 数据集\n",
    "dr_train_loader = RetinalDataset('DRIVE',['\\\\data\\\\DRIVE\\\\train\\\\images'],\n",
    "                           ['\\\\data\\\\DRIVE\\\\train\\\\1st_manual'], 'train')\n",
    "dr_test_loader = RetinalDataset('DRIVE',['\\\\data\\\\DRIVE\\\\test\\\\images'],\n",
    "                           ['\\\\data\\\\DRIVE\\\\test\\\\1st_manual'], 'test')\n",
    "\n",
    "# STARE 数据集\n",
    "st_train_loader = RetinalDataset('STARE',['\\\\data\\\\STARE\\\\train\\\\image'],\n",
    "                           ['\\\\data\\\\STARE\\\\train\\\\labels-ah'], 'train')\n",
    "st_test_loader = RetinalDataset('STARE',['\\\\data\\\\STARE\\\\test\\\\image'],\n",
    "                           ['\\\\data\\\\STARE\\\\test\\\\labels-ah'], 'test')\n",
    "\n",
    "# CHASEDB1 数据集\n",
    "st_train_loader = RetinalDataset('CHASEDB1',['\\\\data\\\\CHASEDB1\\\\train\\\\image'],\n",
    "                           ['\\\\data\\\\CHASEDB1\\\\train\\\\1st'], 'train')\n",
    "st_test_loader = RetinalDataset('CHASEDB1',['\\\\data\\\\CHASEDB1\\\\test\\\\image'],\n",
    "                           ['\\\\data\\\\CHASEDB1\\\\test\\\\1st'], 'test')\n",
    "\n",
    "# HRF 数据集\n",
    "hr_train_loader = RetinalDataset('HRF',['\\\\data\\\\HRF\\\\train\\\\images'],\n",
    "                           ['\\\\data\\\\HRF\\\\train\\\\manual1'], 'train')\n",
    "hr_test_loader = RetinalDataset('HRF',['\\\\data\\\\HRF\\\\test\\\\images'],\n",
    "                           ['\\\\data\\\\HRF\\\\test\\\\manual1'], 'test')\n",
    "\n",
    "# 混合训练集\n",
    "all_train_loader = RetinalDataset('all',['\\\\data\\\\DRIVE\\\\train\\\\images','\\\\data\\\\STARE\\\\train\\\\image',\n",
    "                                        '\\\\data\\\\CHASEDB1\\\\train\\\\image','\\\\data\\\\HRF\\\\train\\\\images'],\n",
    "                                 ['\\\\data\\\\DRIVE\\\\train\\\\1st_manual','\\\\data\\\\STARE\\\\train\\\\labels-ah',\n",
    "                                 '\\\\data\\\\CHASEDB1\\\\train\\\\1st','\\\\data\\\\HRF\\\\train\\\\manual1'],'train')\n",
    "\n",
    "all_test_loader = RetinalDataset('all',['\\\\data\\\\DRIVE\\\\test\\\\images','\\\\data\\\\STARE\\\\test\\\\image',\n",
    "                                        '\\\\data\\\\CHASEDB1\\\\test\\\\image','\\\\data\\\\HRF\\\\test\\\\images'],\n",
    "                                 ['\\\\data\\\\DRIVE\\\\test\\\\1st_manual','\\\\data\\\\STARE\\\\test\\\\labels-ah',\n",
    "                                 '\\\\data\\\\CHASEDB1\\\\test\\\\1st','\\\\data\\\\HRF\\\\test\\\\manual1'],'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ckpt_path = \"./model.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "model = smp.Unet(\"resnet50\", encoder_weights=None, classes=1, activation=None)\n",
    "model.to(device)\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])\n",
    "'''\n",
    "net = smp.Unet('resnet18', classes=1, activation=None, encoder_weights='imagenet')\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss of binary class\n",
    "    Args:\n",
    "        smooth: A float number to smooth loss, and avoid NaN error, default: 1\n",
    "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n",
    "        predict: A tensor of shape [N, *]\n",
    "        target: A tensor of shape same with predict\n",
    "        reduction: Reduction method to apply, return mean over batch if 'mean',\n",
    "            return sum if 'sum', return a tensor of shape [N,] if 'none'\n",
    "    Returns:\n",
    "        Loss tensor according to arg reduction\n",
    "    Raise:\n",
    "        Exception if unexpected reduction\n",
    "    \"\"\"\n",
    "    def __init__(self, smooth=1, p=2, reduction='mean'):\n",
    "        super(BinaryDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        assert predict.shape[0] == target.shape[0], \"predict & target batch size don't match\"\n",
    "        predict = predict.contiguous().view(predict.shape[0], -1)\n",
    "        target = target.contiguous().view(target.shape[0], -1)\n",
    "\n",
    "        num = torch.sum(torch.mul(predict, target), dim=1) + self.smooth\n",
    "        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.smooth\n",
    "\n",
    "        loss = 1 - num / den\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return loss\n",
    "        else:\n",
    "            raise Exception('Unexpected reduction {}'.format(self.reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "batch_iter = math.ceil(len(all_train_loader) / batch_size)\n",
    "\n",
    "net_name = 'Unet-Resnet18'\n",
    "loss_fuc = 'BCEL'\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", patience=4, verbose=True)\n",
    "\n",
    "dataset = \"all\"\n",
    "trainloader = DataLoader(all_train_loader, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "testloader = DataLoader(all_test_loader, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'results'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "weights_path =  \"weights\"\n",
    "if not os.path.exists(weights_path):\n",
    "    os.makedirs(weights_path)\n",
    "\n",
    "f_loss = open(os.path.join(result_path, \"log_%s_%s_%s.txt\"%(dataset,loss_fuc,net_name)),'w')\n",
    "f_loss.write('Dataset : %s\\n'%dataset)\n",
    "f_loss.write('Loss : %s\\n'%loss_fuc)\n",
    "f_loss.write('Net : %s\\n'%net_name)\n",
    "f_loss.write('Learning rate: %05f\\n'%lr)\n",
    "f_loss.write('batch-size: %s\\n'%batch_size)\n",
    "f_loss.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(result_path,dataset)\n",
    "if not os.path.exists(image_path):\n",
    "    os.makedirs(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e):\n",
    "    print('start train epoch: %d'%e)\n",
    "    net.train()\n",
    "    \n",
    "    loss_plot = []\n",
    "    \n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda(async=True)\n",
    "        y = y.cuda(async=True)\n",
    "        \n",
    "        x = net(x)\n",
    "        \n",
    "        loss = criterion(x.squeeze(), y.squeeze())\n",
    "        #loss = loss + criterion[1](x.squeeze(), y.squeeze())\n",
    "        print('Epoch:%d  Batch:%d/%d  loss:%08f'%(e, i+1, batch_iter, loss.data))\n",
    "        \n",
    "        loss_plot.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    acc = torch.tensor(0)\n",
    "    tpr = torch.tensor(0)\n",
    "    fpr = torch.tensor(0)\n",
    "    sn = torch.tensor(0)\n",
    "    sp = torch.tensor(0)\n",
    "    \n",
    "    \n",
    "    for i, (x,y) in enumerate(testloader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda(async=True)\n",
    "        y = y.cuda(async=True)\n",
    "        x = net(x)\n",
    "        \n",
    "        x = torch.sigmoid(x).squeeze()\n",
    "        y = y.squeeze().int().long()\n",
    "        \n",
    "        x = torch.where(x > 0.5, torch.tensor(1).cuda(), torch.tensor(0).cuda())\n",
    "        \n",
    "        temp = x + torch.tensor(2).cuda().long() * y\n",
    "        tp = torch.sum(torch.where(temp == 3, torch.tensor(1).cuda(),torch.tensor(0).cuda())).float()\n",
    "        fp = torch.sum(torch.where(temp == 1, torch.tensor(1).cuda(),torch.tensor(0).cuda())).float()\n",
    "        tn = torch.sum(torch.where(temp == 0, torch.tensor(1).cuda(),torch.tensor(0).cuda())).float()\n",
    "        fn = torch.sum(torch.where(temp == 2, torch.tensor(1).cuda(),torch.tensor(0).cuda())).float()\n",
    "        \n",
    "        acc = acc + (tp + tn) / (tp + fp + tn + fn)\n",
    "        tpr = tpr + tp / (tp + fn)\n",
    "        fpr = fpr + fp / (tn + fp)\n",
    "        sn = sn + tn / (tn + fp)\n",
    "        sp = sp + tp / (tp + fn)\n",
    "        \n",
    "    acc = (acc / len(testloader)).cpu().numpy()\n",
    "    tpr = (tpr / len(testloader)).cpu().numpy()\n",
    "    fpr = (fpr / len(testloader)).cpu().numpy()\n",
    "    sn = (sn / len(testloader)).cpu().numpy()\n",
    "    sp = (sp / len(testloader)).cpu().numpy()\n",
    "    \n",
    "    print('ACC:',acc)\n",
    "    print('TPR:',tpr)\n",
    "    print('FPR:',fpr)\n",
    "    print('SN:',sn)\n",
    "    print('SP:',sp)\n",
    "    \n",
    "    f_log = open(os.path.join(result_path, \"log_%s_%s_%s.txt\"%(dataset,loss_fuc,net_name)),'a')\n",
    "    f_log.write('Epoch:%d  acc:%08f\\n'%(e, acc))\n",
    "    f_log.write('Epoch:%d  TPR:%08f\\n'%(e, tpr))\n",
    "    f_log.write('Epoch:%d  FPR:%08f\\n'%(e, fpr))\n",
    "    f_log.write('Epoch:%d  SN:%08f\\n'%(e, sn))\n",
    "    f_log.write('Epoch:%d  SP:%08f\\n'%(e, sp))\n",
    "    f_log.close()     \n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train epoch: 1\n",
      "Epoch:1  Batch:1/9  loss:0.592653\n",
      "Epoch:1  Batch:2/9  loss:0.522623\n",
      "Epoch:1  Batch:3/9  loss:0.471198\n",
      "Epoch:1  Batch:4/9  loss:0.435442\n",
      "Epoch:1  Batch:5/9  loss:0.409874\n",
      "Epoch:1  Batch:6/9  loss:0.378652\n",
      "Epoch:1  Batch:7/9  loss:0.354120\n",
      "Epoch:1  Batch:8/9  loss:0.337933\n",
      "Epoch:1  Batch:9/9  loss:0.327909\n",
      "start train epoch: 2\n",
      "Epoch:2  Batch:1/9  loss:0.302346\n",
      "Epoch:2  Batch:2/9  loss:0.295034\n",
      "Epoch:2  Batch:3/9  loss:0.284414\n",
      "Epoch:2  Batch:4/9  loss:0.264138\n",
      "Epoch:2  Batch:5/9  loss:0.253476\n",
      "Epoch:2  Batch:6/9  loss:0.246476\n",
      "Epoch:2  Batch:7/9  loss:0.231249\n",
      "Epoch:2  Batch:8/9  loss:0.233345\n",
      "Epoch:2  Batch:9/9  loss:0.215323\n",
      "start train epoch: 3\n",
      "Epoch:3  Batch:1/9  loss:0.215926\n",
      "Epoch:3  Batch:2/9  loss:0.208326\n",
      "Epoch:3  Batch:3/9  loss:0.204228\n",
      "Epoch:3  Batch:4/9  loss:0.194243\n",
      "Epoch:3  Batch:5/9  loss:0.186558\n",
      "Epoch:3  Batch:6/9  loss:0.194066\n",
      "Epoch:3  Batch:7/9  loss:0.184495\n",
      "Epoch:3  Batch:8/9  loss:0.186846\n",
      "Epoch:3  Batch:9/9  loss:0.164881\n",
      "start train epoch: 4\n",
      "Epoch:4  Batch:1/9  loss:0.175049\n",
      "Epoch:4  Batch:2/9  loss:0.162723\n",
      "Epoch:4  Batch:3/9  loss:0.176921\n",
      "Epoch:4  Batch:4/9  loss:0.165960\n",
      "Epoch:4  Batch:5/9  loss:0.166567\n",
      "Epoch:4  Batch:6/9  loss:0.168146\n",
      "Epoch:4  Batch:7/9  loss:0.162162\n",
      "Epoch:4  Batch:8/9  loss:0.155744\n",
      "Epoch:4  Batch:9/9  loss:0.148179\n",
      "start train epoch: 5\n",
      "Epoch:5  Batch:1/9  loss:0.148346\n",
      "Epoch:5  Batch:2/9  loss:0.153590\n",
      "Epoch:5  Batch:3/9  loss:0.155820\n",
      "Epoch:5  Batch:4/9  loss:0.156497\n",
      "Epoch:5  Batch:5/9  loss:0.138819\n",
      "Epoch:5  Batch:6/9  loss:0.148205\n",
      "Epoch:5  Batch:7/9  loss:0.147726\n",
      "Epoch:5  Batch:8/9  loss:0.143246\n",
      "Epoch:5  Batch:9/9  loss:0.140711\n",
      "start train epoch: 6\n",
      "Epoch:6  Batch:1/9  loss:0.146320\n",
      "Epoch:6  Batch:2/9  loss:0.145518\n",
      "Epoch:6  Batch:3/9  loss:0.135522\n",
      "Epoch:6  Batch:4/9  loss:0.132815\n",
      "Epoch:6  Batch:5/9  loss:0.139371\n",
      "Epoch:6  Batch:6/9  loss:0.132598\n",
      "Epoch:6  Batch:7/9  loss:0.130938\n",
      "Epoch:6  Batch:8/9  loss:0.135250\n",
      "Epoch:6  Batch:9/9  loss:0.144419\n",
      "start train epoch: 7\n",
      "Epoch:7  Batch:1/9  loss:0.123893\n",
      "Epoch:7  Batch:2/9  loss:0.129559\n",
      "Epoch:7  Batch:3/9  loss:0.135106\n",
      "Epoch:7  Batch:4/9  loss:0.128998\n",
      "Epoch:7  Batch:5/9  loss:0.124645\n",
      "Epoch:7  Batch:6/9  loss:0.134337\n",
      "Epoch:7  Batch:7/9  loss:0.128456\n",
      "Epoch:7  Batch:8/9  loss:0.125713\n",
      "Epoch:7  Batch:9/9  loss:0.114079\n",
      "start train epoch: 8\n",
      "Epoch:8  Batch:1/9  loss:0.122254\n",
      "Epoch:8  Batch:2/9  loss:0.130104\n",
      "Epoch:8  Batch:3/9  loss:0.126542\n",
      "Epoch:8  Batch:4/9  loss:0.118067\n",
      "Epoch:8  Batch:5/9  loss:0.119707\n",
      "Epoch:8  Batch:6/9  loss:0.117716\n",
      "Epoch:8  Batch:7/9  loss:0.121653\n",
      "Epoch:8  Batch:8/9  loss:0.125187\n",
      "Epoch:8  Batch:9/9  loss:0.105600\n",
      "start train epoch: 9\n",
      "Epoch:9  Batch:1/9  loss:0.137704\n",
      "Epoch:9  Batch:2/9  loss:0.127888\n",
      "Epoch:9  Batch:3/9  loss:0.114223\n",
      "Epoch:9  Batch:4/9  loss:0.120763\n",
      "Epoch:9  Batch:5/9  loss:0.119183\n",
      "Epoch:9  Batch:6/9  loss:0.115754\n",
      "Epoch:9  Batch:7/9  loss:0.111739\n",
      "Epoch:9  Batch:8/9  loss:0.127211\n",
      "Epoch:9  Batch:9/9  loss:0.118566\n",
      "start train epoch: 10\n",
      "Epoch:10  Batch:1/9  loss:0.126115\n",
      "Epoch:10  Batch:2/9  loss:0.120332\n",
      "Epoch:10  Batch:3/9  loss:0.116378\n",
      "Epoch:10  Batch:4/9  loss:0.117772\n",
      "Epoch:10  Batch:5/9  loss:0.118045\n",
      "Epoch:10  Batch:6/9  loss:0.119142\n",
      "Epoch:10  Batch:7/9  loss:0.112462\n",
      "Epoch:10  Batch:8/9  loss:0.121860\n",
      "Epoch:10  Batch:9/9  loss:0.109365\n",
      "ACC: 0.9602071\n",
      "TPR: 0.6478576\n",
      "FPR: 0.013405502\n",
      "SN: 0.9865947\n",
      "SP: 0.6478576\n",
      "start train epoch: 11\n",
      "Epoch:11  Batch:1/9  loss:0.127003\n",
      "Epoch:11  Batch:2/9  loss:0.112300\n",
      "Epoch:11  Batch:3/9  loss:0.105128\n",
      "Epoch:11  Batch:4/9  loss:0.115822\n",
      "Epoch:11  Batch:5/9  loss:0.124175\n",
      "Epoch:11  Batch:6/9  loss:0.111619\n",
      "Epoch:11  Batch:7/9  loss:0.107464\n",
      "Epoch:11  Batch:8/9  loss:0.118173\n",
      "Epoch:11  Batch:9/9  loss:0.176343\n",
      "start train epoch: 12\n",
      "Epoch:12  Batch:1/9  loss:0.115863\n",
      "Epoch:12  Batch:2/9  loss:0.112554\n",
      "Epoch:12  Batch:3/9  loss:0.103808\n",
      "Epoch:12  Batch:4/9  loss:0.101501\n",
      "Epoch:12  Batch:5/9  loss:0.109679\n",
      "Epoch:12  Batch:6/9  loss:0.108124\n",
      "Epoch:12  Batch:7/9  loss:0.113234\n",
      "Epoch:12  Batch:8/9  loss:0.113539\n",
      "Epoch:12  Batch:9/9  loss:0.088816\n",
      "start train epoch: 13\n",
      "Epoch:13  Batch:1/9  loss:0.110724\n",
      "Epoch:13  Batch:2/9  loss:0.110227\n",
      "Epoch:13  Batch:3/9  loss:0.102729\n",
      "Epoch:13  Batch:4/9  loss:0.113420\n",
      "Epoch:13  Batch:5/9  loss:0.107856\n",
      "Epoch:13  Batch:6/9  loss:0.100937\n",
      "Epoch:13  Batch:7/9  loss:0.099394\n",
      "Epoch:13  Batch:8/9  loss:0.118245\n",
      "Epoch:13  Batch:9/9  loss:0.116584\n",
      "start train epoch: 14\n",
      "Epoch:14  Batch:1/9  loss:0.104491\n",
      "Epoch:14  Batch:2/9  loss:0.097232\n",
      "Epoch:14  Batch:3/9  loss:0.105745\n",
      "Epoch:14  Batch:4/9  loss:0.132907\n",
      "Epoch:14  Batch:5/9  loss:0.100086\n",
      "Epoch:14  Batch:6/9  loss:0.104057\n",
      "Epoch:14  Batch:7/9  loss:0.101181\n",
      "Epoch:14  Batch:8/9  loss:0.117223\n",
      "Epoch:14  Batch:9/9  loss:0.112328\n",
      "start train epoch: 15\n",
      "Epoch:15  Batch:1/9  loss:0.112119\n",
      "Epoch:15  Batch:2/9  loss:0.105587\n",
      "Epoch:15  Batch:3/9  loss:0.107476\n",
      "Epoch:15  Batch:4/9  loss:0.098965\n",
      "Epoch:15  Batch:5/9  loss:0.099015\n",
      "Epoch:15  Batch:6/9  loss:0.116365\n",
      "Epoch:15  Batch:7/9  loss:0.105108\n",
      "Epoch:15  Batch:8/9  loss:0.104743\n",
      "Epoch:15  Batch:9/9  loss:0.148630\n",
      "start train epoch: 16\n",
      "Epoch:16  Batch:1/9  loss:0.111855\n",
      "Epoch:16  Batch:2/9  loss:0.113843\n",
      "Epoch:16  Batch:3/9  loss:0.105685\n",
      "Epoch:16  Batch:4/9  loss:0.107931\n",
      "Epoch:16  Batch:5/9  loss:0.105428\n",
      "Epoch:16  Batch:6/9  loss:0.097329\n",
      "Epoch:16  Batch:7/9  loss:0.103166\n",
      "Epoch:16  Batch:8/9  loss:0.099067\n",
      "Epoch:16  Batch:9/9  loss:0.089536\n",
      "start train epoch: 17\n",
      "Epoch:17  Batch:1/9  loss:0.102950\n",
      "Epoch:17  Batch:2/9  loss:0.104053\n",
      "Epoch:17  Batch:3/9  loss:0.088153\n",
      "Epoch:17  Batch:4/9  loss:0.098551\n",
      "Epoch:17  Batch:5/9  loss:0.106247\n",
      "Epoch:17  Batch:6/9  loss:0.102820\n",
      "Epoch:17  Batch:7/9  loss:0.104091\n",
      "Epoch:17  Batch:8/9  loss:0.112406\n",
      "Epoch:17  Batch:9/9  loss:0.101060\n",
      "start train epoch: 18\n",
      "Epoch:18  Batch:1/9  loss:0.102156\n",
      "Epoch:18  Batch:2/9  loss:0.100508\n",
      "Epoch:18  Batch:3/9  loss:0.116897\n",
      "Epoch:18  Batch:4/9  loss:0.098902\n",
      "Epoch:18  Batch:5/9  loss:0.108117\n",
      "Epoch:18  Batch:6/9  loss:0.096047\n",
      "Epoch:18  Batch:7/9  loss:0.094560\n",
      "Epoch:18  Batch:8/9  loss:0.090116\n",
      "Epoch:18  Batch:9/9  loss:0.074540\n",
      "start train epoch: 19\n",
      "Epoch:19  Batch:1/9  loss:0.090849\n",
      "Epoch:19  Batch:2/9  loss:0.102970\n",
      "Epoch:19  Batch:3/9  loss:0.102553\n",
      "Epoch:19  Batch:4/9  loss:0.089532\n",
      "Epoch:19  Batch:5/9  loss:0.100855\n",
      "Epoch:19  Batch:6/9  loss:0.109143\n",
      "Epoch:19  Batch:7/9  loss:0.100880\n",
      "Epoch:19  Batch:8/9  loss:0.096628\n",
      "Epoch:19  Batch:9/9  loss:0.082720\n",
      "start train epoch: 20\n",
      "Epoch:20  Batch:1/9  loss:0.091963\n",
      "Epoch:20  Batch:2/9  loss:0.109814\n",
      "Epoch:20  Batch:3/9  loss:0.093816\n",
      "Epoch:20  Batch:4/9  loss:0.101440\n",
      "Epoch:20  Batch:5/9  loss:0.114849\n",
      "Epoch:20  Batch:6/9  loss:0.098358\n",
      "Epoch:20  Batch:7/9  loss:0.098379\n",
      "Epoch:20  Batch:8/9  loss:0.091506\n",
      "Epoch:20  Batch:9/9  loss:0.070246\n",
      "ACC: 0.9646965\n",
      "TPR: 0.71750623\n",
      "FPR: 0.014361677\n",
      "SN: 0.9856383\n",
      "SP: 0.71750623\n",
      "start train epoch: 21\n",
      "Epoch:21  Batch:1/9  loss:0.100262\n",
      "Epoch:21  Batch:2/9  loss:0.101455\n",
      "Epoch:21  Batch:3/9  loss:0.087624\n",
      "Epoch:21  Batch:4/9  loss:0.100543\n",
      "Epoch:21  Batch:5/9  loss:0.092059\n",
      "Epoch:21  Batch:6/9  loss:0.103293\n",
      "Epoch:21  Batch:7/9  loss:0.110051\n",
      "Epoch:21  Batch:8/9  loss:0.087595\n",
      "Epoch:21  Batch:9/9  loss:0.082265\n",
      "start train epoch: 22\n",
      "Epoch:22  Batch:1/9  loss:0.096059\n",
      "Epoch:22  Batch:2/9  loss:0.099636\n",
      "Epoch:22  Batch:3/9  loss:0.095883\n",
      "Epoch:22  Batch:4/9  loss:0.088693\n",
      "Epoch:22  Batch:5/9  loss:0.096321\n",
      "Epoch:22  Batch:6/9  loss:0.098783\n",
      "Epoch:22  Batch:7/9  loss:0.102247\n",
      "Epoch:22  Batch:8/9  loss:0.099624\n",
      "Epoch:22  Batch:9/9  loss:0.064921\n",
      "start train epoch: 23\n",
      "Epoch:23  Batch:1/9  loss:0.095050\n",
      "Epoch:23  Batch:2/9  loss:0.107515\n",
      "Epoch:23  Batch:3/9  loss:0.087051\n",
      "Epoch:23  Batch:4/9  loss:0.083571\n",
      "Epoch:23  Batch:5/9  loss:0.105869\n",
      "Epoch:23  Batch:6/9  loss:0.091192\n",
      "Epoch:23  Batch:7/9  loss:0.092216\n",
      "Epoch:23  Batch:8/9  loss:0.110141\n",
      "Epoch:23  Batch:9/9  loss:0.088941\n",
      "start train epoch: 24\n",
      "Epoch:24  Batch:1/9  loss:0.109700\n",
      "Epoch:24  Batch:2/9  loss:0.087573\n",
      "Epoch:24  Batch:3/9  loss:0.089623\n",
      "Epoch:24  Batch:4/9  loss:0.091075\n",
      "Epoch:24  Batch:5/9  loss:0.086702\n",
      "Epoch:24  Batch:6/9  loss:0.110447\n",
      "Epoch:24  Batch:7/9  loss:0.100071\n",
      "Epoch:24  Batch:8/9  loss:0.087989\n",
      "Epoch:24  Batch:9/9  loss:0.104353\n",
      "start train epoch: 25\n",
      "Epoch:25  Batch:1/9  loss:0.114835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:25  Batch:2/9  loss:0.086914\n",
      "Epoch:25  Batch:3/9  loss:0.087247\n",
      "Epoch:25  Batch:4/9  loss:0.120450\n",
      "Epoch:25  Batch:5/9  loss:0.087060\n",
      "Epoch:25  Batch:6/9  loss:0.098557\n",
      "Epoch:25  Batch:7/9  loss:0.093593\n",
      "Epoch:25  Batch:8/9  loss:0.093108\n",
      "Epoch:25  Batch:9/9  loss:0.071359\n",
      "start train epoch: 26\n",
      "Epoch:26  Batch:1/9  loss:0.103343\n",
      "Epoch:26  Batch:2/9  loss:0.105890\n",
      "Epoch:26  Batch:3/9  loss:0.091444\n",
      "Epoch:26  Batch:4/9  loss:0.092861\n",
      "Epoch:26  Batch:5/9  loss:0.097377\n",
      "Epoch:26  Batch:6/9  loss:0.096719\n",
      "Epoch:26  Batch:7/9  loss:0.097736\n",
      "Epoch:26  Batch:8/9  loss:0.088680\n",
      "Epoch:26  Batch:9/9  loss:0.095924\n",
      "start train epoch: 27\n",
      "Epoch:27  Batch:1/9  loss:0.099298\n",
      "Epoch:27  Batch:2/9  loss:0.089428\n",
      "Epoch:27  Batch:3/9  loss:0.093813\n",
      "Epoch:27  Batch:4/9  loss:0.091254\n",
      "Epoch:27  Batch:5/9  loss:0.099557\n",
      "Epoch:27  Batch:6/9  loss:0.102138\n",
      "Epoch:27  Batch:7/9  loss:0.094004\n",
      "Epoch:27  Batch:8/9  loss:0.098656\n",
      "Epoch:27  Batch:9/9  loss:0.121087\n",
      "start train epoch: 28\n",
      "Epoch:28  Batch:1/9  loss:0.084989\n",
      "Epoch:28  Batch:2/9  loss:0.093317\n",
      "Epoch:28  Batch:3/9  loss:0.086543\n",
      "Epoch:28  Batch:4/9  loss:0.101654\n",
      "Epoch:28  Batch:5/9  loss:0.092934\n",
      "Epoch:28  Batch:6/9  loss:0.094523\n",
      "Epoch:28  Batch:7/9  loss:0.102621\n",
      "Epoch:28  Batch:8/9  loss:0.102291\n",
      "Epoch:28  Batch:9/9  loss:0.115777\n",
      "start train epoch: 29\n",
      "Epoch:29  Batch:1/9  loss:0.104436\n",
      "Epoch:29  Batch:2/9  loss:0.105897\n",
      "Epoch:29  Batch:3/9  loss:0.094276\n",
      "Epoch:29  Batch:4/9  loss:0.090674\n",
      "Epoch:29  Batch:5/9  loss:0.091856\n",
      "Epoch:29  Batch:6/9  loss:0.099663\n",
      "Epoch:29  Batch:7/9  loss:0.095815\n",
      "Epoch:29  Batch:8/9  loss:0.104003\n",
      "Epoch:29  Batch:9/9  loss:0.099043\n",
      "start train epoch: 30\n",
      "Epoch:30  Batch:1/9  loss:0.092329\n",
      "Epoch:30  Batch:2/9  loss:0.099126\n",
      "Epoch:30  Batch:3/9  loss:0.102728\n",
      "Epoch:30  Batch:4/9  loss:0.094486\n",
      "Epoch:30  Batch:5/9  loss:0.091517\n",
      "Epoch:30  Batch:6/9  loss:0.091341\n",
      "Epoch:30  Batch:7/9  loss:0.098205\n",
      "Epoch:30  Batch:8/9  loss:0.089909\n",
      "Epoch:30  Batch:9/9  loss:0.075591\n",
      "ACC: 0.96565944\n",
      "TPR: 0.743636\n",
      "FPR: 0.015388392\n",
      "SN: 0.9846114\n",
      "SP: 0.743636\n",
      "start train epoch: 31\n",
      "Epoch:31  Batch:1/9  loss:0.090480\n",
      "Epoch:31  Batch:2/9  loss:0.096016\n",
      "Epoch:31  Batch:3/9  loss:0.114902\n",
      "Epoch:31  Batch:4/9  loss:0.106545\n",
      "Epoch:31  Batch:5/9  loss:0.097124\n",
      "Epoch:31  Batch:6/9  loss:0.084334\n",
      "Epoch:31  Batch:7/9  loss:0.086205\n",
      "Epoch:31  Batch:8/9  loss:0.085702\n",
      "Epoch:31  Batch:9/9  loss:0.061756\n",
      "start train epoch: 32\n",
      "Epoch:32  Batch:1/9  loss:0.111115\n",
      "Epoch:32  Batch:2/9  loss:0.094521\n",
      "Epoch:32  Batch:3/9  loss:0.085850\n",
      "Epoch:32  Batch:4/9  loss:0.088138\n",
      "Epoch:32  Batch:5/9  loss:0.089540\n",
      "Epoch:32  Batch:6/9  loss:0.104977\n",
      "Epoch:32  Batch:7/9  loss:0.094951\n",
      "Epoch:32  Batch:8/9  loss:0.084530\n",
      "Epoch:32  Batch:9/9  loss:0.074027\n",
      "start train epoch: 33\n",
      "Epoch:33  Batch:1/9  loss:0.101019\n",
      "Epoch:33  Batch:2/9  loss:0.093969\n",
      "Epoch:33  Batch:3/9  loss:0.086828\n",
      "Epoch:33  Batch:4/9  loss:0.084550\n",
      "Epoch:33  Batch:5/9  loss:0.087195\n",
      "Epoch:33  Batch:6/9  loss:0.099316\n",
      "Epoch:33  Batch:7/9  loss:0.100158\n",
      "Epoch:33  Batch:8/9  loss:0.087053\n",
      "Epoch:33  Batch:9/9  loss:0.121243\n",
      "start train epoch: 34\n",
      "Epoch:34  Batch:1/9  loss:0.102977\n",
      "Epoch:34  Batch:2/9  loss:0.104526\n",
      "Epoch:34  Batch:3/9  loss:0.104910\n",
      "Epoch:34  Batch:4/9  loss:0.085035\n",
      "Epoch:34  Batch:5/9  loss:0.087679\n",
      "Epoch:34  Batch:6/9  loss:0.086706\n",
      "Epoch:34  Batch:7/9  loss:0.093553\n",
      "Epoch:34  Batch:8/9  loss:0.090905\n",
      "Epoch:34  Batch:9/9  loss:0.071519\n",
      "start train epoch: 35\n",
      "Epoch:35  Batch:1/9  loss:0.091333\n",
      "Epoch:35  Batch:2/9  loss:0.098778\n",
      "Epoch:35  Batch:3/9  loss:0.091477\n",
      "Epoch:35  Batch:4/9  loss:0.097337\n",
      "Epoch:35  Batch:5/9  loss:0.096992\n",
      "Epoch:35  Batch:6/9  loss:0.095377\n",
      "Epoch:35  Batch:7/9  loss:0.090660\n",
      "Epoch:35  Batch:8/9  loss:0.088433\n",
      "Epoch:35  Batch:9/9  loss:0.101218\n",
      "start train epoch: 36\n",
      "Epoch:36  Batch:1/9  loss:0.080170\n",
      "Epoch:36  Batch:2/9  loss:0.092182\n",
      "Epoch:36  Batch:3/9  loss:0.100470\n",
      "Epoch:36  Batch:4/9  loss:0.079099\n",
      "Epoch:36  Batch:5/9  loss:0.096519\n",
      "Epoch:36  Batch:6/9  loss:0.100673\n",
      "Epoch:36  Batch:7/9  loss:0.106742\n",
      "Epoch:36  Batch:8/9  loss:0.091755\n",
      "Epoch:36  Batch:9/9  loss:0.068922\n",
      "start train epoch: 37\n",
      "Epoch:37  Batch:1/9  loss:0.100976\n",
      "Epoch:37  Batch:2/9  loss:0.084172\n",
      "Epoch:37  Batch:3/9  loss:0.086327\n",
      "Epoch:37  Batch:4/9  loss:0.095354\n",
      "Epoch:37  Batch:5/9  loss:0.094000\n",
      "Epoch:37  Batch:6/9  loss:0.094947\n",
      "Epoch:37  Batch:7/9  loss:0.085239\n",
      "Epoch:37  Batch:8/9  loss:0.097353\n",
      "Epoch:37  Batch:9/9  loss:0.070825\n",
      "start train epoch: 38\n",
      "Epoch:38  Batch:1/9  loss:0.085639\n",
      "Epoch:38  Batch:2/9  loss:0.108762\n",
      "Epoch:38  Batch:3/9  loss:0.083229\n",
      "Epoch:38  Batch:4/9  loss:0.081757\n",
      "Epoch:38  Batch:5/9  loss:0.091488\n",
      "Epoch:38  Batch:6/9  loss:0.095077\n",
      "Epoch:38  Batch:7/9  loss:0.092803\n",
      "Epoch:38  Batch:8/9  loss:0.087262\n",
      "Epoch:38  Batch:9/9  loss:0.081041\n",
      "start train epoch: 39\n",
      "Epoch:39  Batch:1/9  loss:0.082691\n",
      "Epoch:39  Batch:2/9  loss:0.092379\n",
      "Epoch:39  Batch:3/9  loss:0.110813\n",
      "Epoch:39  Batch:4/9  loss:0.090625\n",
      "Epoch:39  Batch:5/9  loss:0.089095\n",
      "Epoch:39  Batch:6/9  loss:0.091993\n",
      "Epoch:39  Batch:7/9  loss:0.098621\n",
      "Epoch:39  Batch:8/9  loss:0.083356\n",
      "Epoch:39  Batch:9/9  loss:0.072225\n",
      "start train epoch: 40\n",
      "Epoch:40  Batch:1/9  loss:0.079156\n",
      "Epoch:40  Batch:2/9  loss:0.082632\n",
      "Epoch:40  Batch:3/9  loss:0.089109\n",
      "Epoch:40  Batch:4/9  loss:0.086753\n",
      "Epoch:40  Batch:5/9  loss:0.102857\n",
      "Epoch:40  Batch:6/9  loss:0.098241\n",
      "Epoch:40  Batch:7/9  loss:0.105038\n",
      "Epoch:40  Batch:8/9  loss:0.091314\n",
      "Epoch:40  Batch:9/9  loss:0.076595\n",
      "ACC: 0.9661682\n",
      "TPR: 0.7421745\n",
      "FPR: 0.014717078\n",
      "SN: 0.985283\n",
      "SP: 0.7421745\n",
      "start train epoch: 41\n",
      "Epoch:41  Batch:1/9  loss:0.104812\n",
      "Epoch:41  Batch:2/9  loss:0.090998\n",
      "Epoch:41  Batch:3/9  loss:0.076585\n",
      "Epoch:41  Batch:4/9  loss:0.087320\n",
      "Epoch:41  Batch:5/9  loss:0.086123\n",
      "Epoch:41  Batch:6/9  loss:0.102813\n",
      "Epoch:41  Batch:7/9  loss:0.105124\n",
      "Epoch:41  Batch:8/9  loss:0.082873\n",
      "Epoch:41  Batch:9/9  loss:0.089558\n",
      "start train epoch: 42\n",
      "Epoch:42  Batch:1/9  loss:0.091148\n",
      "Epoch:42  Batch:2/9  loss:0.095587\n",
      "Epoch:42  Batch:3/9  loss:0.087862\n",
      "Epoch:42  Batch:4/9  loss:0.086718\n",
      "Epoch:42  Batch:5/9  loss:0.096906\n",
      "Epoch:42  Batch:6/9  loss:0.080171\n",
      "Epoch:42  Batch:7/9  loss:0.092056\n",
      "Epoch:42  Batch:8/9  loss:0.098803\n",
      "Epoch:42  Batch:9/9  loss:0.060985\n",
      "start train epoch: 43\n",
      "Epoch:43  Batch:1/9  loss:0.080692\n",
      "Epoch:43  Batch:2/9  loss:0.089159\n",
      "Epoch:43  Batch:3/9  loss:0.108932\n",
      "Epoch:43  Batch:4/9  loss:0.084069\n",
      "Epoch:43  Batch:5/9  loss:0.086776\n",
      "Epoch:43  Batch:6/9  loss:0.082479\n",
      "Epoch:43  Batch:7/9  loss:0.103234\n",
      "Epoch:43  Batch:8/9  loss:0.088158\n",
      "Epoch:43  Batch:9/9  loss:0.095556\n",
      "start train epoch: 44\n",
      "Epoch:44  Batch:1/9  loss:0.074111\n",
      "Epoch:44  Batch:2/9  loss:0.093290\n",
      "Epoch:44  Batch:3/9  loss:0.088836\n",
      "Epoch:44  Batch:4/9  loss:0.100566\n",
      "Epoch:44  Batch:5/9  loss:0.085048\n",
      "Epoch:44  Batch:6/9  loss:0.083284\n",
      "Epoch:44  Batch:7/9  loss:0.100632\n",
      "Epoch:44  Batch:8/9  loss:0.091225\n",
      "Epoch:44  Batch:9/9  loss:0.157044\n",
      "start train epoch: 45\n",
      "Epoch:45  Batch:1/9  loss:0.090269\n",
      "Epoch:45  Batch:2/9  loss:0.090904\n",
      "Epoch:45  Batch:3/9  loss:0.088614\n",
      "Epoch:45  Batch:4/9  loss:0.084426\n",
      "Epoch:45  Batch:5/9  loss:0.099209\n",
      "Epoch:45  Batch:6/9  loss:0.092531\n",
      "Epoch:45  Batch:7/9  loss:0.079873\n",
      "Epoch:45  Batch:8/9  loss:0.082677\n",
      "Epoch:45  Batch:9/9  loss:0.104556\n",
      "start train epoch: 46\n",
      "Epoch:46  Batch:1/9  loss:0.094653\n",
      "Epoch:46  Batch:2/9  loss:0.085197\n",
      "Epoch:46  Batch:3/9  loss:0.103530\n",
      "Epoch:46  Batch:4/9  loss:0.091699\n",
      "Epoch:46  Batch:5/9  loss:0.086810\n",
      "Epoch:46  Batch:6/9  loss:0.086206\n",
      "Epoch:46  Batch:7/9  loss:0.088249\n",
      "Epoch:46  Batch:8/9  loss:0.087444\n",
      "Epoch:46  Batch:9/9  loss:0.076662\n",
      "start train epoch: 47\n",
      "Epoch:47  Batch:1/9  loss:0.090331\n",
      "Epoch:47  Batch:2/9  loss:0.084995\n",
      "Epoch:47  Batch:3/9  loss:0.095815\n",
      "Epoch:47  Batch:4/9  loss:0.103900\n",
      "Epoch:47  Batch:5/9  loss:0.082115\n",
      "Epoch:47  Batch:6/9  loss:0.091238\n",
      "Epoch:47  Batch:7/9  loss:0.078225\n",
      "Epoch:47  Batch:8/9  loss:0.099964\n",
      "Epoch:47  Batch:9/9  loss:0.089105\n",
      "start train epoch: 48\n",
      "Epoch:48  Batch:1/9  loss:0.096067\n",
      "Epoch:48  Batch:2/9  loss:0.083225\n",
      "Epoch:48  Batch:3/9  loss:0.094158\n",
      "Epoch:48  Batch:4/9  loss:0.087349\n",
      "Epoch:48  Batch:5/9  loss:0.089457\n",
      "Epoch:48  Batch:6/9  loss:0.089548\n",
      "Epoch:48  Batch:7/9  loss:0.092308\n",
      "Epoch:48  Batch:8/9  loss:0.097612\n",
      "Epoch:48  Batch:9/9  loss:0.086388\n",
      "start train epoch: 49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:49  Batch:1/9  loss:0.089961\n",
      "Epoch:49  Batch:2/9  loss:0.099994\n",
      "Epoch:49  Batch:3/9  loss:0.090323\n",
      "Epoch:49  Batch:4/9  loss:0.086669\n",
      "Epoch:49  Batch:5/9  loss:0.082062\n",
      "Epoch:49  Batch:6/9  loss:0.092239\n",
      "Epoch:49  Batch:7/9  loss:0.087712\n",
      "Epoch:49  Batch:8/9  loss:0.093247\n",
      "Epoch:49  Batch:9/9  loss:0.062436\n",
      "start train epoch: 50\n",
      "Epoch:50  Batch:1/9  loss:0.083157\n",
      "Epoch:50  Batch:2/9  loss:0.091892\n",
      "Epoch:50  Batch:3/9  loss:0.079403\n",
      "Epoch:50  Batch:4/9  loss:0.091498\n",
      "Epoch:50  Batch:5/9  loss:0.095676\n",
      "Epoch:50  Batch:6/9  loss:0.090242\n",
      "Epoch:50  Batch:7/9  loss:0.080403\n",
      "Epoch:50  Batch:8/9  loss:0.083455\n",
      "Epoch:50  Batch:9/9  loss:0.081352\n",
      "ACC: 0.96699244\n",
      "TPR: 0.7662155\n",
      "FPR: 0.01598511\n",
      "SN: 0.984015\n",
      "SP: 0.7662155\n",
      "start train epoch: 51\n",
      "Epoch:51  Batch:1/9  loss:0.095823\n",
      "Epoch:51  Batch:2/9  loss:0.082443\n",
      "Epoch:51  Batch:3/9  loss:0.084181\n",
      "Epoch:51  Batch:4/9  loss:0.091143\n",
      "Epoch:51  Batch:5/9  loss:0.096815\n",
      "Epoch:51  Batch:6/9  loss:0.091423\n",
      "Epoch:51  Batch:7/9  loss:0.085695\n",
      "Epoch:51  Batch:8/9  loss:0.087505\n",
      "Epoch:51  Batch:9/9  loss:0.089948\n",
      "start train epoch: 52\n",
      "Epoch:52  Batch:1/9  loss:0.092242\n",
      "Epoch:52  Batch:2/9  loss:0.096141\n",
      "Epoch:52  Batch:3/9  loss:0.095432\n",
      "Epoch:52  Batch:4/9  loss:0.081675\n",
      "Epoch:52  Batch:5/9  loss:0.103042\n",
      "Epoch:52  Batch:6/9  loss:0.083138\n",
      "Epoch:52  Batch:7/9  loss:0.091693\n",
      "Epoch:52  Batch:8/9  loss:0.080941\n",
      "Epoch:52  Batch:9/9  loss:0.096607\n",
      "start train epoch: 53\n",
      "Epoch:53  Batch:1/9  loss:0.081674\n",
      "Epoch:53  Batch:2/9  loss:0.084544\n",
      "Epoch:53  Batch:3/9  loss:0.104933\n",
      "Epoch:53  Batch:4/9  loss:0.092311\n",
      "Epoch:53  Batch:5/9  loss:0.092473\n",
      "Epoch:53  Batch:6/9  loss:0.087913\n",
      "Epoch:53  Batch:7/9  loss:0.097863\n",
      "Epoch:53  Batch:8/9  loss:0.085266\n",
      "Epoch:53  Batch:9/9  loss:0.066482\n",
      "start train epoch: 54\n",
      "Epoch:54  Batch:1/9  loss:0.098762\n",
      "Epoch:54  Batch:2/9  loss:0.080770\n",
      "Epoch:54  Batch:3/9  loss:0.083840\n",
      "Epoch:54  Batch:4/9  loss:0.101656\n",
      "Epoch:54  Batch:5/9  loss:0.083715\n",
      "Epoch:54  Batch:6/9  loss:0.087038\n",
      "Epoch:54  Batch:7/9  loss:0.096657\n",
      "Epoch:54  Batch:8/9  loss:0.080448\n",
      "Epoch:54  Batch:9/9  loss:0.060614\n",
      "start train epoch: 55\n",
      "Epoch:55  Batch:1/9  loss:0.074524\n",
      "Epoch:55  Batch:2/9  loss:0.090571\n",
      "Epoch:55  Batch:3/9  loss:0.102942\n",
      "Epoch:55  Batch:4/9  loss:0.081835\n",
      "Epoch:55  Batch:5/9  loss:0.092184\n",
      "Epoch:55  Batch:6/9  loss:0.084339\n",
      "Epoch:55  Batch:7/9  loss:0.096089\n",
      "Epoch:55  Batch:8/9  loss:0.088912\n",
      "Epoch:55  Batch:9/9  loss:0.172416\n",
      "start train epoch: 56\n",
      "Epoch:56  Batch:1/9  loss:0.083378\n",
      "Epoch:56  Batch:2/9  loss:0.089999\n",
      "Epoch:56  Batch:3/9  loss:0.089956\n",
      "Epoch:56  Batch:4/9  loss:0.100443\n",
      "Epoch:56  Batch:5/9  loss:0.089605\n",
      "Epoch:56  Batch:6/9  loss:0.085190\n",
      "Epoch:56  Batch:7/9  loss:0.094131\n",
      "Epoch:56  Batch:8/9  loss:0.096553\n",
      "Epoch:56  Batch:9/9  loss:0.103293\n",
      "start train epoch: 57\n",
      "Epoch:57  Batch:1/9  loss:0.078119\n",
      "Epoch:57  Batch:2/9  loss:0.080218\n",
      "Epoch:57  Batch:3/9  loss:0.081045\n",
      "Epoch:57  Batch:4/9  loss:0.090679\n",
      "Epoch:57  Batch:5/9  loss:0.092993\n",
      "Epoch:57  Batch:6/9  loss:0.090989\n",
      "Epoch:57  Batch:7/9  loss:0.081546\n",
      "Epoch:57  Batch:8/9  loss:0.095482\n",
      "Epoch:57  Batch:9/9  loss:0.091432\n",
      "start train epoch: 58\n",
      "Epoch:58  Batch:1/9  loss:0.079763\n",
      "Epoch:58  Batch:2/9  loss:0.098755\n",
      "Epoch:58  Batch:3/9  loss:0.080280\n",
      "Epoch:58  Batch:4/9  loss:0.077767\n",
      "Epoch:58  Batch:5/9  loss:0.078654\n",
      "Epoch:58  Batch:6/9  loss:0.091242\n",
      "Epoch:58  Batch:7/9  loss:0.087038\n",
      "Epoch:58  Batch:8/9  loss:0.097890\n",
      "Epoch:58  Batch:9/9  loss:0.095546\n",
      "start train epoch: 59\n",
      "Epoch:59  Batch:1/9  loss:0.080233\n",
      "Epoch:59  Batch:2/9  loss:0.087757\n",
      "Epoch:59  Batch:3/9  loss:0.091402\n",
      "Epoch:59  Batch:4/9  loss:0.075931\n",
      "Epoch:59  Batch:5/9  loss:0.099030\n",
      "Epoch:59  Batch:6/9  loss:0.082920\n",
      "Epoch:59  Batch:7/9  loss:0.096022\n",
      "Epoch:59  Batch:8/9  loss:0.078231\n",
      "Epoch:59  Batch:9/9  loss:0.084179\n",
      "start train epoch: 60\n",
      "Epoch:60  Batch:1/9  loss:0.093411\n",
      "Epoch:60  Batch:2/9  loss:0.079440\n",
      "Epoch:60  Batch:3/9  loss:0.095889\n",
      "Epoch:60  Batch:4/9  loss:0.095541\n",
      "Epoch:60  Batch:5/9  loss:0.091191\n",
      "Epoch:60  Batch:6/9  loss:0.080959\n",
      "Epoch:60  Batch:7/9  loss:0.096990\n",
      "Epoch:60  Batch:8/9  loss:0.086635\n",
      "Epoch:60  Batch:9/9  loss:0.074242\n",
      "ACC: 0.967858\n",
      "TPR: 0.73866415\n",
      "FPR: 0.012748098\n",
      "SN: 0.98725164\n",
      "SP: 0.73866415\n",
      "start train epoch: 61\n",
      "Epoch:61  Batch:1/9  loss:0.097044\n",
      "Epoch:61  Batch:2/9  loss:0.084681\n",
      "Epoch:61  Batch:3/9  loss:0.092158\n",
      "Epoch:61  Batch:4/9  loss:0.082071\n",
      "Epoch:61  Batch:5/9  loss:0.082382\n",
      "Epoch:61  Batch:6/9  loss:0.087906\n",
      "Epoch:61  Batch:7/9  loss:0.075390\n",
      "Epoch:61  Batch:8/9  loss:0.090914\n",
      "Epoch:61  Batch:9/9  loss:0.092308\n",
      "start train epoch: 62\n",
      "Epoch:62  Batch:1/9  loss:0.083874\n",
      "Epoch:62  Batch:2/9  loss:0.080268\n",
      "Epoch:62  Batch:3/9  loss:0.086732\n",
      "Epoch:62  Batch:4/9  loss:0.088213\n",
      "Epoch:62  Batch:5/9  loss:0.100250\n",
      "Epoch:62  Batch:6/9  loss:0.080157\n",
      "Epoch:62  Batch:7/9  loss:0.086456\n",
      "Epoch:62  Batch:8/9  loss:0.094925\n",
      "Epoch:62  Batch:9/9  loss:0.065318\n",
      "start train epoch: 63\n",
      "Epoch:63  Batch:1/9  loss:0.085913\n",
      "Epoch:63  Batch:2/9  loss:0.088223\n",
      "Epoch:63  Batch:3/9  loss:0.084254\n",
      "Epoch:63  Batch:4/9  loss:0.092935\n",
      "Epoch:63  Batch:5/9  loss:0.083525\n",
      "Epoch:63  Batch:6/9  loss:0.085972\n",
      "Epoch:63  Batch:7/9  loss:0.071507\n",
      "Epoch:63  Batch:8/9  loss:0.089753\n",
      "Epoch:63  Batch:9/9  loss:0.097476\n",
      "start train epoch: 64\n",
      "Epoch:64  Batch:1/9  loss:0.074613\n",
      "Epoch:64  Batch:2/9  loss:0.100305\n",
      "Epoch:64  Batch:3/9  loss:0.082373\n",
      "Epoch:64  Batch:4/9  loss:0.085411\n",
      "Epoch:64  Batch:5/9  loss:0.095322\n",
      "Epoch:64  Batch:6/9  loss:0.079102\n",
      "Epoch:64  Batch:7/9  loss:0.090896\n",
      "Epoch:64  Batch:8/9  loss:0.083152\n",
      "Epoch:64  Batch:9/9  loss:0.085392\n",
      "start train epoch: 65\n",
      "Epoch:65  Batch:1/9  loss:0.074120\n",
      "Epoch:65  Batch:2/9  loss:0.091941\n",
      "Epoch:65  Batch:3/9  loss:0.080631\n",
      "Epoch:65  Batch:4/9  loss:0.085012\n",
      "Epoch:65  Batch:5/9  loss:0.093317\n",
      "Epoch:65  Batch:6/9  loss:0.089846\n",
      "Epoch:65  Batch:7/9  loss:0.087601\n",
      "Epoch:65  Batch:8/9  loss:0.081828\n",
      "Epoch:65  Batch:9/9  loss:0.111152\n",
      "start train epoch: 66\n",
      "Epoch:66  Batch:1/9  loss:0.090986\n",
      "Epoch:66  Batch:2/9  loss:0.087911\n",
      "Epoch:66  Batch:3/9  loss:0.084111\n",
      "Epoch:66  Batch:4/9  loss:0.087177\n",
      "Epoch:66  Batch:5/9  loss:0.091026\n",
      "Epoch:66  Batch:6/9  loss:0.083243\n",
      "Epoch:66  Batch:7/9  loss:0.085414\n",
      "Epoch:66  Batch:8/9  loss:0.084735\n",
      "Epoch:66  Batch:9/9  loss:0.085527\n",
      "start train epoch: 67\n",
      "Epoch:67  Batch:1/9  loss:0.082425\n",
      "Epoch:67  Batch:2/9  loss:0.084664\n",
      "Epoch:67  Batch:3/9  loss:0.089370\n",
      "Epoch:67  Batch:4/9  loss:0.081878\n",
      "Epoch:67  Batch:5/9  loss:0.097583\n",
      "Epoch:67  Batch:6/9  loss:0.099417\n",
      "Epoch:67  Batch:7/9  loss:0.076683\n",
      "Epoch:67  Batch:8/9  loss:0.084709\n",
      "Epoch:67  Batch:9/9  loss:0.094878\n",
      "start train epoch: 68\n",
      "Epoch:68  Batch:1/9  loss:0.087495\n",
      "Epoch:68  Batch:2/9  loss:0.080704\n",
      "Epoch:68  Batch:3/9  loss:0.077780\n",
      "Epoch:68  Batch:4/9  loss:0.082363\n",
      "Epoch:68  Batch:5/9  loss:0.096146\n",
      "Epoch:68  Batch:6/9  loss:0.078450\n",
      "Epoch:68  Batch:7/9  loss:0.101677\n",
      "Epoch:68  Batch:8/9  loss:0.096754\n",
      "Epoch:68  Batch:9/9  loss:0.064456\n",
      "start train epoch: 69\n",
      "Epoch:69  Batch:1/9  loss:0.096468\n",
      "Epoch:69  Batch:2/9  loss:0.085184\n",
      "Epoch:69  Batch:3/9  loss:0.088695\n",
      "Epoch:69  Batch:4/9  loss:0.078710\n",
      "Epoch:69  Batch:5/9  loss:0.074122\n",
      "Epoch:69  Batch:6/9  loss:0.082522\n",
      "Epoch:69  Batch:7/9  loss:0.099202\n",
      "Epoch:69  Batch:8/9  loss:0.090225\n",
      "Epoch:69  Batch:9/9  loss:0.082218\n",
      "start train epoch: 70\n",
      "Epoch:70  Batch:1/9  loss:0.098797\n",
      "Epoch:70  Batch:2/9  loss:0.083362\n",
      "Epoch:70  Batch:3/9  loss:0.086232\n",
      "Epoch:70  Batch:4/9  loss:0.091055\n",
      "Epoch:70  Batch:5/9  loss:0.082452\n",
      "Epoch:70  Batch:6/9  loss:0.088288\n",
      "Epoch:70  Batch:7/9  loss:0.090765\n",
      "Epoch:70  Batch:8/9  loss:0.082946\n",
      "Epoch:70  Batch:9/9  loss:0.097479\n",
      "ACC: 0.9679628\n",
      "TPR: 0.7480232\n",
      "FPR: 0.013439586\n",
      "SN: 0.98656034\n",
      "SP: 0.7480232\n",
      "start train epoch: 71\n",
      "Epoch:71  Batch:1/9  loss:0.072659\n",
      "Epoch:71  Batch:2/9  loss:0.086740\n",
      "Epoch:71  Batch:3/9  loss:0.090436\n",
      "Epoch:71  Batch:4/9  loss:0.088390\n",
      "Epoch:71  Batch:5/9  loss:0.078218\n",
      "Epoch:71  Batch:6/9  loss:0.095168\n",
      "Epoch:71  Batch:7/9  loss:0.084946\n",
      "Epoch:71  Batch:8/9  loss:0.096465\n",
      "Epoch:71  Batch:9/9  loss:0.078874\n",
      "start train epoch: 72\n",
      "Epoch:72  Batch:1/9  loss:0.088886\n",
      "Epoch:72  Batch:2/9  loss:0.087868\n",
      "Epoch:72  Batch:3/9  loss:0.083798\n",
      "Epoch:72  Batch:4/9  loss:0.090186\n",
      "Epoch:72  Batch:5/9  loss:0.097253\n",
      "Epoch:72  Batch:6/9  loss:0.085089\n",
      "Epoch:72  Batch:7/9  loss:0.075636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:72  Batch:8/9  loss:0.087118\n",
      "Epoch:72  Batch:9/9  loss:0.078549\n",
      "start train epoch: 73\n",
      "Epoch:73  Batch:1/9  loss:0.087987\n",
      "Epoch:73  Batch:2/9  loss:0.084855\n",
      "Epoch:73  Batch:3/9  loss:0.079888\n",
      "Epoch:73  Batch:4/9  loss:0.084000\n",
      "Epoch:73  Batch:5/9  loss:0.078128\n",
      "Epoch:73  Batch:6/9  loss:0.097245\n",
      "Epoch:73  Batch:7/9  loss:0.089938\n",
      "Epoch:73  Batch:8/9  loss:0.091067\n",
      "Epoch:73  Batch:9/9  loss:0.131264\n",
      "start train epoch: 74\n",
      "Epoch:74  Batch:1/9  loss:0.093690\n",
      "Epoch:74  Batch:2/9  loss:0.085918\n",
      "Epoch:74  Batch:3/9  loss:0.091332\n",
      "Epoch:74  Batch:4/9  loss:0.093906\n",
      "Epoch:74  Batch:5/9  loss:0.088054\n",
      "Epoch:74  Batch:6/9  loss:0.076534\n",
      "Epoch:74  Batch:7/9  loss:0.091622\n",
      "Epoch:74  Batch:8/9  loss:0.082754\n",
      "Epoch:74  Batch:9/9  loss:0.105520\n",
      "start train epoch: 75\n",
      "Epoch:75  Batch:1/9  loss:0.092013\n",
      "Epoch:75  Batch:2/9  loss:0.084973\n",
      "Epoch:75  Batch:3/9  loss:0.086413\n",
      "Epoch:75  Batch:4/9  loss:0.087802\n",
      "Epoch:75  Batch:5/9  loss:0.091370\n",
      "Epoch:75  Batch:6/9  loss:0.080336\n",
      "Epoch:75  Batch:7/9  loss:0.089567\n",
      "Epoch:75  Batch:8/9  loss:0.078250\n",
      "Epoch:75  Batch:9/9  loss:0.098405\n",
      "start train epoch: 76\n",
      "Epoch:76  Batch:1/9  loss:0.085018\n",
      "Epoch:76  Batch:2/9  loss:0.084725\n",
      "Epoch:76  Batch:3/9  loss:0.092930\n",
      "Epoch:76  Batch:4/9  loss:0.091624\n",
      "Epoch:76  Batch:5/9  loss:0.086333\n",
      "Epoch:76  Batch:6/9  loss:0.082361\n",
      "Epoch:76  Batch:7/9  loss:0.087338\n",
      "Epoch:76  Batch:8/9  loss:0.077405\n",
      "Epoch:76  Batch:9/9  loss:0.073877\n",
      "start train epoch: 77\n",
      "Epoch:77  Batch:1/9  loss:0.096532\n",
      "Epoch:77  Batch:2/9  loss:0.090804\n",
      "Epoch:77  Batch:3/9  loss:0.072581\n",
      "Epoch:77  Batch:4/9  loss:0.086315\n",
      "Epoch:77  Batch:5/9  loss:0.078470\n",
      "Epoch:77  Batch:6/9  loss:0.082319\n",
      "Epoch:77  Batch:7/9  loss:0.080314\n",
      "Epoch:77  Batch:8/9  loss:0.098440\n",
      "Epoch:77  Batch:9/9  loss:0.086090\n",
      "start train epoch: 78\n",
      "Epoch:78  Batch:1/9  loss:0.079681\n",
      "Epoch:78  Batch:2/9  loss:0.085967\n",
      "Epoch:78  Batch:3/9  loss:0.094693\n",
      "Epoch:78  Batch:4/9  loss:0.089213\n",
      "Epoch:78  Batch:5/9  loss:0.083207\n",
      "Epoch:78  Batch:6/9  loss:0.083582\n",
      "Epoch:78  Batch:7/9  loss:0.087037\n",
      "Epoch:78  Batch:8/9  loss:0.084463\n",
      "Epoch:78  Batch:9/9  loss:0.068423\n",
      "start train epoch: 79\n",
      "Epoch:79  Batch:1/9  loss:0.082526\n",
      "Epoch:79  Batch:2/9  loss:0.090958\n",
      "Epoch:79  Batch:3/9  loss:0.080023\n",
      "Epoch:79  Batch:4/9  loss:0.089506\n",
      "Epoch:79  Batch:5/9  loss:0.089080\n",
      "Epoch:79  Batch:6/9  loss:0.082089\n",
      "Epoch:79  Batch:7/9  loss:0.081132\n",
      "Epoch:79  Batch:8/9  loss:0.088496\n",
      "Epoch:79  Batch:9/9  loss:0.078440\n",
      "start train epoch: 80\n",
      "Epoch:80  Batch:1/9  loss:0.092108\n",
      "Epoch:80  Batch:2/9  loss:0.081656\n",
      "Epoch:80  Batch:3/9  loss:0.076487\n",
      "Epoch:80  Batch:4/9  loss:0.085361\n",
      "Epoch:80  Batch:5/9  loss:0.091844\n",
      "Epoch:80  Batch:6/9  loss:0.090445\n",
      "Epoch:80  Batch:7/9  loss:0.076444\n",
      "Epoch:80  Batch:8/9  loss:0.079250\n",
      "Epoch:80  Batch:9/9  loss:0.175839\n",
      "ACC: 0.9673765\n",
      "TPR: 0.7107931\n",
      "FPR: 0.011035582\n",
      "SN: 0.98896456\n",
      "SP: 0.7107931\n",
      "start train epoch: 81\n",
      "Epoch:81  Batch:1/9  loss:0.079348\n",
      "Epoch:81  Batch:2/9  loss:0.088342\n",
      "Epoch:81  Batch:3/9  loss:0.082003\n",
      "Epoch:81  Batch:4/9  loss:0.082949\n",
      "Epoch:81  Batch:5/9  loss:0.083653\n",
      "Epoch:81  Batch:6/9  loss:0.102458\n",
      "Epoch:81  Batch:7/9  loss:0.088909\n",
      "Epoch:81  Batch:8/9  loss:0.086299\n",
      "Epoch:81  Batch:9/9  loss:0.060089\n",
      "start train epoch: 82\n",
      "Epoch:82  Batch:1/9  loss:0.094305\n",
      "Epoch:82  Batch:2/9  loss:0.090967\n",
      "Epoch:82  Batch:3/9  loss:0.081313\n",
      "Epoch:82  Batch:4/9  loss:0.090382\n",
      "Epoch:82  Batch:5/9  loss:0.080728\n",
      "Epoch:82  Batch:6/9  loss:0.083709\n",
      "Epoch:82  Batch:7/9  loss:0.087622\n",
      "Epoch:82  Batch:8/9  loss:0.091766\n",
      "Epoch:82  Batch:9/9  loss:0.111525\n",
      "start train epoch: 83\n",
      "Epoch:83  Batch:1/9  loss:0.087356\n",
      "Epoch:83  Batch:2/9  loss:0.079735\n",
      "Epoch:83  Batch:3/9  loss:0.081688\n",
      "Epoch:83  Batch:4/9  loss:0.079008\n",
      "Epoch:83  Batch:5/9  loss:0.084578\n",
      "Epoch:83  Batch:6/9  loss:0.086627\n",
      "Epoch:83  Batch:7/9  loss:0.086264\n",
      "Epoch:83  Batch:8/9  loss:0.088028\n",
      "Epoch:83  Batch:9/9  loss:0.089611\n",
      "start train epoch: 84\n",
      "Epoch:84  Batch:1/9  loss:0.079425\n",
      "Epoch:84  Batch:2/9  loss:0.081299\n",
      "Epoch:84  Batch:3/9  loss:0.084841\n",
      "Epoch:84  Batch:4/9  loss:0.089201\n",
      "Epoch:84  Batch:5/9  loss:0.077593\n",
      "Epoch:84  Batch:6/9  loss:0.085924\n",
      "Epoch:84  Batch:7/9  loss:0.098148\n",
      "Epoch:84  Batch:8/9  loss:0.085456\n",
      "Epoch:84  Batch:9/9  loss:0.089798\n",
      "start train epoch: 85\n",
      "Epoch:85  Batch:1/9  loss:0.081711\n",
      "Epoch:85  Batch:2/9  loss:0.083487\n",
      "Epoch:85  Batch:3/9  loss:0.086400\n",
      "Epoch:85  Batch:4/9  loss:0.084009\n",
      "Epoch:85  Batch:5/9  loss:0.082716\n",
      "Epoch:85  Batch:6/9  loss:0.086852\n",
      "Epoch:85  Batch:7/9  loss:0.082634\n",
      "Epoch:85  Batch:8/9  loss:0.081418\n",
      "Epoch:85  Batch:9/9  loss:0.101635\n",
      "start train epoch: 86\n",
      "Epoch:86  Batch:1/9  loss:0.089734\n",
      "Epoch:86  Batch:2/9  loss:0.096730\n",
      "Epoch:86  Batch:3/9  loss:0.077125\n",
      "Epoch:86  Batch:4/9  loss:0.097273\n",
      "Epoch:86  Batch:5/9  loss:0.080709\n",
      "Epoch:86  Batch:6/9  loss:0.074145\n",
      "Epoch:86  Batch:7/9  loss:0.068083\n",
      "Epoch:86  Batch:8/9  loss:0.088977\n",
      "Epoch:86  Batch:9/9  loss:0.134413\n",
      "start train epoch: 87\n",
      "Epoch:87  Batch:1/9  loss:0.086354\n",
      "Epoch:87  Batch:2/9  loss:0.079659\n",
      "Epoch:87  Batch:3/9  loss:0.085242\n",
      "Epoch:87  Batch:4/9  loss:0.088067\n",
      "Epoch:87  Batch:5/9  loss:0.094249\n",
      "Epoch:87  Batch:6/9  loss:0.079934\n",
      "Epoch:87  Batch:7/9  loss:0.083757\n",
      "Epoch:87  Batch:8/9  loss:0.083422\n",
      "Epoch:87  Batch:9/9  loss:0.064188\n",
      "start train epoch: 88\n",
      "Epoch:88  Batch:1/9  loss:0.078928\n",
      "Epoch:88  Batch:2/9  loss:0.087345\n",
      "Epoch:88  Batch:3/9  loss:0.090903\n",
      "Epoch:88  Batch:4/9  loss:0.088127\n",
      "Epoch:88  Batch:5/9  loss:0.086975\n",
      "Epoch:88  Batch:6/9  loss:0.082758\n",
      "Epoch:88  Batch:7/9  loss:0.080772\n",
      "Epoch:88  Batch:8/9  loss:0.080760\n",
      "Epoch:88  Batch:9/9  loss:0.067469\n",
      "start train epoch: 89\n",
      "Epoch:89  Batch:1/9  loss:0.080241\n",
      "Epoch:89  Batch:2/9  loss:0.075312\n",
      "Epoch:89  Batch:3/9  loss:0.088349\n",
      "Epoch:89  Batch:4/9  loss:0.085382\n",
      "Epoch:89  Batch:5/9  loss:0.079284\n",
      "Epoch:89  Batch:6/9  loss:0.082032\n",
      "Epoch:89  Batch:7/9  loss:0.088969\n",
      "Epoch:89  Batch:8/9  loss:0.083041\n",
      "Epoch:89  Batch:9/9  loss:0.066286\n",
      "start train epoch: 90\n",
      "Epoch:90  Batch:1/9  loss:0.088205\n",
      "Epoch:90  Batch:2/9  loss:0.094862\n",
      "Epoch:90  Batch:3/9  loss:0.081442\n",
      "Epoch:90  Batch:4/9  loss:0.088859\n",
      "Epoch:90  Batch:5/9  loss:0.082545\n",
      "Epoch:90  Batch:6/9  loss:0.073737\n",
      "Epoch:90  Batch:7/9  loss:0.076668\n",
      "Epoch:90  Batch:8/9  loss:0.077250\n",
      "Epoch:90  Batch:9/9  loss:0.107422\n",
      "ACC: 0.9676067\n",
      "TPR: 0.7670032\n",
      "FPR: 0.015127899\n",
      "SN: 0.9848723\n",
      "SP: 0.7670032\n",
      "start train epoch: 91\n",
      "Epoch:91  Batch:1/9  loss:0.085603\n",
      "Epoch:91  Batch:2/9  loss:0.087284\n",
      "Epoch:91  Batch:3/9  loss:0.082891\n",
      "Epoch:91  Batch:4/9  loss:0.079135\n",
      "Epoch:91  Batch:5/9  loss:0.092043\n",
      "Epoch:91  Batch:6/9  loss:0.086120\n",
      "Epoch:91  Batch:7/9  loss:0.077905\n",
      "Epoch:91  Batch:8/9  loss:0.081199\n",
      "Epoch:91  Batch:9/9  loss:0.098798\n",
      "start train epoch: 92\n",
      "Epoch:92  Batch:1/9  loss:0.088956\n",
      "Epoch:92  Batch:2/9  loss:0.082771\n",
      "Epoch:92  Batch:3/9  loss:0.089417\n",
      "Epoch:92  Batch:4/9  loss:0.078804\n",
      "Epoch:92  Batch:5/9  loss:0.087557\n",
      "Epoch:92  Batch:6/9  loss:0.086427\n",
      "Epoch:92  Batch:7/9  loss:0.082377\n",
      "Epoch:92  Batch:8/9  loss:0.087606\n",
      "Epoch:92  Batch:9/9  loss:0.076857\n",
      "start train epoch: 93\n",
      "Epoch:93  Batch:1/9  loss:0.071355\n",
      "Epoch:93  Batch:2/9  loss:0.068092\n",
      "Epoch:93  Batch:3/9  loss:0.079293\n",
      "Epoch:93  Batch:4/9  loss:0.082030\n",
      "Epoch:93  Batch:5/9  loss:0.079487\n",
      "Epoch:93  Batch:6/9  loss:0.084663\n",
      "Epoch:93  Batch:7/9  loss:0.088574\n",
      "Epoch:93  Batch:8/9  loss:0.090427\n",
      "Epoch:93  Batch:9/9  loss:0.138388\n",
      "start train epoch: 94\n",
      "Epoch:94  Batch:1/9  loss:0.069897\n",
      "Epoch:94  Batch:2/9  loss:0.093963\n",
      "Epoch:94  Batch:3/9  loss:0.076831\n",
      "Epoch:94  Batch:4/9  loss:0.089874\n",
      "Epoch:94  Batch:5/9  loss:0.072118\n",
      "Epoch:94  Batch:6/9  loss:0.082572\n",
      "Epoch:94  Batch:7/9  loss:0.083549\n",
      "Epoch:94  Batch:8/9  loss:0.100409\n",
      "Epoch:94  Batch:9/9  loss:0.106529\n",
      "start train epoch: 95\n",
      "Epoch:95  Batch:1/9  loss:0.086295\n",
      "Epoch:95  Batch:2/9  loss:0.079557\n",
      "Epoch:95  Batch:3/9  loss:0.085424\n",
      "Epoch:95  Batch:4/9  loss:0.091200\n",
      "Epoch:95  Batch:5/9  loss:0.084912\n",
      "Epoch:95  Batch:6/9  loss:0.084278\n",
      "Epoch:95  Batch:7/9  loss:0.089684\n",
      "Epoch:95  Batch:8/9  loss:0.073492\n",
      "Epoch:95  Batch:9/9  loss:0.090590\n",
      "start train epoch: 96\n",
      "Epoch:96  Batch:1/9  loss:0.090536\n",
      "Epoch:96  Batch:2/9  loss:0.081368\n",
      "Epoch:96  Batch:3/9  loss:0.081953\n",
      "Epoch:96  Batch:4/9  loss:0.087828\n",
      "Epoch:96  Batch:5/9  loss:0.085063\n",
      "Epoch:96  Batch:6/9  loss:0.091575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:96  Batch:7/9  loss:0.080915\n",
      "Epoch:96  Batch:8/9  loss:0.073958\n",
      "Epoch:96  Batch:9/9  loss:0.071756\n",
      "start train epoch: 97\n",
      "Epoch:97  Batch:1/9  loss:0.079373\n",
      "Epoch:97  Batch:2/9  loss:0.084136\n",
      "Epoch:97  Batch:3/9  loss:0.101202\n",
      "Epoch:97  Batch:4/9  loss:0.090373\n",
      "Epoch:97  Batch:5/9  loss:0.077802\n",
      "Epoch:97  Batch:6/9  loss:0.070704\n",
      "Epoch:97  Batch:7/9  loss:0.088038\n",
      "Epoch:97  Batch:8/9  loss:0.082073\n",
      "Epoch:97  Batch:9/9  loss:0.097059\n",
      "start train epoch: 98\n",
      "Epoch:98  Batch:1/9  loss:0.078423\n",
      "Epoch:98  Batch:2/9  loss:0.077263\n",
      "Epoch:98  Batch:3/9  loss:0.082724\n",
      "Epoch:98  Batch:4/9  loss:0.085405\n",
      "Epoch:98  Batch:5/9  loss:0.076731\n",
      "Epoch:98  Batch:6/9  loss:0.080698\n",
      "Epoch:98  Batch:7/9  loss:0.085058\n",
      "Epoch:98  Batch:8/9  loss:0.090127\n",
      "Epoch:98  Batch:9/9  loss:0.098346\n",
      "start train epoch: 99\n",
      "Epoch:99  Batch:1/9  loss:0.080896\n",
      "Epoch:99  Batch:2/9  loss:0.079234\n",
      "Epoch:99  Batch:3/9  loss:0.089118\n",
      "Epoch:99  Batch:4/9  loss:0.087474\n",
      "Epoch:99  Batch:5/9  loss:0.079416\n",
      "Epoch:99  Batch:6/9  loss:0.079819\n",
      "Epoch:99  Batch:7/9  loss:0.081093\n",
      "Epoch:99  Batch:8/9  loss:0.083063\n",
      "Epoch:99  Batch:9/9  loss:0.062334\n",
      "start train epoch: 100\n",
      "Epoch:100  Batch:1/9  loss:0.075876\n",
      "Epoch:100  Batch:2/9  loss:0.073470\n",
      "Epoch:100  Batch:3/9  loss:0.108681\n",
      "Epoch:100  Batch:4/9  loss:0.094586\n",
      "Epoch:100  Batch:5/9  loss:0.090176\n",
      "Epoch:100  Batch:6/9  loss:0.082782\n",
      "Epoch:100  Batch:7/9  loss:0.070207\n",
      "Epoch:100  Batch:8/9  loss:0.073986\n",
      "Epoch:100  Batch:9/9  loss:0.098594\n",
      "ACC: 0.9665605\n",
      "TPR: 0.7984262\n",
      "FPR: 0.018800935\n",
      "SN: 0.981199\n",
      "SP: 0.7984262\n",
      "start train epoch: 101\n",
      "Epoch:101  Batch:1/9  loss:0.087331\n",
      "Epoch:101  Batch:2/9  loss:0.084508\n",
      "Epoch:101  Batch:3/9  loss:0.087116\n",
      "Epoch:101  Batch:4/9  loss:0.076271\n",
      "Epoch:101  Batch:5/9  loss:0.077554\n",
      "Epoch:101  Batch:6/9  loss:0.088095\n",
      "Epoch:101  Batch:7/9  loss:0.080586\n",
      "Epoch:101  Batch:8/9  loss:0.089232\n",
      "Epoch:101  Batch:9/9  loss:0.084538\n",
      "start train epoch: 102\n",
      "Epoch:102  Batch:1/9  loss:0.075771\n",
      "Epoch:102  Batch:2/9  loss:0.085806\n",
      "Epoch:102  Batch:3/9  loss:0.085822\n",
      "Epoch:102  Batch:4/9  loss:0.080778\n",
      "Epoch:102  Batch:5/9  loss:0.083536\n",
      "Epoch:102  Batch:6/9  loss:0.094299\n",
      "Epoch:102  Batch:7/9  loss:0.073551\n",
      "Epoch:102  Batch:8/9  loss:0.082682\n",
      "Epoch:102  Batch:9/9  loss:0.165949\n",
      "start train epoch: 103\n",
      "Epoch:103  Batch:1/9  loss:0.089463\n",
      "Epoch:103  Batch:2/9  loss:0.084536\n",
      "Epoch:103  Batch:3/9  loss:0.076416\n",
      "Epoch:103  Batch:4/9  loss:0.094641\n",
      "Epoch:103  Batch:5/9  loss:0.087336\n",
      "Epoch:103  Batch:6/9  loss:0.082824\n",
      "Epoch:103  Batch:7/9  loss:0.076797\n",
      "Epoch:103  Batch:8/9  loss:0.080894\n",
      "Epoch:103  Batch:9/9  loss:0.082855\n",
      "start train epoch: 104\n",
      "Epoch:104  Batch:1/9  loss:0.082865\n",
      "Epoch:104  Batch:2/9  loss:0.086622\n",
      "Epoch:104  Batch:3/9  loss:0.077935\n",
      "Epoch:104  Batch:4/9  loss:0.073002\n",
      "Epoch:104  Batch:5/9  loss:0.090811\n",
      "Epoch:104  Batch:6/9  loss:0.091293\n",
      "Epoch:104  Batch:7/9  loss:0.091608\n",
      "Epoch:104  Batch:8/9  loss:0.081429\n",
      "Epoch:104  Batch:9/9  loss:0.090250\n",
      "start train epoch: 105\n",
      "Epoch:105  Batch:1/9  loss:0.077644\n",
      "Epoch:105  Batch:2/9  loss:0.077693\n",
      "Epoch:105  Batch:3/9  loss:0.077626\n",
      "Epoch:105  Batch:4/9  loss:0.082081\n",
      "Epoch:105  Batch:5/9  loss:0.090837\n",
      "Epoch:105  Batch:6/9  loss:0.084462\n",
      "Epoch:105  Batch:7/9  loss:0.081584\n",
      "Epoch:105  Batch:8/9  loss:0.084527\n",
      "Epoch:105  Batch:9/9  loss:0.090646\n",
      "start train epoch: 106\n",
      "Epoch:106  Batch:1/9  loss:0.077780\n",
      "Epoch:106  Batch:2/9  loss:0.071420\n",
      "Epoch:106  Batch:3/9  loss:0.086460\n",
      "Epoch:106  Batch:4/9  loss:0.079168\n",
      "Epoch:106  Batch:5/9  loss:0.080083\n",
      "Epoch:106  Batch:6/9  loss:0.093518\n",
      "Epoch:106  Batch:7/9  loss:0.088289\n",
      "Epoch:106  Batch:8/9  loss:0.089016\n",
      "Epoch:106  Batch:9/9  loss:0.081749\n",
      "start train epoch: 107\n",
      "Epoch:107  Batch:1/9  loss:0.082763\n",
      "Epoch:107  Batch:2/9  loss:0.086681\n",
      "Epoch:107  Batch:3/9  loss:0.097445\n",
      "Epoch:107  Batch:4/9  loss:0.079684\n",
      "Epoch:107  Batch:5/9  loss:0.084802\n",
      "Epoch:107  Batch:6/9  loss:0.090450\n",
      "Epoch:107  Batch:7/9  loss:0.083898\n",
      "Epoch:107  Batch:8/9  loss:0.084706\n",
      "Epoch:107  Batch:9/9  loss:0.116455\n",
      "start train epoch: 108\n",
      "Epoch:108  Batch:1/9  loss:0.080927\n",
      "Epoch:108  Batch:2/9  loss:0.086120\n",
      "Epoch:108  Batch:3/9  loss:0.085799\n",
      "Epoch:108  Batch:4/9  loss:0.087595\n",
      "Epoch:108  Batch:5/9  loss:0.084998\n",
      "Epoch:108  Batch:6/9  loss:0.086142\n",
      "Epoch:108  Batch:7/9  loss:0.088787\n",
      "Epoch:108  Batch:8/9  loss:0.086838\n",
      "Epoch:108  Batch:9/9  loss:0.103548\n",
      "start train epoch: 109\n",
      "Epoch:109  Batch:1/9  loss:0.083610\n",
      "Epoch:109  Batch:2/9  loss:0.085296\n",
      "Epoch:109  Batch:3/9  loss:0.081879\n",
      "Epoch:109  Batch:4/9  loss:0.085300\n",
      "Epoch:109  Batch:5/9  loss:0.085606\n",
      "Epoch:109  Batch:6/9  loss:0.078089\n",
      "Epoch:109  Batch:7/9  loss:0.089705\n",
      "Epoch:109  Batch:8/9  loss:0.088324\n",
      "Epoch:109  Batch:9/9  loss:0.091576\n",
      "start train epoch: 110\n",
      "Epoch:110  Batch:1/9  loss:0.081914\n",
      "Epoch:110  Batch:2/9  loss:0.085435\n",
      "Epoch:110  Batch:3/9  loss:0.083898\n",
      "Epoch:110  Batch:4/9  loss:0.099298\n",
      "Epoch:110  Batch:5/9  loss:0.078459\n",
      "Epoch:110  Batch:6/9  loss:0.084006\n",
      "Epoch:110  Batch:7/9  loss:0.087075\n",
      "Epoch:110  Batch:8/9  loss:0.080940\n",
      "Epoch:110  Batch:9/9  loss:0.095790\n",
      "ACC: 0.9682938\n",
      "TPR: 0.73663807\n",
      "FPR: 0.012109255\n",
      "SN: 0.9878908\n",
      "SP: 0.73663807\n",
      "start train epoch: 111\n",
      "Epoch:111  Batch:1/9  loss:0.085296\n",
      "Epoch:111  Batch:2/9  loss:0.079410\n",
      "Epoch:111  Batch:3/9  loss:0.070353\n",
      "Epoch:111  Batch:4/9  loss:0.091836\n",
      "Epoch:111  Batch:5/9  loss:0.079667\n",
      "Epoch:111  Batch:6/9  loss:0.097169\n",
      "Epoch:111  Batch:7/9  loss:0.085429\n",
      "Epoch:111  Batch:8/9  loss:0.074782\n",
      "Epoch:111  Batch:9/9  loss:0.136994\n",
      "start train epoch: 112\n",
      "Epoch:112  Batch:1/9  loss:0.086660\n",
      "Epoch:112  Batch:2/9  loss:0.078752\n",
      "Epoch:112  Batch:3/9  loss:0.094852\n",
      "Epoch:112  Batch:4/9  loss:0.083028\n",
      "Epoch:112  Batch:5/9  loss:0.085466\n",
      "Epoch:112  Batch:6/9  loss:0.083044\n",
      "Epoch:112  Batch:7/9  loss:0.085940\n",
      "Epoch:112  Batch:8/9  loss:0.075829\n",
      "Epoch:112  Batch:9/9  loss:0.078770\n",
      "start train epoch: 113\n",
      "Epoch:113  Batch:1/9  loss:0.094411\n",
      "Epoch:113  Batch:2/9  loss:0.078468\n",
      "Epoch:113  Batch:3/9  loss:0.081713\n",
      "Epoch:113  Batch:4/9  loss:0.073858\n",
      "Epoch:113  Batch:5/9  loss:0.091148\n",
      "Epoch:113  Batch:6/9  loss:0.091281\n",
      "Epoch:113  Batch:7/9  loss:0.078706\n",
      "Epoch:113  Batch:8/9  loss:0.088467\n",
      "Epoch:113  Batch:9/9  loss:0.080879\n",
      "start train epoch: 114\n",
      "Epoch:114  Batch:1/9  loss:0.079963\n",
      "Epoch:114  Batch:2/9  loss:0.075347\n",
      "Epoch:114  Batch:3/9  loss:0.078297\n",
      "Epoch:114  Batch:4/9  loss:0.076892\n",
      "Epoch:114  Batch:5/9  loss:0.081752\n",
      "Epoch:114  Batch:6/9  loss:0.076910\n",
      "Epoch:114  Batch:7/9  loss:0.099082\n",
      "Epoch:114  Batch:8/9  loss:0.087890\n",
      "Epoch:114  Batch:9/9  loss:0.064692\n",
      "start train epoch: 115\n",
      "Epoch:115  Batch:1/9  loss:0.085971\n",
      "Epoch:115  Batch:2/9  loss:0.070396\n",
      "Epoch:115  Batch:3/9  loss:0.098522\n",
      "Epoch:115  Batch:4/9  loss:0.081644\n",
      "Epoch:115  Batch:5/9  loss:0.084144\n",
      "Epoch:115  Batch:6/9  loss:0.077862\n",
      "Epoch:115  Batch:7/9  loss:0.085550\n",
      "Epoch:115  Batch:8/9  loss:0.080448\n",
      "Epoch:115  Batch:9/9  loss:0.094564\n",
      "start train epoch: 116\n",
      "Epoch:116  Batch:1/9  loss:0.078027\n",
      "Epoch:116  Batch:2/9  loss:0.068241\n",
      "Epoch:116  Batch:3/9  loss:0.082937\n",
      "Epoch:116  Batch:4/9  loss:0.078579\n",
      "Epoch:116  Batch:5/9  loss:0.097302\n",
      "Epoch:116  Batch:6/9  loss:0.078041\n",
      "Epoch:116  Batch:7/9  loss:0.088876\n",
      "Epoch:116  Batch:8/9  loss:0.081856\n",
      "Epoch:116  Batch:9/9  loss:0.072859\n",
      "start train epoch: 117\n",
      "Epoch:117  Batch:1/9  loss:0.074038\n",
      "Epoch:117  Batch:2/9  loss:0.087982\n",
      "Epoch:117  Batch:3/9  loss:0.086912\n",
      "Epoch:117  Batch:4/9  loss:0.076032\n",
      "Epoch:117  Batch:5/9  loss:0.079859\n",
      "Epoch:117  Batch:6/9  loss:0.097467\n",
      "Epoch:117  Batch:7/9  loss:0.088628\n",
      "Epoch:117  Batch:8/9  loss:0.085680\n",
      "Epoch:117  Batch:9/9  loss:0.099190\n",
      "start train epoch: 118\n",
      "Epoch:118  Batch:1/9  loss:0.079402\n",
      "Epoch:118  Batch:2/9  loss:0.093858\n",
      "Epoch:118  Batch:3/9  loss:0.081885\n",
      "Epoch:118  Batch:4/9  loss:0.081059\n",
      "Epoch:118  Batch:5/9  loss:0.077251\n",
      "Epoch:118  Batch:6/9  loss:0.092376\n",
      "Epoch:118  Batch:7/9  loss:0.074736\n",
      "Epoch:118  Batch:8/9  loss:0.078328\n",
      "Epoch:118  Batch:9/9  loss:0.112311\n",
      "start train epoch: 119\n",
      "Epoch:119  Batch:1/9  loss:0.074679\n",
      "Epoch:119  Batch:2/9  loss:0.075206\n",
      "Epoch:119  Batch:3/9  loss:0.082763\n",
      "Epoch:119  Batch:4/9  loss:0.101378\n",
      "Epoch:119  Batch:5/9  loss:0.090326\n",
      "Epoch:119  Batch:6/9  loss:0.088363\n",
      "Epoch:119  Batch:7/9  loss:0.082143\n",
      "Epoch:119  Batch:8/9  loss:0.078463\n",
      "Epoch:119  Batch:9/9  loss:0.080005\n",
      "start train epoch: 120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:120  Batch:1/9  loss:0.073973\n",
      "Epoch:120  Batch:2/9  loss:0.085304\n",
      "Epoch:120  Batch:3/9  loss:0.082223\n",
      "Epoch:120  Batch:4/9  loss:0.088290\n",
      "Epoch:120  Batch:5/9  loss:0.080034\n",
      "Epoch:120  Batch:6/9  loss:0.075529\n",
      "Epoch:120  Batch:7/9  loss:0.082733\n",
      "Epoch:120  Batch:8/9  loss:0.098821\n",
      "Epoch:120  Batch:9/9  loss:0.088219\n",
      "ACC: 0.9684499\n",
      "TPR: 0.77262336\n",
      "FPR: 0.014869424\n",
      "SN: 0.9851304\n",
      "SP: 0.77262336\n",
      "start train epoch: 121\n",
      "Epoch:121  Batch:1/9  loss:0.081061\n",
      "Epoch:121  Batch:2/9  loss:0.084767\n",
      "Epoch:121  Batch:3/9  loss:0.079385\n",
      "Epoch:121  Batch:4/9  loss:0.083060\n",
      "Epoch:121  Batch:5/9  loss:0.073640\n",
      "Epoch:121  Batch:6/9  loss:0.096012\n",
      "Epoch:121  Batch:7/9  loss:0.073874\n",
      "Epoch:121  Batch:8/9  loss:0.077477\n",
      "Epoch:121  Batch:9/9  loss:0.102123\n",
      "start train epoch: 122\n",
      "Epoch:122  Batch:1/9  loss:0.075676\n",
      "Epoch:122  Batch:2/9  loss:0.078059\n",
      "Epoch:122  Batch:3/9  loss:0.076495\n",
      "Epoch:122  Batch:4/9  loss:0.084507\n",
      "Epoch:122  Batch:5/9  loss:0.090406\n",
      "Epoch:122  Batch:6/9  loss:0.083928\n",
      "Epoch:122  Batch:7/9  loss:0.088761\n",
      "Epoch:122  Batch:8/9  loss:0.084085\n",
      "Epoch:122  Batch:9/9  loss:0.076710\n",
      "start train epoch: 123\n",
      "Epoch:123  Batch:1/9  loss:0.075739\n",
      "Epoch:123  Batch:2/9  loss:0.089458\n",
      "Epoch:123  Batch:3/9  loss:0.081395\n",
      "Epoch:123  Batch:4/9  loss:0.082955\n",
      "Epoch:123  Batch:5/9  loss:0.083839\n",
      "Epoch:123  Batch:6/9  loss:0.084867\n",
      "Epoch:123  Batch:7/9  loss:0.085735\n",
      "Epoch:123  Batch:8/9  loss:0.079474\n",
      "Epoch:123  Batch:9/9  loss:0.095619\n",
      "start train epoch: 124\n",
      "Epoch:124  Batch:1/9  loss:0.075053\n",
      "Epoch:124  Batch:2/9  loss:0.085634\n",
      "Epoch:124  Batch:3/9  loss:0.079379\n",
      "Epoch:124  Batch:4/9  loss:0.085944\n",
      "Epoch:124  Batch:5/9  loss:0.076464\n",
      "Epoch:124  Batch:6/9  loss:0.094281\n",
      "Epoch:124  Batch:7/9  loss:0.080734\n",
      "Epoch:124  Batch:8/9  loss:0.092221\n",
      "Epoch:124  Batch:9/9  loss:0.156543\n",
      "start train epoch: 125\n",
      "Epoch:125  Batch:1/9  loss:0.077598\n",
      "Epoch:125  Batch:2/9  loss:0.103660\n",
      "Epoch:125  Batch:3/9  loss:0.103438\n",
      "Epoch:125  Batch:4/9  loss:0.090256\n",
      "Epoch:125  Batch:5/9  loss:0.085630\n",
      "Epoch:125  Batch:6/9  loss:0.092464\n",
      "Epoch:125  Batch:7/9  loss:0.080879\n",
      "Epoch:125  Batch:8/9  loss:0.084535\n",
      "Epoch:125  Batch:9/9  loss:0.078308\n",
      "start train epoch: 126\n",
      "Epoch:126  Batch:1/9  loss:0.082544\n",
      "Epoch:126  Batch:2/9  loss:0.079493\n",
      "Epoch:126  Batch:3/9  loss:0.087660\n",
      "Epoch:126  Batch:4/9  loss:0.088313\n",
      "Epoch:126  Batch:5/9  loss:0.098538\n",
      "Epoch:126  Batch:6/9  loss:0.101365\n",
      "Epoch:126  Batch:7/9  loss:0.080558\n",
      "Epoch:126  Batch:8/9  loss:0.077913\n",
      "Epoch:126  Batch:9/9  loss:0.081840\n",
      "start train epoch: 127\n",
      "Epoch:127  Batch:1/9  loss:0.085734\n",
      "Epoch:127  Batch:2/9  loss:0.091248\n",
      "Epoch:127  Batch:3/9  loss:0.081741\n",
      "Epoch:127  Batch:4/9  loss:0.083759\n",
      "Epoch:127  Batch:5/9  loss:0.083288\n",
      "Epoch:127  Batch:6/9  loss:0.089726\n",
      "Epoch:127  Batch:7/9  loss:0.075695\n",
      "Epoch:127  Batch:8/9  loss:0.091331\n",
      "Epoch:127  Batch:9/9  loss:0.130793\n",
      "start train epoch: 128\n",
      "Epoch:128  Batch:1/9  loss:0.089570\n",
      "Epoch:128  Batch:2/9  loss:0.071157\n",
      "Epoch:128  Batch:3/9  loss:0.077875\n",
      "Epoch:128  Batch:4/9  loss:0.094052\n",
      "Epoch:128  Batch:5/9  loss:0.092682\n",
      "Epoch:128  Batch:6/9  loss:0.081194\n",
      "Epoch:128  Batch:7/9  loss:0.083373\n",
      "Epoch:128  Batch:8/9  loss:0.077431\n",
      "Epoch:128  Batch:9/9  loss:0.104136\n",
      "start train epoch: 129\n",
      "Epoch:129  Batch:1/9  loss:0.076703\n",
      "Epoch:129  Batch:2/9  loss:0.074619\n",
      "Epoch:129  Batch:3/9  loss:0.086821\n",
      "Epoch:129  Batch:4/9  loss:0.086992\n",
      "Epoch:129  Batch:5/9  loss:0.088027\n",
      "Epoch:129  Batch:6/9  loss:0.073737\n",
      "Epoch:129  Batch:7/9  loss:0.094037\n",
      "Epoch:129  Batch:8/9  loss:0.079154\n",
      "Epoch:129  Batch:9/9  loss:0.082741\n",
      "start train epoch: 130\n",
      "Epoch:130  Batch:1/9  loss:0.084286\n",
      "Epoch:130  Batch:2/9  loss:0.074478\n",
      "Epoch:130  Batch:3/9  loss:0.086246\n",
      "Epoch:130  Batch:4/9  loss:0.079610\n",
      "Epoch:130  Batch:5/9  loss:0.099284\n",
      "Epoch:130  Batch:6/9  loss:0.079911\n",
      "Epoch:130  Batch:7/9  loss:0.077231\n",
      "Epoch:130  Batch:8/9  loss:0.083177\n",
      "Epoch:130  Batch:9/9  loss:0.087176\n",
      "ACC: 0.9678466\n",
      "TPR: 0.70317626\n",
      "FPR: 0.009768022\n",
      "SN: 0.990232\n",
      "SP: 0.70317626\n",
      "start train epoch: 131\n",
      "Epoch:131  Batch:1/9  loss:0.087838\n",
      "Epoch:131  Batch:2/9  loss:0.087632\n",
      "Epoch:131  Batch:3/9  loss:0.078233\n",
      "Epoch:131  Batch:4/9  loss:0.078148\n",
      "Epoch:131  Batch:5/9  loss:0.080956\n",
      "Epoch:131  Batch:6/9  loss:0.083485\n",
      "Epoch:131  Batch:7/9  loss:0.084869\n",
      "Epoch:131  Batch:8/9  loss:0.077533\n",
      "Epoch:131  Batch:9/9  loss:0.065640\n",
      "start train epoch: 132\n",
      "Epoch:132  Batch:1/9  loss:0.080725\n",
      "Epoch:132  Batch:2/9  loss:0.073844\n",
      "Epoch:132  Batch:3/9  loss:0.082521\n",
      "Epoch:132  Batch:4/9  loss:0.091793\n",
      "Epoch:132  Batch:5/9  loss:0.094857\n",
      "Epoch:132  Batch:6/9  loss:0.085998\n",
      "Epoch:132  Batch:7/9  loss:0.087879\n",
      "Epoch:132  Batch:8/9  loss:0.075342\n",
      "Epoch:132  Batch:9/9  loss:0.057326\n",
      "start train epoch: 133\n",
      "Epoch:133  Batch:1/9  loss:0.081759\n",
      "Epoch:133  Batch:2/9  loss:0.081706\n",
      "Epoch:133  Batch:3/9  loss:0.080600\n",
      "Epoch:133  Batch:4/9  loss:0.079072\n",
      "Epoch:133  Batch:5/9  loss:0.091753\n",
      "Epoch:133  Batch:6/9  loss:0.090770\n",
      "Epoch:133  Batch:7/9  loss:0.072198\n",
      "Epoch:133  Batch:8/9  loss:0.085026\n",
      "Epoch:133  Batch:9/9  loss:0.061178\n",
      "start train epoch: 134\n",
      "Epoch:134  Batch:1/9  loss:0.073295\n",
      "Epoch:134  Batch:2/9  loss:0.073787\n",
      "Epoch:134  Batch:3/9  loss:0.086123\n",
      "Epoch:134  Batch:4/9  loss:0.082011\n",
      "Epoch:134  Batch:5/9  loss:0.084245\n",
      "Epoch:134  Batch:6/9  loss:0.087579\n",
      "Epoch:134  Batch:7/9  loss:0.083256\n",
      "Epoch:134  Batch:8/9  loss:0.076882\n",
      "Epoch:134  Batch:9/9  loss:0.077128\n",
      "start train epoch: 135\n",
      "Epoch:135  Batch:1/9  loss:0.074711\n",
      "Epoch:135  Batch:2/9  loss:0.094820\n",
      "Epoch:135  Batch:3/9  loss:0.073099\n",
      "Epoch:135  Batch:4/9  loss:0.077789\n",
      "Epoch:135  Batch:5/9  loss:0.083109\n",
      "Epoch:135  Batch:6/9  loss:0.091607\n",
      "Epoch:135  Batch:7/9  loss:0.082066\n",
      "Epoch:135  Batch:8/9  loss:0.084938\n",
      "Epoch:135  Batch:9/9  loss:0.091587\n",
      "start train epoch: 136\n",
      "Epoch:136  Batch:1/9  loss:0.085915\n",
      "Epoch:136  Batch:2/9  loss:0.082070\n",
      "Epoch:136  Batch:3/9  loss:0.072928\n",
      "Epoch:136  Batch:4/9  loss:0.080883\n",
      "Epoch:136  Batch:5/9  loss:0.076432\n",
      "Epoch:136  Batch:6/9  loss:0.080232\n",
      "Epoch:136  Batch:7/9  loss:0.084726\n",
      "Epoch:136  Batch:8/9  loss:0.084008\n",
      "Epoch:136  Batch:9/9  loss:0.075199\n",
      "start train epoch: 137\n",
      "Epoch:137  Batch:1/9  loss:0.073901\n",
      "Epoch:137  Batch:2/9  loss:0.078530\n",
      "Epoch:137  Batch:3/9  loss:0.077593\n",
      "Epoch:137  Batch:4/9  loss:0.083378\n",
      "Epoch:137  Batch:5/9  loss:0.087354\n",
      "Epoch:137  Batch:6/9  loss:0.082453\n",
      "Epoch:137  Batch:7/9  loss:0.085885\n",
      "Epoch:137  Batch:8/9  loss:0.076824\n",
      "Epoch:137  Batch:9/9  loss:0.091320\n",
      "start train epoch: 138\n",
      "Epoch:138  Batch:1/9  loss:0.076124\n",
      "Epoch:138  Batch:2/9  loss:0.080978\n",
      "Epoch:138  Batch:3/9  loss:0.090480\n",
      "Epoch:138  Batch:4/9  loss:0.076727\n",
      "Epoch:138  Batch:5/9  loss:0.085982\n",
      "Epoch:138  Batch:6/9  loss:0.076930\n",
      "Epoch:138  Batch:7/9  loss:0.071671\n",
      "Epoch:138  Batch:8/9  loss:0.077542\n",
      "Epoch:138  Batch:9/9  loss:0.086466\n",
      "start train epoch: 139\n",
      "Epoch:139  Batch:1/9  loss:0.082644\n",
      "Epoch:139  Batch:2/9  loss:0.080075\n",
      "Epoch:139  Batch:3/9  loss:0.085114\n",
      "Epoch:139  Batch:4/9  loss:0.078831\n",
      "Epoch:139  Batch:5/9  loss:0.076338\n",
      "Epoch:139  Batch:6/9  loss:0.079102\n",
      "Epoch:139  Batch:7/9  loss:0.070587\n",
      "Epoch:139  Batch:8/9  loss:0.084590\n",
      "Epoch:139  Batch:9/9  loss:0.092030\n",
      "start train epoch: 140\n",
      "Epoch:140  Batch:1/9  loss:0.080371\n",
      "Epoch:140  Batch:2/9  loss:0.083728\n",
      "Epoch:140  Batch:3/9  loss:0.092565\n",
      "Epoch:140  Batch:4/9  loss:0.077679\n",
      "Epoch:140  Batch:5/9  loss:0.076487\n",
      "Epoch:140  Batch:6/9  loss:0.097007\n",
      "Epoch:140  Batch:7/9  loss:0.076632\n",
      "Epoch:140  Batch:8/9  loss:0.070384\n",
      "Epoch:140  Batch:9/9  loss:0.083333\n",
      "ACC: 0.9683666\n",
      "TPR: 0.7598653\n",
      "FPR: 0.013648656\n",
      "SN: 0.9863514\n",
      "SP: 0.7598653\n",
      "start train epoch: 141\n",
      "Epoch:141  Batch:1/9  loss:0.076119\n",
      "Epoch:141  Batch:2/9  loss:0.072649\n",
      "Epoch:141  Batch:3/9  loss:0.082503\n",
      "Epoch:141  Batch:4/9  loss:0.082351\n",
      "Epoch:141  Batch:5/9  loss:0.078733\n",
      "Epoch:141  Batch:6/9  loss:0.079129\n",
      "Epoch:141  Batch:7/9  loss:0.081668\n",
      "Epoch:141  Batch:8/9  loss:0.085675\n",
      "Epoch:141  Batch:9/9  loss:0.085215\n",
      "start train epoch: 142\n",
      "Epoch:142  Batch:1/9  loss:0.077660\n",
      "Epoch:142  Batch:2/9  loss:0.081061\n",
      "Epoch:142  Batch:3/9  loss:0.079145\n",
      "Epoch:142  Batch:4/9  loss:0.094048\n",
      "Epoch:142  Batch:5/9  loss:0.079024\n",
      "Epoch:142  Batch:6/9  loss:0.076137\n",
      "Epoch:142  Batch:7/9  loss:0.081878\n",
      "Epoch:142  Batch:8/9  loss:0.074493\n",
      "Epoch:142  Batch:9/9  loss:0.082715\n",
      "start train epoch: 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:143  Batch:1/9  loss:0.088606\n",
      "Epoch:143  Batch:2/9  loss:0.083937\n",
      "Epoch:143  Batch:3/9  loss:0.077973\n",
      "Epoch:143  Batch:4/9  loss:0.081190\n",
      "Epoch:143  Batch:5/9  loss:0.079601\n",
      "Epoch:143  Batch:6/9  loss:0.070438\n",
      "Epoch:143  Batch:7/9  loss:0.082787\n",
      "Epoch:143  Batch:8/9  loss:0.073136\n",
      "Epoch:143  Batch:9/9  loss:0.118211\n",
      "start train epoch: 144\n",
      "Epoch:144  Batch:1/9  loss:0.094210\n",
      "Epoch:144  Batch:2/9  loss:0.086299\n",
      "Epoch:144  Batch:3/9  loss:0.083526\n",
      "Epoch:144  Batch:4/9  loss:0.081605\n",
      "Epoch:144  Batch:5/9  loss:0.070399\n",
      "Epoch:144  Batch:6/9  loss:0.092348\n",
      "Epoch:144  Batch:7/9  loss:0.070915\n",
      "Epoch:144  Batch:8/9  loss:0.080118\n",
      "Epoch:144  Batch:9/9  loss:0.079459\n",
      "start train epoch: 145\n",
      "Epoch:145  Batch:1/9  loss:0.076534\n",
      "Epoch:145  Batch:2/9  loss:0.090334\n",
      "Epoch:145  Batch:3/9  loss:0.085182\n",
      "Epoch:145  Batch:4/9  loss:0.074478\n",
      "Epoch:145  Batch:5/9  loss:0.087747\n",
      "Epoch:145  Batch:6/9  loss:0.077185\n",
      "Epoch:145  Batch:7/9  loss:0.077225\n",
      "Epoch:145  Batch:8/9  loss:0.075844\n",
      "Epoch:145  Batch:9/9  loss:0.098151\n",
      "start train epoch: 146\n",
      "Epoch:146  Batch:1/9  loss:0.082787\n",
      "Epoch:146  Batch:2/9  loss:0.091045\n",
      "Epoch:146  Batch:3/9  loss:0.077944\n",
      "Epoch:146  Batch:4/9  loss:0.091935\n",
      "Epoch:146  Batch:5/9  loss:0.072826\n",
      "Epoch:146  Batch:6/9  loss:0.075627\n",
      "Epoch:146  Batch:7/9  loss:0.080042\n",
      "Epoch:146  Batch:8/9  loss:0.077743\n",
      "Epoch:146  Batch:9/9  loss:0.082139\n",
      "start train epoch: 147\n",
      "Epoch:147  Batch:1/9  loss:0.079371\n",
      "Epoch:147  Batch:2/9  loss:0.081944\n",
      "Epoch:147  Batch:3/9  loss:0.090532\n",
      "Epoch:147  Batch:4/9  loss:0.081653\n",
      "Epoch:147  Batch:5/9  loss:0.073788\n",
      "Epoch:147  Batch:6/9  loss:0.084994\n",
      "Epoch:147  Batch:7/9  loss:0.086540\n",
      "Epoch:147  Batch:8/9  loss:0.074115\n",
      "Epoch:147  Batch:9/9  loss:0.085843\n",
      "start train epoch: 148\n",
      "Epoch:148  Batch:1/9  loss:0.078758\n",
      "Epoch:148  Batch:2/9  loss:0.093540\n",
      "Epoch:148  Batch:3/9  loss:0.083537\n",
      "Epoch:148  Batch:4/9  loss:0.077258\n",
      "Epoch:148  Batch:5/9  loss:0.077244\n",
      "Epoch:148  Batch:6/9  loss:0.082726\n",
      "Epoch:148  Batch:7/9  loss:0.081184\n",
      "Epoch:148  Batch:8/9  loss:0.088710\n",
      "Epoch:148  Batch:9/9  loss:0.063376\n",
      "start train epoch: 149\n",
      "Epoch:149  Batch:1/9  loss:0.080525\n",
      "Epoch:149  Batch:2/9  loss:0.071486\n",
      "Epoch:149  Batch:3/9  loss:0.081069\n",
      "Epoch:149  Batch:4/9  loss:0.079131\n",
      "Epoch:149  Batch:5/9  loss:0.079227\n",
      "Epoch:149  Batch:6/9  loss:0.093263\n",
      "Epoch:149  Batch:7/9  loss:0.080313\n",
      "Epoch:149  Batch:8/9  loss:0.072157\n",
      "Epoch:149  Batch:9/9  loss:0.057161\n",
      "start train epoch: 150\n",
      "Epoch:150  Batch:1/9  loss:0.085091\n",
      "Epoch:150  Batch:2/9  loss:0.079536\n",
      "Epoch:150  Batch:3/9  loss:0.083997\n",
      "Epoch:150  Batch:4/9  loss:0.090199\n",
      "Epoch:150  Batch:5/9  loss:0.079281\n",
      "Epoch:150  Batch:6/9  loss:0.091848\n",
      "Epoch:150  Batch:7/9  loss:0.065950\n",
      "Epoch:150  Batch:8/9  loss:0.068595\n",
      "Epoch:150  Batch:9/9  loss:0.133084\n",
      "ACC: 0.9688881\n",
      "TPR: 0.74051744\n",
      "FPR: 0.011680925\n",
      "SN: 0.98831916\n",
      "SP: 0.74051744\n",
      "start train epoch: 151\n",
      "Epoch:151  Batch:1/9  loss:0.085781\n",
      "Epoch:151  Batch:2/9  loss:0.071920\n",
      "Epoch:151  Batch:3/9  loss:0.076235\n",
      "Epoch:151  Batch:4/9  loss:0.076187\n",
      "Epoch:151  Batch:5/9  loss:0.078492\n",
      "Epoch:151  Batch:6/9  loss:0.071871\n",
      "Epoch:151  Batch:7/9  loss:0.093599\n",
      "Epoch:151  Batch:8/9  loss:0.090626\n",
      "Epoch:151  Batch:9/9  loss:0.053301\n",
      "start train epoch: 152\n",
      "Epoch:152  Batch:1/9  loss:0.085555\n",
      "Epoch:152  Batch:2/9  loss:0.080499\n",
      "Epoch:152  Batch:3/9  loss:0.078775\n",
      "Epoch:152  Batch:4/9  loss:0.070413\n",
      "Epoch:152  Batch:5/9  loss:0.080656\n",
      "Epoch:152  Batch:6/9  loss:0.080943\n",
      "Epoch:152  Batch:7/9  loss:0.070530\n",
      "Epoch:152  Batch:8/9  loss:0.072314\n",
      "Epoch:152  Batch:9/9  loss:0.067169\n",
      "start train epoch: 153\n",
      "Epoch:153  Batch:1/9  loss:0.078210\n",
      "Epoch:153  Batch:2/9  loss:0.082236\n",
      "Epoch:153  Batch:3/9  loss:0.073766\n",
      "Epoch:153  Batch:4/9  loss:0.076778\n",
      "Epoch:153  Batch:5/9  loss:0.073811\n",
      "Epoch:153  Batch:6/9  loss:0.080283\n",
      "Epoch:153  Batch:7/9  loss:0.077227\n",
      "Epoch:153  Batch:8/9  loss:0.092332\n",
      "Epoch:153  Batch:9/9  loss:0.083673\n",
      "start train epoch: 154\n",
      "Epoch:154  Batch:1/9  loss:0.073909\n",
      "Epoch:154  Batch:2/9  loss:0.080355\n",
      "Epoch:154  Batch:3/9  loss:0.080453\n",
      "Epoch:154  Batch:4/9  loss:0.077106\n",
      "Epoch:154  Batch:5/9  loss:0.083879\n",
      "Epoch:154  Batch:6/9  loss:0.076716\n",
      "Epoch:154  Batch:7/9  loss:0.083175\n",
      "Epoch:154  Batch:8/9  loss:0.078821\n",
      "Epoch:154  Batch:9/9  loss:0.098381\n",
      "start train epoch: 155\n",
      "Epoch:155  Batch:1/9  loss:0.078492\n",
      "Epoch:155  Batch:2/9  loss:0.080915\n",
      "Epoch:155  Batch:3/9  loss:0.078977\n",
      "Epoch:155  Batch:4/9  loss:0.077489\n",
      "Epoch:155  Batch:5/9  loss:0.086725\n",
      "Epoch:155  Batch:6/9  loss:0.085334\n",
      "Epoch:155  Batch:7/9  loss:0.079258\n",
      "Epoch:155  Batch:8/9  loss:0.087903\n",
      "Epoch:155  Batch:9/9  loss:0.058727\n",
      "start train epoch: 156\n",
      "Epoch:156  Batch:1/9  loss:0.069486\n",
      "Epoch:156  Batch:2/9  loss:0.091164\n",
      "Epoch:156  Batch:3/9  loss:0.081248\n",
      "Epoch:156  Batch:4/9  loss:0.070060\n",
      "Epoch:156  Batch:5/9  loss:0.088588\n",
      "Epoch:156  Batch:6/9  loss:0.074511\n",
      "Epoch:156  Batch:7/9  loss:0.089046\n",
      "Epoch:156  Batch:8/9  loss:0.074728\n",
      "Epoch:156  Batch:9/9  loss:0.101247\n",
      "start train epoch: 157\n",
      "Epoch:157  Batch:1/9  loss:0.072378\n",
      "Epoch:157  Batch:2/9  loss:0.079671\n",
      "Epoch:157  Batch:3/9  loss:0.085967\n",
      "Epoch:157  Batch:4/9  loss:0.086210\n",
      "Epoch:157  Batch:5/9  loss:0.074359\n",
      "Epoch:157  Batch:6/9  loss:0.078479\n",
      "Epoch:157  Batch:7/9  loss:0.086310\n",
      "Epoch:157  Batch:8/9  loss:0.071289\n",
      "Epoch:157  Batch:9/9  loss:0.106349\n",
      "start train epoch: 158\n",
      "Epoch:158  Batch:1/9  loss:0.081481\n",
      "Epoch:158  Batch:2/9  loss:0.083150\n",
      "Epoch:158  Batch:3/9  loss:0.091964\n",
      "Epoch:158  Batch:4/9  loss:0.071773\n",
      "Epoch:158  Batch:5/9  loss:0.079189\n",
      "Epoch:158  Batch:6/9  loss:0.072773\n",
      "Epoch:158  Batch:7/9  loss:0.078894\n",
      "Epoch:158  Batch:8/9  loss:0.088219\n",
      "Epoch:158  Batch:9/9  loss:0.078950\n",
      "start train epoch: 159\n",
      "Epoch:159  Batch:1/9  loss:0.067725\n",
      "Epoch:159  Batch:2/9  loss:0.075332\n",
      "Epoch:159  Batch:3/9  loss:0.072435\n",
      "Epoch:159  Batch:4/9  loss:0.091230\n",
      "Epoch:159  Batch:5/9  loss:0.076613\n",
      "Epoch:159  Batch:6/9  loss:0.087362\n",
      "Epoch:159  Batch:7/9  loss:0.079017\n",
      "Epoch:159  Batch:8/9  loss:0.082992\n",
      "Epoch:159  Batch:9/9  loss:0.060475\n",
      "start train epoch: 160\n",
      "Epoch:160  Batch:1/9  loss:0.084548\n",
      "Epoch:160  Batch:2/9  loss:0.086625\n",
      "Epoch:160  Batch:3/9  loss:0.091225\n",
      "Epoch:160  Batch:4/9  loss:0.082551\n",
      "Epoch:160  Batch:5/9  loss:0.073000\n",
      "Epoch:160  Batch:6/9  loss:0.069511\n",
      "Epoch:160  Batch:7/9  loss:0.067202\n",
      "Epoch:160  Batch:8/9  loss:0.079030\n",
      "Epoch:160  Batch:9/9  loss:0.065248\n",
      "ACC: 0.9689963\n",
      "TPR: 0.7407324\n",
      "FPR: 0.011704197\n",
      "SN: 0.988296\n",
      "SP: 0.7407324\n",
      "start train epoch: 161\n",
      "Epoch:161  Batch:1/9  loss:0.078415\n",
      "Epoch:161  Batch:2/9  loss:0.077283\n",
      "Epoch:161  Batch:3/9  loss:0.085865\n",
      "Epoch:161  Batch:4/9  loss:0.073374\n",
      "Epoch:161  Batch:5/9  loss:0.079308\n",
      "Epoch:161  Batch:6/9  loss:0.076493\n",
      "Epoch:161  Batch:7/9  loss:0.085427\n",
      "Epoch:161  Batch:8/9  loss:0.079354\n",
      "Epoch:161  Batch:9/9  loss:0.107113\n",
      "start train epoch: 162\n",
      "Epoch:162  Batch:1/9  loss:0.061667\n",
      "Epoch:162  Batch:2/9  loss:0.094117\n",
      "Epoch:162  Batch:3/9  loss:0.080599\n",
      "Epoch:162  Batch:4/9  loss:0.065703\n",
      "Epoch:162  Batch:5/9  loss:0.091456\n",
      "Epoch:162  Batch:6/9  loss:0.087329\n",
      "Epoch:162  Batch:7/9  loss:0.073909\n",
      "Epoch:162  Batch:8/9  loss:0.088479\n",
      "Epoch:162  Batch:9/9  loss:0.069092\n",
      "start train epoch: 163\n",
      "Epoch:163  Batch:1/9  loss:0.078304\n",
      "Epoch:163  Batch:2/9  loss:0.074284\n",
      "Epoch:163  Batch:3/9  loss:0.081479\n",
      "Epoch:163  Batch:4/9  loss:0.076612\n",
      "Epoch:163  Batch:5/9  loss:0.079504\n",
      "Epoch:163  Batch:6/9  loss:0.084947\n",
      "Epoch:163  Batch:7/9  loss:0.084270\n",
      "Epoch:163  Batch:8/9  loss:0.079667\n",
      "Epoch:163  Batch:9/9  loss:0.054078\n",
      "start train epoch: 164\n",
      "Epoch:164  Batch:1/9  loss:0.068324\n",
      "Epoch:164  Batch:2/9  loss:0.071167\n",
      "Epoch:164  Batch:3/9  loss:0.095758\n",
      "Epoch:164  Batch:4/9  loss:0.079312\n",
      "Epoch:164  Batch:5/9  loss:0.094680\n",
      "Epoch:164  Batch:6/9  loss:0.072432\n",
      "Epoch:164  Batch:7/9  loss:0.079946\n",
      "Epoch:164  Batch:8/9  loss:0.077595\n",
      "Epoch:164  Batch:9/9  loss:0.114007\n",
      "start train epoch: 165\n",
      "Epoch:165  Batch:1/9  loss:0.085117\n",
      "Epoch:165  Batch:2/9  loss:0.068436\n",
      "Epoch:165  Batch:3/9  loss:0.076214\n",
      "Epoch:165  Batch:4/9  loss:0.079175\n",
      "Epoch:165  Batch:5/9  loss:0.090242\n",
      "Epoch:165  Batch:6/9  loss:0.088193\n",
      "Epoch:165  Batch:7/9  loss:0.082668\n",
      "Epoch:165  Batch:8/9  loss:0.083966\n",
      "Epoch:165  Batch:9/9  loss:0.100804\n",
      "start train epoch: 166\n",
      "Epoch:166  Batch:1/9  loss:0.087721\n",
      "Epoch:166  Batch:2/9  loss:0.073615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:166  Batch:3/9  loss:0.087798\n",
      "Epoch:166  Batch:4/9  loss:0.082706\n",
      "Epoch:166  Batch:5/9  loss:0.072191\n",
      "Epoch:166  Batch:6/9  loss:0.069334\n",
      "Epoch:166  Batch:7/9  loss:0.084032\n",
      "Epoch:166  Batch:8/9  loss:0.075531\n",
      "Epoch:166  Batch:9/9  loss:0.100774\n",
      "start train epoch: 167\n",
      "Epoch:167  Batch:1/9  loss:0.080046\n",
      "Epoch:167  Batch:2/9  loss:0.082753\n",
      "Epoch:167  Batch:3/9  loss:0.091095\n",
      "Epoch:167  Batch:4/9  loss:0.078928\n",
      "Epoch:167  Batch:5/9  loss:0.072583\n",
      "Epoch:167  Batch:6/9  loss:0.069982\n",
      "Epoch:167  Batch:7/9  loss:0.080922\n",
      "Epoch:167  Batch:8/9  loss:0.072154\n",
      "Epoch:167  Batch:9/9  loss:0.076963\n",
      "start train epoch: 168\n",
      "Epoch:168  Batch:1/9  loss:0.087409\n",
      "Epoch:168  Batch:2/9  loss:0.069240\n",
      "Epoch:168  Batch:3/9  loss:0.082476\n",
      "Epoch:168  Batch:4/9  loss:0.069265\n",
      "Epoch:168  Batch:5/9  loss:0.090639\n",
      "Epoch:168  Batch:6/9  loss:0.065369\n",
      "Epoch:168  Batch:7/9  loss:0.077320\n",
      "Epoch:168  Batch:8/9  loss:0.084104\n",
      "Epoch:168  Batch:9/9  loss:0.105860\n",
      "start train epoch: 169\n",
      "Epoch:169  Batch:1/9  loss:0.072931\n",
      "Epoch:169  Batch:2/9  loss:0.079636\n",
      "Epoch:169  Batch:3/9  loss:0.079947\n",
      "Epoch:169  Batch:4/9  loss:0.080322\n",
      "Epoch:169  Batch:5/9  loss:0.080747\n",
      "Epoch:169  Batch:6/9  loss:0.082422\n",
      "Epoch:169  Batch:7/9  loss:0.072787\n",
      "Epoch:169  Batch:8/9  loss:0.090166\n",
      "Epoch:169  Batch:9/9  loss:0.115721\n",
      "start train epoch: 170\n",
      "Epoch:170  Batch:1/9  loss:0.081188\n",
      "Epoch:170  Batch:2/9  loss:0.081178\n",
      "Epoch:170  Batch:3/9  loss:0.074430\n",
      "Epoch:170  Batch:4/9  loss:0.080179\n",
      "Epoch:170  Batch:5/9  loss:0.088708\n",
      "Epoch:170  Batch:6/9  loss:0.085913\n",
      "Epoch:170  Batch:7/9  loss:0.081632\n",
      "Epoch:170  Batch:8/9  loss:0.076804\n",
      "Epoch:170  Batch:9/9  loss:0.078769\n",
      "ACC: 0.9684868\n",
      "TPR: 0.7511226\n",
      "FPR: 0.013030551\n",
      "SN: 0.98696935\n",
      "SP: 0.7511226\n",
      "start train epoch: 171\n",
      "Epoch:171  Batch:1/9  loss:0.076600\n",
      "Epoch:171  Batch:2/9  loss:0.073701\n",
      "Epoch:171  Batch:3/9  loss:0.070293\n",
      "Epoch:171  Batch:4/9  loss:0.078843\n",
      "Epoch:171  Batch:5/9  loss:0.086733\n",
      "Epoch:171  Batch:6/9  loss:0.081166\n",
      "Epoch:171  Batch:7/9  loss:0.074244\n",
      "Epoch:171  Batch:8/9  loss:0.084272\n",
      "Epoch:171  Batch:9/9  loss:0.110950\n",
      "start train epoch: 172\n",
      "Epoch:172  Batch:1/9  loss:0.083929\n",
      "Epoch:172  Batch:2/9  loss:0.075761\n",
      "Epoch:172  Batch:3/9  loss:0.073885\n",
      "Epoch:172  Batch:4/9  loss:0.083478\n",
      "Epoch:172  Batch:5/9  loss:0.073837\n",
      "Epoch:172  Batch:6/9  loss:0.078828\n",
      "Epoch:172  Batch:7/9  loss:0.092192\n",
      "Epoch:172  Batch:8/9  loss:0.078354\n",
      "Epoch:172  Batch:9/9  loss:0.066277\n",
      "start train epoch: 173\n",
      "Epoch:173  Batch:1/9  loss:0.077309\n",
      "Epoch:173  Batch:2/9  loss:0.066628\n",
      "Epoch:173  Batch:3/9  loss:0.081317\n",
      "Epoch:173  Batch:4/9  loss:0.087083\n",
      "Epoch:173  Batch:5/9  loss:0.082068\n",
      "Epoch:173  Batch:6/9  loss:0.095473\n",
      "Epoch:173  Batch:7/9  loss:0.095153\n",
      "Epoch:173  Batch:8/9  loss:0.068621\n",
      "Epoch:173  Batch:9/9  loss:0.088310\n",
      "start train epoch: 174\n",
      "Epoch:174  Batch:1/9  loss:0.082863\n",
      "Epoch:174  Batch:2/9  loss:0.074076\n",
      "Epoch:174  Batch:3/9  loss:0.083538\n",
      "Epoch:174  Batch:4/9  loss:0.092997\n",
      "Epoch:174  Batch:5/9  loss:0.073383\n",
      "Epoch:174  Batch:6/9  loss:0.075618\n",
      "Epoch:174  Batch:7/9  loss:0.069173\n",
      "Epoch:174  Batch:8/9  loss:0.076426\n",
      "Epoch:174  Batch:9/9  loss:0.088286\n",
      "start train epoch: 175\n",
      "Epoch:175  Batch:1/9  loss:0.074987\n",
      "Epoch:175  Batch:2/9  loss:0.079074\n",
      "Epoch:175  Batch:3/9  loss:0.072203\n",
      "Epoch:175  Batch:4/9  loss:0.078354\n",
      "Epoch:175  Batch:5/9  loss:0.084503\n",
      "Epoch:175  Batch:6/9  loss:0.078902\n",
      "Epoch:175  Batch:7/9  loss:0.071434\n",
      "Epoch:175  Batch:8/9  loss:0.084111\n",
      "Epoch:175  Batch:9/9  loss:0.078798\n",
      "start train epoch: 176\n",
      "Epoch:176  Batch:1/9  loss:0.071785\n",
      "Epoch:176  Batch:2/9  loss:0.073969\n",
      "Epoch:176  Batch:3/9  loss:0.077234\n",
      "Epoch:176  Batch:4/9  loss:0.082847\n",
      "Epoch:176  Batch:5/9  loss:0.069159\n",
      "Epoch:176  Batch:6/9  loss:0.080284\n",
      "Epoch:176  Batch:7/9  loss:0.074858\n",
      "Epoch:176  Batch:8/9  loss:0.091487\n",
      "Epoch:176  Batch:9/9  loss:0.061041\n",
      "start train epoch: 177\n",
      "Epoch:177  Batch:1/9  loss:0.071246\n",
      "Epoch:177  Batch:2/9  loss:0.092044\n",
      "Epoch:177  Batch:3/9  loss:0.080341\n",
      "Epoch:177  Batch:4/9  loss:0.077532\n",
      "Epoch:177  Batch:5/9  loss:0.081435\n",
      "Epoch:177  Batch:6/9  loss:0.077272\n",
      "Epoch:177  Batch:7/9  loss:0.066850\n",
      "Epoch:177  Batch:8/9  loss:0.081942\n",
      "Epoch:177  Batch:9/9  loss:0.100735\n",
      "start train epoch: 178\n",
      "Epoch:178  Batch:1/9  loss:0.084407\n",
      "Epoch:178  Batch:2/9  loss:0.077831\n",
      "Epoch:178  Batch:3/9  loss:0.073383\n",
      "Epoch:178  Batch:4/9  loss:0.101325\n",
      "Epoch:178  Batch:5/9  loss:0.074395\n",
      "Epoch:178  Batch:6/9  loss:0.079231\n",
      "Epoch:178  Batch:7/9  loss:0.081341\n",
      "Epoch:178  Batch:8/9  loss:0.073005\n",
      "Epoch:178  Batch:9/9  loss:0.066768\n",
      "start train epoch: 179\n",
      "Epoch:179  Batch:1/9  loss:0.077979\n",
      "Epoch:179  Batch:2/9  loss:0.082869\n",
      "Epoch:179  Batch:3/9  loss:0.076211\n",
      "Epoch:179  Batch:4/9  loss:0.082707\n",
      "Epoch:179  Batch:5/9  loss:0.070717\n",
      "Epoch:179  Batch:6/9  loss:0.073384\n",
      "Epoch:179  Batch:7/9  loss:0.082235\n",
      "Epoch:179  Batch:8/9  loss:0.071441\n",
      "Epoch:179  Batch:9/9  loss:0.089845\n",
      "start train epoch: 180\n",
      "Epoch:180  Batch:1/9  loss:0.067735\n",
      "Epoch:180  Batch:2/9  loss:0.074076\n",
      "Epoch:180  Batch:3/9  loss:0.071958\n",
      "Epoch:180  Batch:4/9  loss:0.072635\n",
      "Epoch:180  Batch:5/9  loss:0.080895\n",
      "Epoch:180  Batch:6/9  loss:0.080295\n",
      "Epoch:180  Batch:7/9  loss:0.080132\n",
      "Epoch:180  Batch:8/9  loss:0.085974\n",
      "Epoch:180  Batch:9/9  loss:0.079930\n",
      "ACC: 0.968119\n",
      "TPR: 0.7913213\n",
      "FPR: 0.016775701\n",
      "SN: 0.9832242\n",
      "SP: 0.7913213\n",
      "start train epoch: 181\n",
      "Epoch:181  Batch:1/9  loss:0.080621\n",
      "Epoch:181  Batch:2/9  loss:0.086408\n",
      "Epoch:181  Batch:3/9  loss:0.091621\n",
      "Epoch:181  Batch:4/9  loss:0.072418\n",
      "Epoch:181  Batch:5/9  loss:0.067402\n",
      "Epoch:181  Batch:6/9  loss:0.075633\n",
      "Epoch:181  Batch:7/9  loss:0.078515\n",
      "Epoch:181  Batch:8/9  loss:0.077201\n",
      "Epoch:181  Batch:9/9  loss:0.074740\n",
      "start train epoch: 182\n",
      "Epoch:182  Batch:1/9  loss:0.076370\n",
      "Epoch:182  Batch:2/9  loss:0.082754\n",
      "Epoch:182  Batch:3/9  loss:0.094067\n",
      "Epoch:182  Batch:4/9  loss:0.066987\n",
      "Epoch:182  Batch:5/9  loss:0.079084\n",
      "Epoch:182  Batch:6/9  loss:0.070512\n",
      "Epoch:182  Batch:7/9  loss:0.085923\n",
      "Epoch:182  Batch:8/9  loss:0.073783\n",
      "Epoch:182  Batch:9/9  loss:0.083456\n",
      "start train epoch: 183\n",
      "Epoch:183  Batch:1/9  loss:0.075257\n",
      "Epoch:183  Batch:2/9  loss:0.069680\n",
      "Epoch:183  Batch:3/9  loss:0.075724\n",
      "Epoch:183  Batch:4/9  loss:0.073861\n",
      "Epoch:183  Batch:5/9  loss:0.076165\n",
      "Epoch:183  Batch:6/9  loss:0.083277\n",
      "Epoch:183  Batch:7/9  loss:0.080438\n",
      "Epoch:183  Batch:8/9  loss:0.087355\n",
      "Epoch:183  Batch:9/9  loss:0.095878\n",
      "start train epoch: 184\n",
      "Epoch:184  Batch:1/9  loss:0.067713\n",
      "Epoch:184  Batch:2/9  loss:0.079551\n",
      "Epoch:184  Batch:3/9  loss:0.103013\n",
      "Epoch:184  Batch:4/9  loss:0.070793\n",
      "Epoch:184  Batch:5/9  loss:0.078892\n",
      "Epoch:184  Batch:6/9  loss:0.080922\n",
      "Epoch:184  Batch:7/9  loss:0.092523\n",
      "Epoch:184  Batch:8/9  loss:0.076387\n",
      "Epoch:184  Batch:9/9  loss:0.064242\n",
      "start train epoch: 185\n",
      "Epoch:185  Batch:1/9  loss:0.080216\n",
      "Epoch:185  Batch:2/9  loss:0.071641\n",
      "Epoch:185  Batch:3/9  loss:0.074799\n",
      "Epoch:185  Batch:4/9  loss:0.079933\n",
      "Epoch:185  Batch:5/9  loss:0.081203\n",
      "Epoch:185  Batch:6/9  loss:0.080076\n",
      "Epoch:185  Batch:7/9  loss:0.078204\n",
      "Epoch:185  Batch:8/9  loss:0.095374\n",
      "Epoch:185  Batch:9/9  loss:0.082985\n",
      "start train epoch: 186\n",
      "Epoch:186  Batch:1/9  loss:0.078752\n",
      "Epoch:186  Batch:2/9  loss:0.071893\n",
      "Epoch:186  Batch:3/9  loss:0.084940\n",
      "Epoch:186  Batch:4/9  loss:0.073032\n",
      "Epoch:186  Batch:5/9  loss:0.074715\n",
      "Epoch:186  Batch:6/9  loss:0.087484\n",
      "Epoch:186  Batch:7/9  loss:0.082864\n",
      "Epoch:186  Batch:8/9  loss:0.072031\n",
      "Epoch:186  Batch:9/9  loss:0.075924\n",
      "start train epoch: 187\n",
      "Epoch:187  Batch:1/9  loss:0.075953\n",
      "Epoch:187  Batch:2/9  loss:0.080463\n",
      "Epoch:187  Batch:3/9  loss:0.073999\n",
      "Epoch:187  Batch:4/9  loss:0.074588\n",
      "Epoch:187  Batch:5/9  loss:0.071781\n",
      "Epoch:187  Batch:6/9  loss:0.087201\n",
      "Epoch:187  Batch:7/9  loss:0.071085\n",
      "Epoch:187  Batch:8/9  loss:0.085214\n",
      "Epoch:187  Batch:9/9  loss:0.096307\n",
      "start train epoch: 188\n",
      "Epoch:188  Batch:1/9  loss:0.076702\n",
      "Epoch:188  Batch:2/9  loss:0.081005\n",
      "Epoch:188  Batch:3/9  loss:0.085026\n",
      "Epoch:188  Batch:4/9  loss:0.090521\n",
      "Epoch:188  Batch:5/9  loss:0.087952\n",
      "Epoch:188  Batch:6/9  loss:0.074755\n",
      "Epoch:188  Batch:7/9  loss:0.072356\n",
      "Epoch:188  Batch:8/9  loss:0.083390\n",
      "Epoch:188  Batch:9/9  loss:0.071348\n",
      "start train epoch: 189\n",
      "Epoch:189  Batch:1/9  loss:0.083712\n",
      "Epoch:189  Batch:2/9  loss:0.072020\n",
      "Epoch:189  Batch:3/9  loss:0.092304\n",
      "Epoch:189  Batch:4/9  loss:0.085611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:189  Batch:5/9  loss:0.067170\n",
      "Epoch:189  Batch:6/9  loss:0.079987\n",
      "Epoch:189  Batch:7/9  loss:0.073295\n",
      "Epoch:189  Batch:8/9  loss:0.080384\n",
      "Epoch:189  Batch:9/9  loss:0.062071\n",
      "start train epoch: 190\n",
      "Epoch:190  Batch:1/9  loss:0.078734\n",
      "Epoch:190  Batch:2/9  loss:0.073638\n",
      "Epoch:190  Batch:3/9  loss:0.070112\n",
      "Epoch:190  Batch:4/9  loss:0.077852\n",
      "Epoch:190  Batch:5/9  loss:0.091446\n",
      "Epoch:190  Batch:6/9  loss:0.087184\n",
      "Epoch:190  Batch:7/9  loss:0.082166\n",
      "Epoch:190  Batch:8/9  loss:0.073054\n",
      "Epoch:190  Batch:9/9  loss:0.056784\n",
      "ACC: 0.9692036\n",
      "TPR: 0.75650656\n",
      "FPR: 0.012680797\n",
      "SN: 0.9873193\n",
      "SP: 0.75650656\n",
      "start train epoch: 191\n",
      "Epoch:191  Batch:1/9  loss:0.079198\n",
      "Epoch:191  Batch:2/9  loss:0.079903\n",
      "Epoch:191  Batch:3/9  loss:0.074593\n",
      "Epoch:191  Batch:4/9  loss:0.074650\n",
      "Epoch:191  Batch:5/9  loss:0.082512\n",
      "Epoch:191  Batch:6/9  loss:0.071963\n",
      "Epoch:191  Batch:7/9  loss:0.073946\n",
      "Epoch:191  Batch:8/9  loss:0.092152\n",
      "Epoch:191  Batch:9/9  loss:0.065124\n",
      "start train epoch: 192\n",
      "Epoch:192  Batch:1/9  loss:0.077558\n",
      "Epoch:192  Batch:2/9  loss:0.066333\n",
      "Epoch:192  Batch:3/9  loss:0.076594\n",
      "Epoch:192  Batch:4/9  loss:0.073362\n",
      "Epoch:192  Batch:5/9  loss:0.080249\n",
      "Epoch:192  Batch:6/9  loss:0.086036\n",
      "Epoch:192  Batch:7/9  loss:0.076786\n",
      "Epoch:192  Batch:8/9  loss:0.074112\n",
      "Epoch:192  Batch:9/9  loss:0.078087\n",
      "start train epoch: 193\n",
      "Epoch:193  Batch:1/9  loss:0.077212\n",
      "Epoch:193  Batch:2/9  loss:0.078157\n",
      "Epoch:193  Batch:3/9  loss:0.072630\n",
      "Epoch:193  Batch:4/9  loss:0.081749\n",
      "Epoch:193  Batch:5/9  loss:0.076434\n",
      "Epoch:193  Batch:6/9  loss:0.085431\n",
      "Epoch:193  Batch:7/9  loss:0.082869\n",
      "Epoch:193  Batch:8/9  loss:0.072640\n",
      "Epoch:193  Batch:9/9  loss:0.117215\n",
      "start train epoch: 194\n",
      "Epoch:194  Batch:1/9  loss:0.077320\n",
      "Epoch:194  Batch:2/9  loss:0.079357\n",
      "Epoch:194  Batch:3/9  loss:0.074511\n",
      "Epoch:194  Batch:4/9  loss:0.077422\n",
      "Epoch:194  Batch:5/9  loss:0.083662\n",
      "Epoch:194  Batch:6/9  loss:0.075879\n",
      "Epoch:194  Batch:7/9  loss:0.069716\n",
      "Epoch:194  Batch:8/9  loss:0.085491\n",
      "Epoch:194  Batch:9/9  loss:0.054740\n",
      "start train epoch: 195\n",
      "Epoch:195  Batch:1/9  loss:0.088047\n",
      "Epoch:195  Batch:2/9  loss:0.078674\n",
      "Epoch:195  Batch:3/9  loss:0.070269\n",
      "Epoch:195  Batch:4/9  loss:0.076062\n",
      "Epoch:195  Batch:5/9  loss:0.084967\n",
      "Epoch:195  Batch:6/9  loss:0.084091\n",
      "Epoch:195  Batch:7/9  loss:0.078230\n",
      "Epoch:195  Batch:8/9  loss:0.081922\n",
      "Epoch:195  Batch:9/9  loss:0.062957\n",
      "start train epoch: 196\n",
      "Epoch:196  Batch:1/9  loss:0.075558\n",
      "Epoch:196  Batch:2/9  loss:0.081096\n",
      "Epoch:196  Batch:3/9  loss:0.077729\n",
      "Epoch:196  Batch:4/9  loss:0.074202\n",
      "Epoch:196  Batch:5/9  loss:0.080485\n",
      "Epoch:196  Batch:6/9  loss:0.072618\n",
      "Epoch:196  Batch:7/9  loss:0.080409\n",
      "Epoch:196  Batch:8/9  loss:0.075448\n",
      "Epoch:196  Batch:9/9  loss:0.104856\n",
      "start train epoch: 197\n",
      "Epoch:197  Batch:1/9  loss:0.091616\n",
      "Epoch:197  Batch:2/9  loss:0.080695\n",
      "Epoch:197  Batch:3/9  loss:0.070095\n",
      "Epoch:197  Batch:4/9  loss:0.079511\n",
      "Epoch:197  Batch:5/9  loss:0.078174\n",
      "Epoch:197  Batch:6/9  loss:0.071689\n",
      "Epoch:197  Batch:7/9  loss:0.077343\n",
      "Epoch:197  Batch:8/9  loss:0.082852\n",
      "Epoch:197  Batch:9/9  loss:0.094305\n",
      "start train epoch: 198\n",
      "Epoch:198  Batch:1/9  loss:0.076358\n",
      "Epoch:198  Batch:2/9  loss:0.088495\n",
      "Epoch:198  Batch:3/9  loss:0.078889\n",
      "Epoch:198  Batch:4/9  loss:0.076855\n",
      "Epoch:198  Batch:5/9  loss:0.075949\n",
      "Epoch:198  Batch:6/9  loss:0.080799\n",
      "Epoch:198  Batch:7/9  loss:0.088801\n",
      "Epoch:198  Batch:8/9  loss:0.066940\n",
      "Epoch:198  Batch:9/9  loss:0.098655\n",
      "start train epoch: 199\n",
      "Epoch:199  Batch:1/9  loss:0.070836\n",
      "Epoch:199  Batch:2/9  loss:0.074539\n",
      "Epoch:199  Batch:3/9  loss:0.077832\n",
      "Epoch:199  Batch:4/9  loss:0.090170\n",
      "Epoch:199  Batch:5/9  loss:0.077297\n",
      "Epoch:199  Batch:6/9  loss:0.078429\n",
      "Epoch:199  Batch:7/9  loss:0.075848\n",
      "Epoch:199  Batch:8/9  loss:0.078295\n",
      "Epoch:199  Batch:9/9  loss:0.090850\n",
      "start train epoch: 200\n",
      "Epoch:200  Batch:1/9  loss:0.070782\n",
      "Epoch:200  Batch:2/9  loss:0.087023\n",
      "Epoch:200  Batch:3/9  loss:0.067075\n",
      "Epoch:200  Batch:4/9  loss:0.071009\n",
      "Epoch:200  Batch:5/9  loss:0.080044\n",
      "Epoch:200  Batch:6/9  loss:0.078910\n",
      "Epoch:200  Batch:7/9  loss:0.085524\n",
      "Epoch:200  Batch:8/9  loss:0.079434\n",
      "Epoch:200  Batch:9/9  loss:0.108048\n",
      "ACC: 0.9687729\n",
      "TPR: 0.76684546\n",
      "FPR: 0.01408904\n",
      "SN: 0.9859111\n",
      "SP: 0.76684546\n",
      "start train epoch: 201\n",
      "Epoch:201  Batch:1/9  loss:0.082012\n",
      "Epoch:201  Batch:2/9  loss:0.076702\n",
      "Epoch:201  Batch:3/9  loss:0.083781\n",
      "Epoch:201  Batch:4/9  loss:0.078266\n",
      "Epoch:201  Batch:5/9  loss:0.076799\n",
      "Epoch:201  Batch:6/9  loss:0.080166\n",
      "Epoch:201  Batch:7/9  loss:0.067949\n",
      "Epoch:201  Batch:8/9  loss:0.077188\n",
      "Epoch:201  Batch:9/9  loss:0.057474\n",
      "start train epoch: 202\n",
      "Epoch:202  Batch:1/9  loss:0.089735\n",
      "Epoch:202  Batch:2/9  loss:0.062176\n",
      "Epoch:202  Batch:3/9  loss:0.078803\n",
      "Epoch:202  Batch:4/9  loss:0.076667\n",
      "Epoch:202  Batch:5/9  loss:0.074932\n",
      "Epoch:202  Batch:6/9  loss:0.080767\n",
      "Epoch:202  Batch:7/9  loss:0.077965\n",
      "Epoch:202  Batch:8/9  loss:0.065981\n",
      "Epoch:202  Batch:9/9  loss:0.087529\n",
      "start train epoch: 203\n",
      "Epoch:203  Batch:1/9  loss:0.072231\n",
      "Epoch:203  Batch:2/9  loss:0.078305\n",
      "Epoch:203  Batch:3/9  loss:0.081824\n",
      "Epoch:203  Batch:4/9  loss:0.080096\n",
      "Epoch:203  Batch:5/9  loss:0.071165\n",
      "Epoch:203  Batch:6/9  loss:0.083849\n",
      "Epoch:203  Batch:7/9  loss:0.074283\n",
      "Epoch:203  Batch:8/9  loss:0.067944\n",
      "Epoch:203  Batch:9/9  loss:0.093793\n",
      "start train epoch: 204\n",
      "Epoch:204  Batch:1/9  loss:0.083600\n",
      "Epoch:204  Batch:2/9  loss:0.068762\n",
      "Epoch:204  Batch:3/9  loss:0.073059\n",
      "Epoch:204  Batch:4/9  loss:0.079175\n",
      "Epoch:204  Batch:5/9  loss:0.084353\n",
      "Epoch:204  Batch:6/9  loss:0.085502\n",
      "Epoch:204  Batch:7/9  loss:0.067136\n",
      "Epoch:204  Batch:8/9  loss:0.074182\n",
      "Epoch:204  Batch:9/9  loss:0.065053\n",
      "start train epoch: 205\n",
      "Epoch:205  Batch:1/9  loss:0.085195\n",
      "Epoch:205  Batch:2/9  loss:0.082318\n",
      "Epoch:205  Batch:3/9  loss:0.090057\n",
      "Epoch:205  Batch:4/9  loss:0.069452\n",
      "Epoch:205  Batch:5/9  loss:0.078045\n",
      "Epoch:205  Batch:6/9  loss:0.081771\n",
      "Epoch:205  Batch:7/9  loss:0.069267\n",
      "Epoch:205  Batch:8/9  loss:0.066704\n",
      "Epoch:205  Batch:9/9  loss:0.071841\n",
      "start train epoch: 206\n",
      "Epoch:206  Batch:1/9  loss:0.078382\n",
      "Epoch:206  Batch:2/9  loss:0.089855\n",
      "Epoch:206  Batch:3/9  loss:0.065517\n",
      "Epoch:206  Batch:4/9  loss:0.077713\n",
      "Epoch:206  Batch:5/9  loss:0.070709\n",
      "Epoch:206  Batch:6/9  loss:0.082932\n",
      "Epoch:206  Batch:7/9  loss:0.073038\n",
      "Epoch:206  Batch:8/9  loss:0.082434\n",
      "Epoch:206  Batch:9/9  loss:0.080531\n",
      "start train epoch: 207\n",
      "Epoch:207  Batch:1/9  loss:0.079216\n",
      "Epoch:207  Batch:2/9  loss:0.082552\n",
      "Epoch:207  Batch:3/9  loss:0.071921\n",
      "Epoch:207  Batch:4/9  loss:0.091640\n",
      "Epoch:207  Batch:5/9  loss:0.071483\n",
      "Epoch:207  Batch:6/9  loss:0.070467\n",
      "Epoch:207  Batch:7/9  loss:0.071473\n",
      "Epoch:207  Batch:8/9  loss:0.076337\n",
      "Epoch:207  Batch:9/9  loss:0.082422\n",
      "start train epoch: 208\n",
      "Epoch:208  Batch:1/9  loss:0.073484\n",
      "Epoch:208  Batch:2/9  loss:0.099409\n",
      "Epoch:208  Batch:3/9  loss:0.078385\n",
      "Epoch:208  Batch:4/9  loss:0.082525\n",
      "Epoch:208  Batch:5/9  loss:0.072899\n",
      "Epoch:208  Batch:6/9  loss:0.083961\n",
      "Epoch:208  Batch:7/9  loss:0.072545\n",
      "Epoch:208  Batch:8/9  loss:0.068005\n",
      "Epoch:208  Batch:9/9  loss:0.056577\n",
      "start train epoch: 209\n",
      "Epoch:209  Batch:1/9  loss:0.068151\n",
      "Epoch:209  Batch:2/9  loss:0.081550\n",
      "Epoch:209  Batch:3/9  loss:0.077450\n",
      "Epoch:209  Batch:4/9  loss:0.074733\n",
      "Epoch:209  Batch:5/9  loss:0.079667\n",
      "Epoch:209  Batch:6/9  loss:0.082898\n",
      "Epoch:209  Batch:7/9  loss:0.086501\n",
      "Epoch:209  Batch:8/9  loss:0.072442\n",
      "Epoch:209  Batch:9/9  loss:0.078444\n",
      "start train epoch: 210\n",
      "Epoch:210  Batch:1/9  loss:0.083887\n",
      "Epoch:210  Batch:2/9  loss:0.071267\n",
      "Epoch:210  Batch:3/9  loss:0.085524\n",
      "Epoch:210  Batch:4/9  loss:0.076610\n",
      "Epoch:210  Batch:5/9  loss:0.076403\n",
      "Epoch:210  Batch:6/9  loss:0.075507\n",
      "Epoch:210  Batch:7/9  loss:0.075410\n",
      "Epoch:210  Batch:8/9  loss:0.075810\n",
      "Epoch:210  Batch:9/9  loss:0.090726\n",
      "ACC: 0.9688202\n",
      "TPR: 0.726174\n",
      "FPR: 0.0105269775\n",
      "SN: 0.9894732\n",
      "SP: 0.726174\n",
      "start train epoch: 211\n",
      "Epoch:211  Batch:1/9  loss:0.074449\n",
      "Epoch:211  Batch:2/9  loss:0.073360\n",
      "Epoch:211  Batch:3/9  loss:0.078508\n",
      "Epoch:211  Batch:4/9  loss:0.076093\n",
      "Epoch:211  Batch:5/9  loss:0.081690\n",
      "Epoch:211  Batch:6/9  loss:0.088847\n",
      "Epoch:211  Batch:7/9  loss:0.078887\n",
      "Epoch:211  Batch:8/9  loss:0.078392\n",
      "Epoch:211  Batch:9/9  loss:0.058788\n",
      "start train epoch: 212\n",
      "Epoch:212  Batch:1/9  loss:0.076235\n",
      "Epoch:212  Batch:2/9  loss:0.082353\n",
      "Epoch:212  Batch:3/9  loss:0.087253\n",
      "Epoch:212  Batch:4/9  loss:0.077002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:212  Batch:5/9  loss:0.082404\n",
      "Epoch:212  Batch:6/9  loss:0.079549\n",
      "Epoch:212  Batch:7/9  loss:0.064476\n",
      "Epoch:212  Batch:8/9  loss:0.074412\n",
      "Epoch:212  Batch:9/9  loss:0.054720\n",
      "start train epoch: 213\n",
      "Epoch:213  Batch:1/9  loss:0.074766\n",
      "Epoch:213  Batch:2/9  loss:0.079178\n",
      "Epoch:213  Batch:3/9  loss:0.076699\n",
      "Epoch:213  Batch:4/9  loss:0.079369\n",
      "Epoch:213  Batch:5/9  loss:0.072208\n",
      "Epoch:213  Batch:6/9  loss:0.075788\n",
      "Epoch:213  Batch:7/9  loss:0.079208\n",
      "Epoch:213  Batch:8/9  loss:0.072852\n",
      "Epoch:213  Batch:9/9  loss:0.062035\n",
      "start train epoch: 214\n",
      "Epoch:214  Batch:1/9  loss:0.077270\n",
      "Epoch:214  Batch:2/9  loss:0.080988\n",
      "Epoch:214  Batch:3/9  loss:0.065095\n",
      "Epoch:214  Batch:4/9  loss:0.078277\n",
      "Epoch:214  Batch:5/9  loss:0.074511\n",
      "Epoch:214  Batch:6/9  loss:0.083616\n",
      "Epoch:214  Batch:7/9  loss:0.077787\n",
      "Epoch:214  Batch:8/9  loss:0.077298\n",
      "Epoch:214  Batch:9/9  loss:0.094596\n",
      "start train epoch: 215\n",
      "Epoch:215  Batch:1/9  loss:0.080009\n",
      "Epoch:215  Batch:2/9  loss:0.082570\n",
      "Epoch:215  Batch:3/9  loss:0.065292\n",
      "Epoch:215  Batch:4/9  loss:0.075795\n",
      "Epoch:215  Batch:5/9  loss:0.075512\n",
      "Epoch:215  Batch:6/9  loss:0.081900\n",
      "Epoch:215  Batch:7/9  loss:0.074846\n",
      "Epoch:215  Batch:8/9  loss:0.069912\n",
      "Epoch:215  Batch:9/9  loss:0.071496\n",
      "start train epoch: 216\n",
      "Epoch:216  Batch:1/9  loss:0.088052\n",
      "Epoch:216  Batch:2/9  loss:0.085268\n",
      "Epoch:216  Batch:3/9  loss:0.070723\n",
      "Epoch:216  Batch:4/9  loss:0.073248\n",
      "Epoch:216  Batch:5/9  loss:0.069361\n",
      "Epoch:216  Batch:6/9  loss:0.073954\n",
      "Epoch:216  Batch:7/9  loss:0.074128\n",
      "Epoch:216  Batch:8/9  loss:0.071215\n",
      "Epoch:216  Batch:9/9  loss:0.074121\n",
      "start train epoch: 217\n",
      "Epoch:217  Batch:1/9  loss:0.085843\n",
      "Epoch:217  Batch:2/9  loss:0.064567\n",
      "Epoch:217  Batch:3/9  loss:0.087049\n",
      "Epoch:217  Batch:4/9  loss:0.070963\n",
      "Epoch:217  Batch:5/9  loss:0.074981\n",
      "Epoch:217  Batch:6/9  loss:0.073756\n",
      "Epoch:217  Batch:7/9  loss:0.071626\n",
      "Epoch:217  Batch:8/9  loss:0.075348\n",
      "Epoch:217  Batch:9/9  loss:0.079474\n",
      "start train epoch: 218\n",
      "Epoch:218  Batch:1/9  loss:0.071894\n",
      "Epoch:218  Batch:2/9  loss:0.084661\n",
      "Epoch:218  Batch:3/9  loss:0.080615\n",
      "Epoch:218  Batch:4/9  loss:0.081719\n",
      "Epoch:218  Batch:5/9  loss:0.061437\n",
      "Epoch:218  Batch:6/9  loss:0.085095\n",
      "Epoch:218  Batch:7/9  loss:0.078707\n",
      "Epoch:218  Batch:8/9  loss:0.064936\n",
      "Epoch:218  Batch:9/9  loss:0.120849\n",
      "start train epoch: 219\n",
      "Epoch:219  Batch:1/9  loss:0.075315\n",
      "Epoch:219  Batch:2/9  loss:0.067521\n",
      "Epoch:219  Batch:3/9  loss:0.080113\n",
      "Epoch:219  Batch:4/9  loss:0.077354\n",
      "Epoch:219  Batch:5/9  loss:0.072922\n",
      "Epoch:219  Batch:6/9  loss:0.073834\n",
      "Epoch:219  Batch:7/9  loss:0.075341\n",
      "Epoch:219  Batch:8/9  loss:0.087292\n",
      "Epoch:219  Batch:9/9  loss:0.052260\n",
      "start train epoch: 220\n",
      "Epoch:220  Batch:1/9  loss:0.067153\n",
      "Epoch:220  Batch:2/9  loss:0.066430\n",
      "Epoch:220  Batch:3/9  loss:0.076693\n",
      "Epoch:220  Batch:4/9  loss:0.065446\n",
      "Epoch:220  Batch:5/9  loss:0.089825\n",
      "Epoch:220  Batch:6/9  loss:0.074199\n",
      "Epoch:220  Batch:7/9  loss:0.075909\n",
      "Epoch:220  Batch:8/9  loss:0.085760\n",
      "Epoch:220  Batch:9/9  loss:0.088566\n",
      "ACC: 0.96852034\n",
      "TPR: 0.7811826\n",
      "FPR: 0.0154288355\n",
      "SN: 0.984571\n",
      "SP: 0.7811826\n",
      "start train epoch: 221\n",
      "Epoch:221  Batch:1/9  loss:0.078187\n",
      "Epoch:221  Batch:2/9  loss:0.085359\n",
      "Epoch:221  Batch:3/9  loss:0.076148\n",
      "Epoch:221  Batch:4/9  loss:0.082890\n",
      "Epoch:221  Batch:5/9  loss:0.070867\n",
      "Epoch:221  Batch:6/9  loss:0.074259\n",
      "Epoch:221  Batch:7/9  loss:0.074445\n",
      "Epoch:221  Batch:8/9  loss:0.073703\n",
      "Epoch:221  Batch:9/9  loss:0.148809\n",
      "start train epoch: 222\n",
      "Epoch:222  Batch:1/9  loss:0.065698\n",
      "Epoch:222  Batch:2/9  loss:0.070700\n",
      "Epoch:222  Batch:3/9  loss:0.078981\n",
      "Epoch:222  Batch:4/9  loss:0.083723\n",
      "Epoch:222  Batch:5/9  loss:0.073301\n",
      "Epoch:222  Batch:6/9  loss:0.076772\n",
      "Epoch:222  Batch:7/9  loss:0.082294\n",
      "Epoch:222  Batch:8/9  loss:0.083082\n",
      "Epoch:222  Batch:9/9  loss:0.088835\n",
      "start train epoch: 223\n",
      "Epoch:223  Batch:1/9  loss:0.079630\n",
      "Epoch:223  Batch:2/9  loss:0.069798\n",
      "Epoch:223  Batch:3/9  loss:0.078880\n",
      "Epoch:223  Batch:4/9  loss:0.076651\n",
      "Epoch:223  Batch:5/9  loss:0.086203\n",
      "Epoch:223  Batch:6/9  loss:0.089990\n",
      "Epoch:223  Batch:7/9  loss:0.082433\n",
      "Epoch:223  Batch:8/9  loss:0.068464\n",
      "Epoch:223  Batch:9/9  loss:0.071410\n",
      "start train epoch: 224\n",
      "Epoch:224  Batch:1/9  loss:0.078971\n",
      "Epoch:224  Batch:2/9  loss:0.083533\n",
      "Epoch:224  Batch:3/9  loss:0.077416\n",
      "Epoch:224  Batch:4/9  loss:0.076445\n",
      "Epoch:224  Batch:5/9  loss:0.068179\n",
      "Epoch:224  Batch:6/9  loss:0.082102\n",
      "Epoch:224  Batch:7/9  loss:0.070954\n",
      "Epoch:224  Batch:8/9  loss:0.093627\n",
      "Epoch:224  Batch:9/9  loss:0.072952\n",
      "start train epoch: 225\n",
      "Epoch:225  Batch:1/9  loss:0.076762\n",
      "Epoch:225  Batch:2/9  loss:0.074075\n",
      "Epoch:225  Batch:3/9  loss:0.077530\n",
      "Epoch:225  Batch:4/9  loss:0.078015\n",
      "Epoch:225  Batch:5/9  loss:0.074603\n",
      "Epoch:225  Batch:6/9  loss:0.085062\n",
      "Epoch:225  Batch:7/9  loss:0.078964\n",
      "Epoch:225  Batch:8/9  loss:0.068622\n",
      "Epoch:225  Batch:9/9  loss:0.062067\n",
      "start train epoch: 226\n",
      "Epoch:226  Batch:1/9  loss:0.074189\n",
      "Epoch:226  Batch:2/9  loss:0.085016\n",
      "Epoch:226  Batch:3/9  loss:0.073952\n",
      "Epoch:226  Batch:4/9  loss:0.083038\n",
      "Epoch:226  Batch:5/9  loss:0.065285\n",
      "Epoch:226  Batch:6/9  loss:0.070858\n",
      "Epoch:226  Batch:7/9  loss:0.068452\n",
      "Epoch:226  Batch:8/9  loss:0.078367\n",
      "Epoch:226  Batch:9/9  loss:0.086221\n",
      "start train epoch: 227\n",
      "Epoch:227  Batch:1/9  loss:0.079196\n",
      "Epoch:227  Batch:2/9  loss:0.071393\n",
      "Epoch:227  Batch:3/9  loss:0.073049\n",
      "Epoch:227  Batch:4/9  loss:0.075518\n",
      "Epoch:227  Batch:5/9  loss:0.083569\n",
      "Epoch:227  Batch:6/9  loss:0.075787\n",
      "Epoch:227  Batch:7/9  loss:0.081357\n",
      "Epoch:227  Batch:8/9  loss:0.073225\n",
      "Epoch:227  Batch:9/9  loss:0.074403\n",
      "start train epoch: 228\n",
      "Epoch:228  Batch:1/9  loss:0.078695\n",
      "Epoch:228  Batch:2/9  loss:0.071742\n",
      "Epoch:228  Batch:3/9  loss:0.075450\n",
      "Epoch:228  Batch:4/9  loss:0.076552\n",
      "Epoch:228  Batch:5/9  loss:0.074738\n",
      "Epoch:228  Batch:6/9  loss:0.076121\n",
      "Epoch:228  Batch:7/9  loss:0.077279\n",
      "Epoch:228  Batch:8/9  loss:0.076781\n",
      "Epoch:228  Batch:9/9  loss:0.051765\n",
      "start train epoch: 229\n",
      "Epoch:229  Batch:1/9  loss:0.083150\n",
      "Epoch:229  Batch:2/9  loss:0.079361\n",
      "Epoch:229  Batch:3/9  loss:0.076662\n",
      "Epoch:229  Batch:4/9  loss:0.068723\n",
      "Epoch:229  Batch:5/9  loss:0.075354\n",
      "Epoch:229  Batch:6/9  loss:0.080932\n",
      "Epoch:229  Batch:7/9  loss:0.074646\n",
      "Epoch:229  Batch:8/9  loss:0.085133\n",
      "Epoch:229  Batch:9/9  loss:0.071769\n",
      "start train epoch: 230\n",
      "Epoch:230  Batch:1/9  loss:0.070986\n",
      "Epoch:230  Batch:2/9  loss:0.069591\n",
      "Epoch:230  Batch:3/9  loss:0.071072\n",
      "Epoch:230  Batch:4/9  loss:0.074681\n",
      "Epoch:230  Batch:5/9  loss:0.083312\n",
      "Epoch:230  Batch:6/9  loss:0.083528\n",
      "Epoch:230  Batch:7/9  loss:0.074233\n",
      "Epoch:230  Batch:8/9  loss:0.082347\n",
      "Epoch:230  Batch:9/9  loss:0.083866\n",
      "ACC: 0.9695146\n",
      "TPR: 0.7602815\n",
      "FPR: 0.012833997\n",
      "SN: 0.9871661\n",
      "SP: 0.7602815\n",
      "start train epoch: 231\n",
      "Epoch:231  Batch:1/9  loss:0.080103\n",
      "Epoch:231  Batch:2/9  loss:0.068478\n",
      "Epoch:231  Batch:3/9  loss:0.083799\n",
      "Epoch:231  Batch:4/9  loss:0.072336\n",
      "Epoch:231  Batch:5/9  loss:0.078465\n",
      "Epoch:231  Batch:6/9  loss:0.066265\n",
      "Epoch:231  Batch:7/9  loss:0.079388\n",
      "Epoch:231  Batch:8/9  loss:0.084492\n",
      "Epoch:231  Batch:9/9  loss:0.068240\n",
      "start train epoch: 232\n",
      "Epoch:232  Batch:1/9  loss:0.069616\n",
      "Epoch:232  Batch:2/9  loss:0.071094\n",
      "Epoch:232  Batch:3/9  loss:0.062431\n",
      "Epoch:232  Batch:4/9  loss:0.082524\n",
      "Epoch:232  Batch:5/9  loss:0.072372\n",
      "Epoch:232  Batch:6/9  loss:0.093435\n",
      "Epoch:232  Batch:7/9  loss:0.069964\n",
      "Epoch:232  Batch:8/9  loss:0.080243\n",
      "Epoch:232  Batch:9/9  loss:0.070355\n",
      "start train epoch: 233\n",
      "Epoch:233  Batch:1/9  loss:0.074603\n",
      "Epoch:233  Batch:2/9  loss:0.080319\n",
      "Epoch:233  Batch:3/9  loss:0.073459\n",
      "Epoch:233  Batch:4/9  loss:0.084314\n",
      "Epoch:233  Batch:5/9  loss:0.078341\n",
      "Epoch:233  Batch:6/9  loss:0.072997\n",
      "Epoch:233  Batch:7/9  loss:0.084489\n",
      "Epoch:233  Batch:8/9  loss:0.062737\n",
      "Epoch:233  Batch:9/9  loss:0.055261\n",
      "start train epoch: 234\n",
      "Epoch:234  Batch:1/9  loss:0.079182\n",
      "Epoch:234  Batch:2/9  loss:0.076107\n",
      "Epoch:234  Batch:3/9  loss:0.068176\n",
      "Epoch:234  Batch:4/9  loss:0.071755\n",
      "Epoch:234  Batch:5/9  loss:0.083497\n",
      "Epoch:234  Batch:6/9  loss:0.073662\n",
      "Epoch:234  Batch:7/9  loss:0.081718\n",
      "Epoch:234  Batch:8/9  loss:0.082562\n",
      "Epoch:234  Batch:9/9  loss:0.075653\n",
      "start train epoch: 235\n",
      "Epoch:235  Batch:1/9  loss:0.081001\n",
      "Epoch:235  Batch:2/9  loss:0.075043\n",
      "Epoch:235  Batch:3/9  loss:0.070637\n",
      "Epoch:235  Batch:4/9  loss:0.076645\n",
      "Epoch:235  Batch:5/9  loss:0.067841\n",
      "Epoch:235  Batch:6/9  loss:0.073304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:235  Batch:7/9  loss:0.081201\n",
      "Epoch:235  Batch:8/9  loss:0.080821\n",
      "Epoch:235  Batch:9/9  loss:0.059818\n",
      "start train epoch: 236\n",
      "Epoch:236  Batch:1/9  loss:0.071878\n",
      "Epoch:236  Batch:2/9  loss:0.082199\n",
      "Epoch:236  Batch:3/9  loss:0.078756\n",
      "Epoch:236  Batch:4/9  loss:0.079136\n",
      "Epoch:236  Batch:5/9  loss:0.073960\n",
      "Epoch:236  Batch:6/9  loss:0.069981\n",
      "Epoch:236  Batch:7/9  loss:0.087052\n",
      "Epoch:236  Batch:8/9  loss:0.071601\n",
      "Epoch:236  Batch:9/9  loss:0.051630\n",
      "start train epoch: 237\n",
      "Epoch:237  Batch:1/9  loss:0.068289\n",
      "Epoch:237  Batch:2/9  loss:0.065665\n",
      "Epoch:237  Batch:3/9  loss:0.079335\n",
      "Epoch:237  Batch:4/9  loss:0.077751\n",
      "Epoch:237  Batch:5/9  loss:0.071176\n",
      "Epoch:237  Batch:6/9  loss:0.077664\n",
      "Epoch:237  Batch:7/9  loss:0.082769\n",
      "Epoch:237  Batch:8/9  loss:0.073321\n",
      "Epoch:237  Batch:9/9  loss:0.071463\n",
      "start train epoch: 238\n",
      "Epoch:238  Batch:1/9  loss:0.074681\n",
      "Epoch:238  Batch:2/9  loss:0.080673\n",
      "Epoch:238  Batch:3/9  loss:0.076334\n",
      "Epoch:238  Batch:4/9  loss:0.074797\n",
      "Epoch:238  Batch:5/9  loss:0.080225\n",
      "Epoch:238  Batch:6/9  loss:0.075174\n",
      "Epoch:238  Batch:7/9  loss:0.065640\n",
      "Epoch:238  Batch:8/9  loss:0.088900\n",
      "Epoch:238  Batch:9/9  loss:0.076713\n",
      "start train epoch: 239\n",
      "Epoch:239  Batch:1/9  loss:0.068056\n",
      "Epoch:239  Batch:2/9  loss:0.069765\n",
      "Epoch:239  Batch:3/9  loss:0.079509\n",
      "Epoch:239  Batch:4/9  loss:0.086269\n",
      "Epoch:239  Batch:5/9  loss:0.071283\n",
      "Epoch:239  Batch:6/9  loss:0.071122\n",
      "Epoch:239  Batch:7/9  loss:0.080272\n",
      "Epoch:239  Batch:8/9  loss:0.072531\n",
      "Epoch:239  Batch:9/9  loss:0.079734\n",
      "start train epoch: 240\n",
      "Epoch:240  Batch:1/9  loss:0.079671\n",
      "Epoch:240  Batch:2/9  loss:0.079000\n",
      "Epoch:240  Batch:3/9  loss:0.080913\n",
      "Epoch:240  Batch:4/9  loss:0.064631\n",
      "Epoch:240  Batch:5/9  loss:0.074697\n",
      "Epoch:240  Batch:6/9  loss:0.077623\n",
      "Epoch:240  Batch:7/9  loss:0.073654\n",
      "Epoch:240  Batch:8/9  loss:0.082383\n",
      "Epoch:240  Batch:9/9  loss:0.072343\n",
      "ACC: 0.96955144\n",
      "TPR: 0.7597593\n",
      "FPR: 0.012559831\n",
      "SN: 0.9874401\n",
      "SP: 0.7597593\n",
      "start train epoch: 241\n",
      "Epoch:241  Batch:1/9  loss:0.062762\n",
      "Epoch:241  Batch:2/9  loss:0.079594\n",
      "Epoch:241  Batch:3/9  loss:0.074221\n",
      "Epoch:241  Batch:4/9  loss:0.075340\n",
      "Epoch:241  Batch:5/9  loss:0.073731\n",
      "Epoch:241  Batch:6/9  loss:0.069933\n",
      "Epoch:241  Batch:7/9  loss:0.075843\n",
      "Epoch:241  Batch:8/9  loss:0.077776\n",
      "Epoch:241  Batch:9/9  loss:0.074516\n",
      "start train epoch: 242\n",
      "Epoch:242  Batch:1/9  loss:0.071269\n",
      "Epoch:242  Batch:2/9  loss:0.087761\n",
      "Epoch:242  Batch:3/9  loss:0.070764\n",
      "Epoch:242  Batch:4/9  loss:0.091003\n",
      "Epoch:242  Batch:5/9  loss:0.075877\n",
      "Epoch:242  Batch:6/9  loss:0.073305\n",
      "Epoch:242  Batch:7/9  loss:0.081545\n",
      "Epoch:242  Batch:8/9  loss:0.076219\n",
      "Epoch:242  Batch:9/9  loss:0.057002\n",
      "start train epoch: 243\n",
      "Epoch:243  Batch:1/9  loss:0.078972\n",
      "Epoch:243  Batch:2/9  loss:0.079689\n",
      "Epoch:243  Batch:3/9  loss:0.071677\n",
      "Epoch:243  Batch:4/9  loss:0.075062\n",
      "Epoch:243  Batch:5/9  loss:0.077820\n",
      "Epoch:243  Batch:6/9  loss:0.086751\n",
      "Epoch:243  Batch:7/9  loss:0.064193\n",
      "Epoch:243  Batch:8/9  loss:0.069570\n",
      "Epoch:243  Batch:9/9  loss:0.081646\n",
      "start train epoch: 244\n",
      "Epoch:244  Batch:1/9  loss:0.082073\n",
      "Epoch:244  Batch:2/9  loss:0.070033\n",
      "Epoch:244  Batch:3/9  loss:0.072368\n",
      "Epoch:244  Batch:4/9  loss:0.078025\n",
      "Epoch:244  Batch:5/9  loss:0.069636\n",
      "Epoch:244  Batch:6/9  loss:0.071826\n",
      "Epoch:244  Batch:7/9  loss:0.076122\n",
      "Epoch:244  Batch:8/9  loss:0.078757\n",
      "Epoch:244  Batch:9/9  loss:0.082298\n",
      "start train epoch: 245\n",
      "Epoch:245  Batch:1/9  loss:0.081644\n",
      "Epoch:245  Batch:2/9  loss:0.069219\n",
      "Epoch:245  Batch:3/9  loss:0.070534\n",
      "Epoch:245  Batch:4/9  loss:0.064522\n",
      "Epoch:245  Batch:5/9  loss:0.080445\n",
      "Epoch:245  Batch:6/9  loss:0.074522\n",
      "Epoch:245  Batch:7/9  loss:0.079196\n",
      "Epoch:245  Batch:8/9  loss:0.067670\n",
      "Epoch:245  Batch:9/9  loss:0.083029\n",
      "start train epoch: 246\n",
      "Epoch:246  Batch:1/9  loss:0.079164\n",
      "Epoch:246  Batch:2/9  loss:0.067735\n",
      "Epoch:246  Batch:3/9  loss:0.074235\n",
      "Epoch:246  Batch:4/9  loss:0.077164\n",
      "Epoch:246  Batch:5/9  loss:0.067995\n",
      "Epoch:246  Batch:6/9  loss:0.074622\n",
      "Epoch:246  Batch:7/9  loss:0.081012\n",
      "Epoch:246  Batch:8/9  loss:0.075241\n",
      "Epoch:246  Batch:9/9  loss:0.051484\n",
      "start train epoch: 247\n",
      "Epoch:247  Batch:1/9  loss:0.069104\n",
      "Epoch:247  Batch:2/9  loss:0.075638\n",
      "Epoch:247  Batch:3/9  loss:0.082449\n",
      "Epoch:247  Batch:4/9  loss:0.071996\n",
      "Epoch:247  Batch:5/9  loss:0.067733\n",
      "Epoch:247  Batch:6/9  loss:0.075287\n",
      "Epoch:247  Batch:7/9  loss:0.085021\n",
      "Epoch:247  Batch:8/9  loss:0.071029\n",
      "Epoch:247  Batch:9/9  loss:0.063589\n",
      "start train epoch: 248\n",
      "Epoch:248  Batch:1/9  loss:0.069899\n",
      "Epoch:248  Batch:2/9  loss:0.073952\n",
      "Epoch:248  Batch:3/9  loss:0.080338\n",
      "Epoch:248  Batch:4/9  loss:0.084297\n",
      "Epoch:248  Batch:5/9  loss:0.074927\n",
      "Epoch:248  Batch:6/9  loss:0.071896\n",
      "Epoch:248  Batch:7/9  loss:0.068373\n",
      "Epoch:248  Batch:8/9  loss:0.072547\n",
      "Epoch:248  Batch:9/9  loss:0.050014\n",
      "start train epoch: 249\n",
      "Epoch:249  Batch:1/9  loss:0.074706\n",
      "Epoch:249  Batch:2/9  loss:0.072885\n",
      "Epoch:249  Batch:3/9  loss:0.085064\n",
      "Epoch:249  Batch:4/9  loss:0.073019\n",
      "Epoch:249  Batch:5/9  loss:0.066264\n",
      "Epoch:249  Batch:6/9  loss:0.083519\n",
      "Epoch:249  Batch:7/9  loss:0.072091\n",
      "Epoch:249  Batch:8/9  loss:0.069657\n",
      "Epoch:249  Batch:9/9  loss:0.074897\n",
      "start train epoch: 250\n",
      "Epoch:250  Batch:1/9  loss:0.070059\n",
      "Epoch:250  Batch:2/9  loss:0.078079\n",
      "Epoch:250  Batch:3/9  loss:0.066116\n",
      "Epoch:250  Batch:4/9  loss:0.070733\n",
      "Epoch:250  Batch:5/9  loss:0.070784\n",
      "Epoch:250  Batch:6/9  loss:0.098316\n",
      "Epoch:250  Batch:7/9  loss:0.078160\n",
      "Epoch:250  Batch:8/9  loss:0.071861\n",
      "Epoch:250  Batch:9/9  loss:0.064421\n",
      "ACC: 0.96927404\n",
      "TPR: 0.77191305\n",
      "FPR: 0.013751682\n",
      "SN: 0.9862484\n",
      "SP: 0.77191305\n",
      "start train epoch: 251\n",
      "Epoch:251  Batch:1/9  loss:0.074124\n",
      "Epoch:251  Batch:2/9  loss:0.077139\n",
      "Epoch:251  Batch:3/9  loss:0.069433\n",
      "Epoch:251  Batch:4/9  loss:0.084713\n",
      "Epoch:251  Batch:5/9  loss:0.081122\n",
      "Epoch:251  Batch:6/9  loss:0.086484\n",
      "Epoch:251  Batch:7/9  loss:0.067287\n",
      "Epoch:251  Batch:8/9  loss:0.066829\n",
      "Epoch:251  Batch:9/9  loss:0.069671\n",
      "start train epoch: 252\n",
      "Epoch:252  Batch:1/9  loss:0.082168\n",
      "Epoch:252  Batch:2/9  loss:0.071433\n",
      "Epoch:252  Batch:3/9  loss:0.082777\n",
      "Epoch:252  Batch:4/9  loss:0.081671\n",
      "Epoch:252  Batch:5/9  loss:0.071802\n",
      "Epoch:252  Batch:6/9  loss:0.061507\n",
      "Epoch:252  Batch:7/9  loss:0.073034\n",
      "Epoch:252  Batch:8/9  loss:0.081129\n",
      "Epoch:252  Batch:9/9  loss:0.065485\n",
      "start train epoch: 253\n",
      "Epoch:253  Batch:1/9  loss:0.060347\n",
      "Epoch:253  Batch:2/9  loss:0.081591\n",
      "Epoch:253  Batch:3/9  loss:0.085095\n",
      "Epoch:253  Batch:4/9  loss:0.068485\n",
      "Epoch:253  Batch:5/9  loss:0.082034\n",
      "Epoch:253  Batch:6/9  loss:0.074586\n",
      "Epoch:253  Batch:7/9  loss:0.071346\n",
      "Epoch:253  Batch:8/9  loss:0.085604\n",
      "Epoch:253  Batch:9/9  loss:0.085546\n",
      "start train epoch: 254\n",
      "Epoch:254  Batch:1/9  loss:0.078076\n",
      "Epoch:254  Batch:2/9  loss:0.086784\n",
      "Epoch:254  Batch:3/9  loss:0.078048\n",
      "Epoch:254  Batch:4/9  loss:0.070162\n",
      "Epoch:254  Batch:5/9  loss:0.076683\n",
      "Epoch:254  Batch:6/9  loss:0.074025\n",
      "Epoch:254  Batch:7/9  loss:0.074899\n",
      "Epoch:254  Batch:8/9  loss:0.077501\n",
      "Epoch:254  Batch:9/9  loss:0.071294\n",
      "start train epoch: 255\n",
      "Epoch:255  Batch:1/9  loss:0.073712\n",
      "Epoch:255  Batch:2/9  loss:0.077310\n",
      "Epoch:255  Batch:3/9  loss:0.076829\n",
      "Epoch:255  Batch:4/9  loss:0.076642\n",
      "Epoch:255  Batch:5/9  loss:0.077879\n",
      "Epoch:255  Batch:6/9  loss:0.082359\n",
      "Epoch:255  Batch:7/9  loss:0.071173\n",
      "Epoch:255  Batch:8/9  loss:0.075671\n",
      "Epoch:255  Batch:9/9  loss:0.044717\n",
      "start train epoch: 256\n",
      "Epoch:256  Batch:1/9  loss:0.071359\n",
      "Epoch:256  Batch:2/9  loss:0.068708\n",
      "Epoch:256  Batch:3/9  loss:0.075005\n",
      "Epoch:256  Batch:4/9  loss:0.084208\n",
      "Epoch:256  Batch:5/9  loss:0.068087\n",
      "Epoch:256  Batch:6/9  loss:0.068506\n",
      "Epoch:256  Batch:7/9  loss:0.080863\n",
      "Epoch:256  Batch:8/9  loss:0.076471\n",
      "Epoch:256  Batch:9/9  loss:0.091837\n",
      "start train epoch: 257\n",
      "Epoch:257  Batch:1/9  loss:0.073538\n",
      "Epoch:257  Batch:2/9  loss:0.076409\n",
      "Epoch:257  Batch:3/9  loss:0.082474\n",
      "Epoch:257  Batch:4/9  loss:0.069688\n",
      "Epoch:257  Batch:5/9  loss:0.069594\n",
      "Epoch:257  Batch:6/9  loss:0.079920\n",
      "Epoch:257  Batch:7/9  loss:0.078122\n",
      "Epoch:257  Batch:8/9  loss:0.075277\n",
      "Epoch:257  Batch:9/9  loss:0.070204\n",
      "start train epoch: 258\n",
      "Epoch:258  Batch:1/9  loss:0.083483\n",
      "Epoch:258  Batch:2/9  loss:0.072582\n",
      "Epoch:258  Batch:3/9  loss:0.081447\n",
      "Epoch:258  Batch:4/9  loss:0.072622\n",
      "Epoch:258  Batch:5/9  loss:0.075905\n",
      "Epoch:258  Batch:6/9  loss:0.073413\n",
      "Epoch:258  Batch:7/9  loss:0.070380\n",
      "Epoch:258  Batch:8/9  loss:0.068116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:258  Batch:9/9  loss:0.061991\n",
      "start train epoch: 259\n",
      "Epoch:259  Batch:1/9  loss:0.079488\n",
      "Epoch:259  Batch:2/9  loss:0.073435\n",
      "Epoch:259  Batch:3/9  loss:0.074551\n",
      "Epoch:259  Batch:4/9  loss:0.069808\n",
      "Epoch:259  Batch:5/9  loss:0.071875\n",
      "Epoch:259  Batch:6/9  loss:0.070321\n",
      "Epoch:259  Batch:7/9  loss:0.085053\n",
      "Epoch:259  Batch:8/9  loss:0.069962\n",
      "Epoch:259  Batch:9/9  loss:0.082371\n",
      "start train epoch: 260\n",
      "Epoch:260  Batch:1/9  loss:0.073294\n",
      "Epoch:260  Batch:2/9  loss:0.069925\n",
      "Epoch:260  Batch:3/9  loss:0.076686\n",
      "Epoch:260  Batch:4/9  loss:0.072826\n",
      "Epoch:260  Batch:5/9  loss:0.059245\n",
      "Epoch:260  Batch:6/9  loss:0.078638\n",
      "Epoch:260  Batch:7/9  loss:0.074212\n",
      "Epoch:260  Batch:8/9  loss:0.085065\n",
      "Epoch:260  Batch:9/9  loss:0.085636\n",
      "ACC: 0.96942836\n",
      "TPR: 0.7593416\n",
      "FPR: 0.012696109\n",
      "SN: 0.9873038\n",
      "SP: 0.7593416\n",
      "start train epoch: 261\n",
      "Epoch:261  Batch:1/9  loss:0.076340\n",
      "Epoch:261  Batch:2/9  loss:0.070858\n",
      "Epoch:261  Batch:3/9  loss:0.081220\n",
      "Epoch:261  Batch:4/9  loss:0.075886\n",
      "Epoch:261  Batch:5/9  loss:0.071461\n",
      "Epoch:261  Batch:6/9  loss:0.079701\n",
      "Epoch:261  Batch:7/9  loss:0.074005\n",
      "Epoch:261  Batch:8/9  loss:0.072428\n",
      "Epoch:261  Batch:9/9  loss:0.059646\n",
      "start train epoch: 262\n",
      "Epoch:262  Batch:1/9  loss:0.065055\n",
      "Epoch:262  Batch:2/9  loss:0.068339\n",
      "Epoch:262  Batch:3/9  loss:0.067890\n",
      "Epoch:262  Batch:4/9  loss:0.079807\n",
      "Epoch:262  Batch:5/9  loss:0.079151\n",
      "Epoch:262  Batch:6/9  loss:0.089032\n",
      "Epoch:262  Batch:7/9  loss:0.071143\n",
      "Epoch:262  Batch:8/9  loss:0.073316\n",
      "Epoch:262  Batch:9/9  loss:0.087508\n",
      "start train epoch: 263\n",
      "Epoch:263  Batch:1/9  loss:0.070490\n",
      "Epoch:263  Batch:2/9  loss:0.067628\n",
      "Epoch:263  Batch:3/9  loss:0.078317\n",
      "Epoch:263  Batch:4/9  loss:0.086258\n",
      "Epoch:263  Batch:5/9  loss:0.074805\n",
      "Epoch:263  Batch:6/9  loss:0.076150\n",
      "Epoch:263  Batch:7/9  loss:0.074305\n",
      "Epoch:263  Batch:8/9  loss:0.075690\n",
      "Epoch:263  Batch:9/9  loss:0.092387\n",
      "start train epoch: 264\n",
      "Epoch:264  Batch:1/9  loss:0.076050\n",
      "Epoch:264  Batch:2/9  loss:0.071365\n",
      "Epoch:264  Batch:3/9  loss:0.078387\n",
      "Epoch:264  Batch:4/9  loss:0.074337\n",
      "Epoch:264  Batch:5/9  loss:0.078548\n",
      "Epoch:264  Batch:6/9  loss:0.085921\n",
      "Epoch:264  Batch:7/9  loss:0.074270\n",
      "Epoch:264  Batch:8/9  loss:0.062837\n",
      "Epoch:264  Batch:9/9  loss:0.041318\n",
      "start train epoch: 265\n",
      "Epoch:265  Batch:1/9  loss:0.075500\n",
      "Epoch:265  Batch:2/9  loss:0.083713\n",
      "Epoch:265  Batch:3/9  loss:0.075998\n",
      "Epoch:265  Batch:4/9  loss:0.065991\n",
      "Epoch:265  Batch:5/9  loss:0.059230\n",
      "Epoch:265  Batch:6/9  loss:0.075778\n",
      "Epoch:265  Batch:7/9  loss:0.074233\n",
      "Epoch:265  Batch:8/9  loss:0.082753\n",
      "Epoch:265  Batch:9/9  loss:0.079024\n",
      "start train epoch: 266\n",
      "Epoch:266  Batch:1/9  loss:0.075272\n",
      "Epoch:266  Batch:2/9  loss:0.074069\n",
      "Epoch:266  Batch:3/9  loss:0.078789\n",
      "Epoch:266  Batch:4/9  loss:0.081053\n",
      "Epoch:266  Batch:5/9  loss:0.062587\n",
      "Epoch:266  Batch:6/9  loss:0.067151\n",
      "Epoch:266  Batch:7/9  loss:0.077966\n",
      "Epoch:266  Batch:8/9  loss:0.081089\n",
      "Epoch:266  Batch:9/9  loss:0.074646\n",
      "start train epoch: 267\n",
      "Epoch:267  Batch:1/9  loss:0.068963\n",
      "Epoch:267  Batch:2/9  loss:0.077766\n",
      "Epoch:267  Batch:3/9  loss:0.077927\n",
      "Epoch:267  Batch:4/9  loss:0.081749\n",
      "Epoch:267  Batch:5/9  loss:0.066520\n",
      "Epoch:267  Batch:6/9  loss:0.070624\n",
      "Epoch:267  Batch:7/9  loss:0.077979\n",
      "Epoch:267  Batch:8/9  loss:0.069821\n",
      "Epoch:267  Batch:9/9  loss:0.057281\n",
      "start train epoch: 268\n",
      "Epoch:268  Batch:1/9  loss:0.072771\n",
      "Epoch:268  Batch:2/9  loss:0.072240\n",
      "Epoch:268  Batch:3/9  loss:0.073213\n",
      "Epoch:268  Batch:4/9  loss:0.079782\n",
      "Epoch:268  Batch:5/9  loss:0.079208\n",
      "Epoch:268  Batch:6/9  loss:0.079673\n",
      "Epoch:268  Batch:7/9  loss:0.071300\n",
      "Epoch:268  Batch:8/9  loss:0.073124\n",
      "Epoch:268  Batch:9/9  loss:0.077459\n",
      "start train epoch: 269\n",
      "Epoch:269  Batch:1/9  loss:0.079393\n",
      "Epoch:269  Batch:2/9  loss:0.069514\n",
      "Epoch:269  Batch:3/9  loss:0.073131\n",
      "Epoch:269  Batch:4/9  loss:0.071326\n",
      "Epoch:269  Batch:5/9  loss:0.070526\n",
      "Epoch:269  Batch:6/9  loss:0.066093\n",
      "Epoch:269  Batch:7/9  loss:0.079566\n",
      "Epoch:269  Batch:8/9  loss:0.080052\n",
      "Epoch:269  Batch:9/9  loss:0.125420\n",
      "start train epoch: 270\n",
      "Epoch:270  Batch:1/9  loss:0.072591\n",
      "Epoch:270  Batch:2/9  loss:0.070500\n",
      "Epoch:270  Batch:3/9  loss:0.082397\n",
      "Epoch:270  Batch:4/9  loss:0.076399\n",
      "Epoch:270  Batch:5/9  loss:0.078786\n",
      "Epoch:270  Batch:6/9  loss:0.074438\n",
      "Epoch:270  Batch:7/9  loss:0.076209\n",
      "Epoch:270  Batch:8/9  loss:0.069680\n",
      "Epoch:270  Batch:9/9  loss:0.086569\n",
      "ACC: 0.9692392\n",
      "TPR: 0.77638197\n",
      "FPR: 0.014254369\n",
      "SN: 0.9857457\n",
      "SP: 0.77638197\n",
      "start train epoch: 271\n",
      "Epoch:271  Batch:1/9  loss:0.080778\n",
      "Epoch:271  Batch:2/9  loss:0.070432\n",
      "Epoch:271  Batch:3/9  loss:0.070970\n",
      "Epoch:271  Batch:4/9  loss:0.071272\n",
      "Epoch:271  Batch:5/9  loss:0.081697\n",
      "Epoch:271  Batch:6/9  loss:0.085797\n",
      "Epoch:271  Batch:7/9  loss:0.075114\n",
      "Epoch:271  Batch:8/9  loss:0.079704\n",
      "Epoch:271  Batch:9/9  loss:0.093175\n",
      "start train epoch: 272\n",
      "Epoch:272  Batch:1/9  loss:0.079985\n",
      "Epoch:272  Batch:2/9  loss:0.068683\n",
      "Epoch:272  Batch:3/9  loss:0.073065\n",
      "Epoch:272  Batch:4/9  loss:0.077874\n",
      "Epoch:272  Batch:5/9  loss:0.075671\n",
      "Epoch:272  Batch:6/9  loss:0.068064\n",
      "Epoch:272  Batch:7/9  loss:0.074291\n",
      "Epoch:272  Batch:8/9  loss:0.082547\n",
      "Epoch:272  Batch:9/9  loss:0.086921\n",
      "start train epoch: 273\n",
      "Epoch:273  Batch:1/9  loss:0.078938\n",
      "Epoch:273  Batch:2/9  loss:0.075240\n",
      "Epoch:273  Batch:3/9  loss:0.070661\n",
      "Epoch:273  Batch:4/9  loss:0.075424\n",
      "Epoch:273  Batch:5/9  loss:0.074819\n",
      "Epoch:273  Batch:6/9  loss:0.077736\n",
      "Epoch:273  Batch:7/9  loss:0.083769\n",
      "Epoch:273  Batch:8/9  loss:0.066129\n",
      "Epoch:273  Batch:9/9  loss:0.060885\n",
      "start train epoch: 274\n",
      "Epoch:274  Batch:1/9  loss:0.079863\n",
      "Epoch:274  Batch:2/9  loss:0.085975\n",
      "Epoch:274  Batch:3/9  loss:0.073059\n",
      "Epoch:274  Batch:4/9  loss:0.083658\n",
      "Epoch:274  Batch:5/9  loss:0.075504\n",
      "Epoch:274  Batch:6/9  loss:0.069870\n",
      "Epoch:274  Batch:7/9  loss:0.069459\n",
      "Epoch:274  Batch:8/9  loss:0.063550\n",
      "Epoch:274  Batch:9/9  loss:0.079553\n",
      "start train epoch: 275\n",
      "Epoch:275  Batch:1/9  loss:0.072012\n",
      "Epoch:275  Batch:2/9  loss:0.071660\n",
      "Epoch:275  Batch:3/9  loss:0.070315\n",
      "Epoch:275  Batch:4/9  loss:0.075850\n",
      "Epoch:275  Batch:5/9  loss:0.078947\n",
      "Epoch:275  Batch:6/9  loss:0.077368\n",
      "Epoch:275  Batch:7/9  loss:0.068362\n",
      "Epoch:275  Batch:8/9  loss:0.074547\n",
      "Epoch:275  Batch:9/9  loss:0.051640\n",
      "start train epoch: 276\n",
      "Epoch:276  Batch:1/9  loss:0.065956\n",
      "Epoch:276  Batch:2/9  loss:0.078766\n",
      "Epoch:276  Batch:3/9  loss:0.069244\n",
      "Epoch:276  Batch:4/9  loss:0.072981\n",
      "Epoch:276  Batch:5/9  loss:0.072226\n",
      "Epoch:276  Batch:6/9  loss:0.070261\n",
      "Epoch:276  Batch:7/9  loss:0.082123\n",
      "Epoch:276  Batch:8/9  loss:0.070785\n",
      "Epoch:276  Batch:9/9  loss:0.085679\n",
      "start train epoch: 277\n",
      "Epoch:277  Batch:1/9  loss:0.071320\n",
      "Epoch:277  Batch:2/9  loss:0.073093\n",
      "Epoch:277  Batch:3/9  loss:0.071593\n",
      "Epoch:277  Batch:4/9  loss:0.061617\n",
      "Epoch:277  Batch:5/9  loss:0.071450\n",
      "Epoch:277  Batch:6/9  loss:0.080150\n",
      "Epoch:277  Batch:7/9  loss:0.090141\n",
      "Epoch:277  Batch:8/9  loss:0.070196\n",
      "Epoch:277  Batch:9/9  loss:0.085404\n",
      "start train epoch: 278\n",
      "Epoch:278  Batch:1/9  loss:0.074485\n",
      "Epoch:278  Batch:2/9  loss:0.085699\n",
      "Epoch:278  Batch:3/9  loss:0.068631\n",
      "Epoch:278  Batch:4/9  loss:0.067736\n",
      "Epoch:278  Batch:5/9  loss:0.072756\n",
      "Epoch:278  Batch:6/9  loss:0.068933\n",
      "Epoch:278  Batch:7/9  loss:0.062017\n",
      "Epoch:278  Batch:8/9  loss:0.085103\n",
      "Epoch:278  Batch:9/9  loss:0.100710\n",
      "start train epoch: 279\n",
      "Epoch:279  Batch:1/9  loss:0.079024\n",
      "Epoch:279  Batch:2/9  loss:0.086733\n",
      "Epoch:279  Batch:3/9  loss:0.067890\n",
      "Epoch:279  Batch:4/9  loss:0.084994\n",
      "Epoch:279  Batch:5/9  loss:0.067143\n",
      "Epoch:279  Batch:6/9  loss:0.073555\n",
      "Epoch:279  Batch:7/9  loss:0.072889\n",
      "Epoch:279  Batch:8/9  loss:0.068493\n",
      "Epoch:279  Batch:9/9  loss:0.104466\n",
      "start train epoch: 280\n",
      "Epoch:280  Batch:1/9  loss:0.063071\n",
      "Epoch:280  Batch:2/9  loss:0.081288\n",
      "Epoch:280  Batch:3/9  loss:0.066358\n",
      "Epoch:280  Batch:4/9  loss:0.079729\n",
      "Epoch:280  Batch:5/9  loss:0.080350\n",
      "Epoch:280  Batch:6/9  loss:0.070862\n",
      "Epoch:280  Batch:7/9  loss:0.073377\n",
      "Epoch:280  Batch:8/9  loss:0.079548\n",
      "Epoch:280  Batch:9/9  loss:0.080443\n",
      "ACC: 0.96926767\n",
      "TPR: 0.7803193\n",
      "FPR: 0.014852385\n",
      "SN: 0.9851475\n",
      "SP: 0.7803193\n",
      "start train epoch: 281\n",
      "Epoch:281  Batch:1/9  loss:0.093255\n",
      "Epoch:281  Batch:2/9  loss:0.073732\n",
      "Epoch:281  Batch:3/9  loss:0.070756\n",
      "Epoch:281  Batch:4/9  loss:0.074003\n",
      "Epoch:281  Batch:5/9  loss:0.061647\n",
      "Epoch:281  Batch:6/9  loss:0.074673\n",
      "Epoch:281  Batch:7/9  loss:0.073496\n",
      "Epoch:281  Batch:8/9  loss:0.072805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:281  Batch:9/9  loss:0.071678\n",
      "start train epoch: 282\n",
      "Epoch:282  Batch:1/9  loss:0.072219\n",
      "Epoch:282  Batch:2/9  loss:0.058429\n",
      "Epoch:282  Batch:3/9  loss:0.081841\n",
      "Epoch:282  Batch:4/9  loss:0.072023\n",
      "Epoch:282  Batch:5/9  loss:0.065603\n",
      "Epoch:282  Batch:6/9  loss:0.079056\n",
      "Epoch:282  Batch:7/9  loss:0.074679\n",
      "Epoch:282  Batch:8/9  loss:0.079372\n",
      "Epoch:282  Batch:9/9  loss:0.077447\n",
      "start train epoch: 283\n",
      "Epoch:283  Batch:1/9  loss:0.088126\n",
      "Epoch:283  Batch:2/9  loss:0.069073\n",
      "Epoch:283  Batch:3/9  loss:0.073782\n",
      "Epoch:283  Batch:4/9  loss:0.068012\n",
      "Epoch:283  Batch:5/9  loss:0.076181\n",
      "Epoch:283  Batch:6/9  loss:0.075868\n",
      "Epoch:283  Batch:7/9  loss:0.070820\n",
      "Epoch:283  Batch:8/9  loss:0.072264\n",
      "Epoch:283  Batch:9/9  loss:0.086461\n",
      "start train epoch: 284\n",
      "Epoch:284  Batch:1/9  loss:0.067427\n",
      "Epoch:284  Batch:2/9  loss:0.085455\n",
      "Epoch:284  Batch:3/9  loss:0.072595\n",
      "Epoch:284  Batch:4/9  loss:0.077414\n",
      "Epoch:284  Batch:5/9  loss:0.072673\n",
      "Epoch:284  Batch:6/9  loss:0.071064\n",
      "Epoch:284  Batch:7/9  loss:0.064433\n",
      "Epoch:284  Batch:8/9  loss:0.076516\n",
      "Epoch:284  Batch:9/9  loss:0.112388\n",
      "start train epoch: 285\n",
      "Epoch:285  Batch:1/9  loss:0.080680\n",
      "Epoch:285  Batch:2/9  loss:0.078990\n",
      "Epoch:285  Batch:3/9  loss:0.070252\n",
      "Epoch:285  Batch:4/9  loss:0.092492\n",
      "Epoch:285  Batch:5/9  loss:0.069039\n",
      "Epoch:285  Batch:6/9  loss:0.065990\n",
      "Epoch:285  Batch:7/9  loss:0.066579\n",
      "Epoch:285  Batch:8/9  loss:0.066306\n",
      "Epoch:285  Batch:9/9  loss:0.081460\n",
      "start train epoch: 286\n",
      "Epoch:286  Batch:1/9  loss:0.082480\n",
      "Epoch:286  Batch:2/9  loss:0.071000\n",
      "Epoch:286  Batch:3/9  loss:0.076515\n",
      "Epoch:286  Batch:4/9  loss:0.066941\n",
      "Epoch:286  Batch:5/9  loss:0.065795\n",
      "Epoch:286  Batch:6/9  loss:0.075369\n",
      "Epoch:286  Batch:7/9  loss:0.071976\n",
      "Epoch:286  Batch:8/9  loss:0.084450\n",
      "Epoch:286  Batch:9/9  loss:0.074704\n",
      "start train epoch: 287\n",
      "Epoch:287  Batch:1/9  loss:0.081698\n",
      "Epoch:287  Batch:2/9  loss:0.071924\n",
      "Epoch:287  Batch:3/9  loss:0.069872\n",
      "Epoch:287  Batch:4/9  loss:0.093769\n",
      "Epoch:287  Batch:5/9  loss:0.069279\n",
      "Epoch:287  Batch:6/9  loss:0.067167\n",
      "Epoch:287  Batch:7/9  loss:0.068884\n",
      "Epoch:287  Batch:8/9  loss:0.075314\n",
      "Epoch:287  Batch:9/9  loss:0.091914\n",
      "start train epoch: 288\n",
      "Epoch:288  Batch:1/9  loss:0.092241\n",
      "Epoch:288  Batch:2/9  loss:0.072456\n",
      "Epoch:288  Batch:3/9  loss:0.074144\n",
      "Epoch:288  Batch:4/9  loss:0.069855\n",
      "Epoch:288  Batch:5/9  loss:0.064717\n",
      "Epoch:288  Batch:6/9  loss:0.069767\n",
      "Epoch:288  Batch:7/9  loss:0.067800\n",
      "Epoch:288  Batch:8/9  loss:0.079215\n",
      "Epoch:288  Batch:9/9  loss:0.120139\n",
      "start train epoch: 289\n",
      "Epoch:289  Batch:1/9  loss:0.077336\n",
      "Epoch:289  Batch:2/9  loss:0.079725\n",
      "Epoch:289  Batch:3/9  loss:0.081191\n",
      "Epoch:289  Batch:4/9  loss:0.081897\n",
      "Epoch:289  Batch:5/9  loss:0.068386\n",
      "Epoch:289  Batch:6/9  loss:0.073161\n",
      "Epoch:289  Batch:7/9  loss:0.067401\n",
      "Epoch:289  Batch:8/9  loss:0.065227\n",
      "Epoch:289  Batch:9/9  loss:0.055676\n",
      "start train epoch: 290\n",
      "Epoch:290  Batch:1/9  loss:0.079940\n",
      "Epoch:290  Batch:2/9  loss:0.087296\n",
      "Epoch:290  Batch:3/9  loss:0.079164\n",
      "Epoch:290  Batch:4/9  loss:0.065600\n",
      "Epoch:290  Batch:5/9  loss:0.060818\n",
      "Epoch:290  Batch:6/9  loss:0.068536\n",
      "Epoch:290  Batch:7/9  loss:0.073813\n",
      "Epoch:290  Batch:8/9  loss:0.070223\n",
      "Epoch:290  Batch:9/9  loss:0.088532\n",
      "ACC: 0.96894175\n",
      "TPR: 0.77156985\n",
      "FPR: 0.014394502\n",
      "SN: 0.98560536\n",
      "SP: 0.77156985\n",
      "start train epoch: 291\n",
      "Epoch:291  Batch:1/9  loss:0.070846\n",
      "Epoch:291  Batch:2/9  loss:0.075512\n",
      "Epoch:291  Batch:3/9  loss:0.069478\n",
      "Epoch:291  Batch:4/9  loss:0.071721\n",
      "Epoch:291  Batch:5/9  loss:0.071780\n",
      "Epoch:291  Batch:6/9  loss:0.076334\n",
      "Epoch:291  Batch:7/9  loss:0.081624\n",
      "Epoch:291  Batch:8/9  loss:0.068765\n",
      "Epoch:291  Batch:9/9  loss:0.171655\n",
      "start train epoch: 292\n",
      "Epoch:292  Batch:1/9  loss:0.064200\n",
      "Epoch:292  Batch:2/9  loss:0.082068\n",
      "Epoch:292  Batch:3/9  loss:0.071288\n",
      "Epoch:292  Batch:4/9  loss:0.087586\n",
      "Epoch:292  Batch:5/9  loss:0.070119\n",
      "Epoch:292  Batch:6/9  loss:0.087362\n",
      "Epoch:292  Batch:7/9  loss:0.089503\n",
      "Epoch:292  Batch:8/9  loss:0.090779\n",
      "Epoch:292  Batch:9/9  loss:0.098582\n",
      "start train epoch: 293\n",
      "Epoch:293  Batch:1/9  loss:0.073213\n",
      "Epoch:293  Batch:2/9  loss:0.079823\n",
      "Epoch:293  Batch:3/9  loss:0.080604\n",
      "Epoch:293  Batch:4/9  loss:0.074612\n",
      "Epoch:293  Batch:5/9  loss:0.083849\n",
      "Epoch:293  Batch:6/9  loss:0.084179\n",
      "Epoch:293  Batch:7/9  loss:0.076626\n",
      "Epoch:293  Batch:8/9  loss:0.078202\n",
      "Epoch:293  Batch:9/9  loss:0.053973\n",
      "start train epoch: 294\n",
      "Epoch:294  Batch:1/9  loss:0.086448\n",
      "Epoch:294  Batch:2/9  loss:0.075980\n",
      "Epoch:294  Batch:3/9  loss:0.077650\n",
      "Epoch:294  Batch:4/9  loss:0.080762\n",
      "Epoch:294  Batch:5/9  loss:0.085468\n",
      "Epoch:294  Batch:6/9  loss:0.072972\n",
      "Epoch:294  Batch:7/9  loss:0.077259\n",
      "Epoch:294  Batch:8/9  loss:0.080705\n",
      "Epoch:294  Batch:9/9  loss:0.065068\n",
      "start train epoch: 295\n",
      "Epoch:295  Batch:1/9  loss:0.083744\n",
      "Epoch:295  Batch:2/9  loss:0.080108\n",
      "Epoch:295  Batch:3/9  loss:0.094822\n",
      "Epoch:295  Batch:4/9  loss:0.073897\n",
      "Epoch:295  Batch:5/9  loss:0.073814\n",
      "Epoch:295  Batch:6/9  loss:0.068680\n",
      "Epoch:295  Batch:7/9  loss:0.080312\n",
      "Epoch:295  Batch:8/9  loss:0.066464\n",
      "Epoch:295  Batch:9/9  loss:0.072312\n",
      "start train epoch: 296\n",
      "Epoch:296  Batch:1/9  loss:0.077908\n",
      "Epoch:296  Batch:2/9  loss:0.081148\n",
      "Epoch:296  Batch:3/9  loss:0.075908\n",
      "Epoch:296  Batch:4/9  loss:0.078106\n",
      "Epoch:296  Batch:5/9  loss:0.081468\n",
      "Epoch:296  Batch:6/9  loss:0.073791\n",
      "Epoch:296  Batch:7/9  loss:0.076550\n",
      "Epoch:296  Batch:8/9  loss:0.075833\n",
      "Epoch:296  Batch:9/9  loss:0.059406\n",
      "start train epoch: 297\n",
      "Epoch:297  Batch:1/9  loss:0.077075\n",
      "Epoch:297  Batch:2/9  loss:0.074828\n",
      "Epoch:297  Batch:3/9  loss:0.076305\n",
      "Epoch:297  Batch:4/9  loss:0.071432\n",
      "Epoch:297  Batch:5/9  loss:0.074406\n",
      "Epoch:297  Batch:6/9  loss:0.099359\n",
      "Epoch:297  Batch:7/9  loss:0.068055\n",
      "Epoch:297  Batch:8/9  loss:0.069882\n",
      "Epoch:297  Batch:9/9  loss:0.072654\n",
      "start train epoch: 298\n",
      "Epoch:298  Batch:1/9  loss:0.070750\n",
      "Epoch:298  Batch:2/9  loss:0.076603\n",
      "Epoch:298  Batch:3/9  loss:0.081750\n",
      "Epoch:298  Batch:4/9  loss:0.087513\n",
      "Epoch:298  Batch:5/9  loss:0.073341\n",
      "Epoch:298  Batch:6/9  loss:0.080138\n",
      "Epoch:298  Batch:7/9  loss:0.083949\n",
      "Epoch:298  Batch:8/9  loss:0.066351\n",
      "Epoch:298  Batch:9/9  loss:0.105036\n",
      "start train epoch: 299\n",
      "Epoch:299  Batch:1/9  loss:0.067855\n",
      "Epoch:299  Batch:2/9  loss:0.079778\n",
      "Epoch:299  Batch:3/9  loss:0.089778\n",
      "Epoch:299  Batch:4/9  loss:0.072301\n",
      "Epoch:299  Batch:5/9  loss:0.072746\n",
      "Epoch:299  Batch:6/9  loss:0.078976\n",
      "Epoch:299  Batch:7/9  loss:0.076045\n",
      "Epoch:299  Batch:8/9  loss:0.073083\n",
      "Epoch:299  Batch:9/9  loss:0.058390\n",
      "start train epoch: 300\n",
      "Epoch:300  Batch:1/9  loss:0.075121\n",
      "Epoch:300  Batch:2/9  loss:0.078988\n",
      "Epoch:300  Batch:3/9  loss:0.087246\n",
      "Epoch:300  Batch:4/9  loss:0.076501\n",
      "Epoch:300  Batch:5/9  loss:0.069691\n",
      "Epoch:300  Batch:6/9  loss:0.065799\n",
      "Epoch:300  Batch:7/9  loss:0.079231\n",
      "Epoch:300  Batch:8/9  loss:0.073933\n",
      "Epoch:300  Batch:9/9  loss:0.098519\n",
      "ACC: 0.9694078\n",
      "TPR: 0.7422179\n",
      "FPR: 0.011262261\n",
      "SN: 0.98873764\n",
      "SP: 0.7422179\n",
      "start train epoch: 301\n",
      "Epoch:301  Batch:1/9  loss:0.086805\n",
      "Epoch:301  Batch:2/9  loss:0.079606\n",
      "Epoch:301  Batch:3/9  loss:0.070335\n",
      "Epoch:301  Batch:4/9  loss:0.067648\n",
      "Epoch:301  Batch:5/9  loss:0.075757\n",
      "Epoch:301  Batch:6/9  loss:0.083316\n",
      "Epoch:301  Batch:7/9  loss:0.082218\n",
      "Epoch:301  Batch:8/9  loss:0.061790\n",
      "Epoch:301  Batch:9/9  loss:0.059610\n",
      "start train epoch: 302\n",
      "Epoch:302  Batch:1/9  loss:0.079090\n",
      "Epoch:302  Batch:2/9  loss:0.071251\n",
      "Epoch:302  Batch:3/9  loss:0.080098\n",
      "Epoch:302  Batch:4/9  loss:0.065047\n",
      "Epoch:302  Batch:5/9  loss:0.071655\n",
      "Epoch:302  Batch:6/9  loss:0.071570\n",
      "Epoch:302  Batch:7/9  loss:0.075089\n",
      "Epoch:302  Batch:8/9  loss:0.079124\n",
      "Epoch:302  Batch:9/9  loss:0.060828\n",
      "start train epoch: 303\n",
      "Epoch:303  Batch:1/9  loss:0.065934\n",
      "Epoch:303  Batch:2/9  loss:0.069092\n",
      "Epoch:303  Batch:3/9  loss:0.072641\n",
      "Epoch:303  Batch:4/9  loss:0.071085\n",
      "Epoch:303  Batch:5/9  loss:0.076287\n",
      "Epoch:303  Batch:6/9  loss:0.077622\n",
      "Epoch:303  Batch:7/9  loss:0.076013\n",
      "Epoch:303  Batch:8/9  loss:0.077485\n",
      "Epoch:303  Batch:9/9  loss:0.104146\n",
      "start train epoch: 304\n",
      "Epoch:304  Batch:1/9  loss:0.073870\n",
      "Epoch:304  Batch:2/9  loss:0.078617\n",
      "Epoch:304  Batch:3/9  loss:0.075966\n",
      "Epoch:304  Batch:4/9  loss:0.071426\n",
      "Epoch:304  Batch:5/9  loss:0.084353\n",
      "Epoch:304  Batch:6/9  loss:0.068456\n",
      "Epoch:304  Batch:7/9  loss:0.079045\n",
      "Epoch:304  Batch:8/9  loss:0.069234\n",
      "Epoch:304  Batch:9/9  loss:0.079365\n",
      "start train epoch: 305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:305  Batch:1/9  loss:0.073159\n",
      "Epoch:305  Batch:2/9  loss:0.074020\n",
      "Epoch:305  Batch:3/9  loss:0.075516\n",
      "Epoch:305  Batch:4/9  loss:0.069469\n",
      "Epoch:305  Batch:5/9  loss:0.075025\n",
      "Epoch:305  Batch:6/9  loss:0.074067\n",
      "Epoch:305  Batch:7/9  loss:0.067061\n",
      "Epoch:305  Batch:8/9  loss:0.080793\n",
      "Epoch:305  Batch:9/9  loss:0.076714\n",
      "start train epoch: 306\n",
      "Epoch:306  Batch:1/9  loss:0.073631\n",
      "Epoch:306  Batch:2/9  loss:0.063191\n",
      "Epoch:306  Batch:3/9  loss:0.071977\n",
      "Epoch:306  Batch:4/9  loss:0.065569\n",
      "Epoch:306  Batch:5/9  loss:0.071386\n",
      "Epoch:306  Batch:6/9  loss:0.082425\n",
      "Epoch:306  Batch:7/9  loss:0.076181\n",
      "Epoch:306  Batch:8/9  loss:0.079205\n",
      "Epoch:306  Batch:9/9  loss:0.116119\n",
      "start train epoch: 307\n",
      "Epoch:307  Batch:1/9  loss:0.069398\n",
      "Epoch:307  Batch:2/9  loss:0.077683\n",
      "Epoch:307  Batch:3/9  loss:0.090319\n",
      "Epoch:307  Batch:4/9  loss:0.068650\n",
      "Epoch:307  Batch:5/9  loss:0.073178\n",
      "Epoch:307  Batch:6/9  loss:0.078234\n",
      "Epoch:307  Batch:7/9  loss:0.075142\n",
      "Epoch:307  Batch:8/9  loss:0.065739\n",
      "Epoch:307  Batch:9/9  loss:0.076599\n",
      "start train epoch: 308\n",
      "Epoch:308  Batch:1/9  loss:0.074952\n",
      "Epoch:308  Batch:2/9  loss:0.083112\n",
      "Epoch:308  Batch:3/9  loss:0.080086\n",
      "Epoch:308  Batch:4/9  loss:0.067601\n",
      "Epoch:308  Batch:5/9  loss:0.072679\n",
      "Epoch:308  Batch:6/9  loss:0.090268\n",
      "Epoch:308  Batch:7/9  loss:0.062189\n",
      "Epoch:308  Batch:8/9  loss:0.070565\n",
      "Epoch:308  Batch:9/9  loss:0.076711\n",
      "start train epoch: 309\n",
      "Epoch:309  Batch:1/9  loss:0.071138\n",
      "Epoch:309  Batch:2/9  loss:0.078944\n",
      "Epoch:309  Batch:3/9  loss:0.074028\n",
      "Epoch:309  Batch:4/9  loss:0.069625\n",
      "Epoch:309  Batch:5/9  loss:0.076409\n",
      "Epoch:309  Batch:6/9  loss:0.077373\n",
      "Epoch:309  Batch:7/9  loss:0.074150\n",
      "Epoch:309  Batch:8/9  loss:0.066053\n",
      "Epoch:309  Batch:9/9  loss:0.093235\n",
      "start train epoch: 310\n",
      "Epoch:310  Batch:1/9  loss:0.081182\n",
      "Epoch:310  Batch:2/9  loss:0.078861\n",
      "Epoch:310  Batch:3/9  loss:0.073376\n",
      "Epoch:310  Batch:4/9  loss:0.076741\n",
      "Epoch:310  Batch:5/9  loss:0.060980\n",
      "Epoch:310  Batch:6/9  loss:0.069598\n",
      "Epoch:310  Batch:7/9  loss:0.073242\n",
      "Epoch:310  Batch:8/9  loss:0.074570\n",
      "Epoch:310  Batch:9/9  loss:0.070504\n",
      "ACC: 0.9694068\n",
      "TPR: 0.75897837\n",
      "FPR: 0.01262368\n",
      "SN: 0.9873763\n",
      "SP: 0.75897837\n",
      "start train epoch: 311\n",
      "Epoch:311  Batch:1/9  loss:0.086799\n",
      "Epoch:311  Batch:2/9  loss:0.072025\n",
      "Epoch:311  Batch:3/9  loss:0.082661\n",
      "Epoch:311  Batch:4/9  loss:0.062315\n",
      "Epoch:311  Batch:5/9  loss:0.082056\n",
      "Epoch:311  Batch:6/9  loss:0.080139\n",
      "Epoch:311  Batch:7/9  loss:0.069337\n",
      "Epoch:311  Batch:8/9  loss:0.077514\n",
      "Epoch:311  Batch:9/9  loss:0.079795\n",
      "start train epoch: 312\n",
      "Epoch:312  Batch:1/9  loss:0.071268\n",
      "Epoch:312  Batch:2/9  loss:0.075930\n",
      "Epoch:312  Batch:3/9  loss:0.065339\n",
      "Epoch:312  Batch:4/9  loss:0.075261\n",
      "Epoch:312  Batch:5/9  loss:0.076610\n",
      "Epoch:312  Batch:6/9  loss:0.079196\n",
      "Epoch:312  Batch:7/9  loss:0.077059\n",
      "Epoch:312  Batch:8/9  loss:0.071115\n",
      "Epoch:312  Batch:9/9  loss:0.053607\n",
      "start train epoch: 313\n",
      "Epoch:313  Batch:1/9  loss:0.075599\n",
      "Epoch:313  Batch:2/9  loss:0.085208\n",
      "Epoch:313  Batch:3/9  loss:0.062183\n",
      "Epoch:313  Batch:4/9  loss:0.074211\n",
      "Epoch:313  Batch:5/9  loss:0.073141\n",
      "Epoch:313  Batch:6/9  loss:0.081398\n",
      "Epoch:313  Batch:7/9  loss:0.074678\n",
      "Epoch:313  Batch:8/9  loss:0.065505\n",
      "Epoch:313  Batch:9/9  loss:0.080862\n",
      "start train epoch: 314\n",
      "Epoch:314  Batch:1/9  loss:0.083368\n",
      "Epoch:314  Batch:2/9  loss:0.073556\n",
      "Epoch:314  Batch:3/9  loss:0.073786\n",
      "Epoch:314  Batch:4/9  loss:0.069940\n",
      "Epoch:314  Batch:5/9  loss:0.066967\n",
      "Epoch:314  Batch:6/9  loss:0.074345\n",
      "Epoch:314  Batch:7/9  loss:0.077295\n",
      "Epoch:314  Batch:8/9  loss:0.066030\n",
      "Epoch:314  Batch:9/9  loss:0.080644\n",
      "start train epoch: 315\n",
      "Epoch:315  Batch:1/9  loss:0.070862\n",
      "Epoch:315  Batch:2/9  loss:0.078670\n",
      "Epoch:315  Batch:3/9  loss:0.071619\n",
      "Epoch:315  Batch:4/9  loss:0.077340\n",
      "Epoch:315  Batch:5/9  loss:0.067380\n",
      "Epoch:315  Batch:6/9  loss:0.076842\n",
      "Epoch:315  Batch:7/9  loss:0.072963\n",
      "Epoch:315  Batch:8/9  loss:0.077337\n",
      "Epoch:315  Batch:9/9  loss:0.096154\n",
      "start train epoch: 316\n",
      "Epoch:316  Batch:1/9  loss:0.071581\n",
      "Epoch:316  Batch:2/9  loss:0.078156\n",
      "Epoch:316  Batch:3/9  loss:0.067806\n",
      "Epoch:316  Batch:4/9  loss:0.074825\n",
      "Epoch:316  Batch:5/9  loss:0.071244\n",
      "Epoch:316  Batch:6/9  loss:0.071712\n",
      "Epoch:316  Batch:7/9  loss:0.080466\n",
      "Epoch:316  Batch:8/9  loss:0.080666\n",
      "Epoch:316  Batch:9/9  loss:0.084914\n",
      "start train epoch: 317\n",
      "Epoch:317  Batch:1/9  loss:0.082447\n",
      "Epoch:317  Batch:2/9  loss:0.073882\n",
      "Epoch:317  Batch:3/9  loss:0.059826\n",
      "Epoch:317  Batch:4/9  loss:0.086041\n",
      "Epoch:317  Batch:5/9  loss:0.063427\n",
      "Epoch:317  Batch:6/9  loss:0.080190\n",
      "Epoch:317  Batch:7/9  loss:0.078403\n",
      "Epoch:317  Batch:8/9  loss:0.067782\n",
      "Epoch:317  Batch:9/9  loss:0.065668\n",
      "start train epoch: 318\n",
      "Epoch:318  Batch:1/9  loss:0.062545\n",
      "Epoch:318  Batch:2/9  loss:0.072030\n",
      "Epoch:318  Batch:3/9  loss:0.080416\n",
      "Epoch:318  Batch:4/9  loss:0.082261\n",
      "Epoch:318  Batch:5/9  loss:0.070719\n",
      "Epoch:318  Batch:6/9  loss:0.064759\n",
      "Epoch:318  Batch:7/9  loss:0.070374\n",
      "Epoch:318  Batch:8/9  loss:0.073500\n",
      "Epoch:318  Batch:9/9  loss:0.096738\n",
      "start train epoch: 319\n",
      "Epoch:319  Batch:1/9  loss:0.084522\n",
      "Epoch:319  Batch:2/9  loss:0.059604\n",
      "Epoch:319  Batch:3/9  loss:0.073802\n",
      "Epoch:319  Batch:4/9  loss:0.071439\n",
      "Epoch:319  Batch:5/9  loss:0.072696\n",
      "Epoch:319  Batch:6/9  loss:0.070418\n",
      "Epoch:319  Batch:7/9  loss:0.071598\n",
      "Epoch:319  Batch:8/9  loss:0.078989\n",
      "Epoch:319  Batch:9/9  loss:0.073515\n",
      "start train epoch: 320\n",
      "Epoch:320  Batch:1/9  loss:0.073797\n",
      "Epoch:320  Batch:2/9  loss:0.078672\n",
      "Epoch:320  Batch:3/9  loss:0.065738\n",
      "Epoch:320  Batch:4/9  loss:0.074157\n",
      "Epoch:320  Batch:5/9  loss:0.072397\n",
      "Epoch:320  Batch:6/9  loss:0.074844\n",
      "Epoch:320  Batch:7/9  loss:0.068332\n",
      "Epoch:320  Batch:8/9  loss:0.064086\n",
      "Epoch:320  Batch:9/9  loss:0.071140\n",
      "ACC: 0.96950287\n",
      "TPR: 0.774582\n",
      "FPR: 0.013786616\n",
      "SN: 0.9862132\n",
      "SP: 0.774582\n",
      "start train epoch: 321\n",
      "Epoch:321  Batch:1/9  loss:0.068714\n",
      "Epoch:321  Batch:2/9  loss:0.078519\n",
      "Epoch:321  Batch:3/9  loss:0.072228\n",
      "Epoch:321  Batch:4/9  loss:0.084048\n",
      "Epoch:321  Batch:5/9  loss:0.076097\n",
      "Epoch:321  Batch:6/9  loss:0.079849\n",
      "Epoch:321  Batch:7/9  loss:0.063793\n",
      "Epoch:321  Batch:8/9  loss:0.065597\n",
      "Epoch:321  Batch:9/9  loss:0.080119\n",
      "start train epoch: 322\n",
      "Epoch:322  Batch:1/9  loss:0.075928\n",
      "Epoch:322  Batch:2/9  loss:0.082074\n",
      "Epoch:322  Batch:3/9  loss:0.069621\n",
      "Epoch:322  Batch:4/9  loss:0.077969\n",
      "Epoch:322  Batch:5/9  loss:0.073527\n",
      "Epoch:322  Batch:6/9  loss:0.068395\n",
      "Epoch:322  Batch:7/9  loss:0.062142\n",
      "Epoch:322  Batch:8/9  loss:0.077646\n",
      "Epoch:322  Batch:9/9  loss:0.107840\n",
      "start train epoch: 323\n",
      "Epoch:323  Batch:1/9  loss:0.072465\n",
      "Epoch:323  Batch:2/9  loss:0.068151\n",
      "Epoch:323  Batch:3/9  loss:0.069168\n",
      "Epoch:323  Batch:4/9  loss:0.072040\n",
      "Epoch:323  Batch:5/9  loss:0.072487\n",
      "Epoch:323  Batch:6/9  loss:0.077068\n",
      "Epoch:323  Batch:7/9  loss:0.079325\n",
      "Epoch:323  Batch:8/9  loss:0.084565\n",
      "Epoch:323  Batch:9/9  loss:0.078318\n",
      "start train epoch: 324\n",
      "Epoch:324  Batch:1/9  loss:0.068714\n",
      "Epoch:324  Batch:2/9  loss:0.068682\n",
      "Epoch:324  Batch:3/9  loss:0.070627\n",
      "Epoch:324  Batch:4/9  loss:0.079928\n",
      "Epoch:324  Batch:5/9  loss:0.083407\n",
      "Epoch:324  Batch:6/9  loss:0.067876\n",
      "Epoch:324  Batch:7/9  loss:0.068159\n",
      "Epoch:324  Batch:8/9  loss:0.074967\n",
      "Epoch:324  Batch:9/9  loss:0.084938\n",
      "start train epoch: 325\n",
      "Epoch:325  Batch:1/9  loss:0.076063\n",
      "Epoch:325  Batch:2/9  loss:0.068771\n",
      "Epoch:325  Batch:3/9  loss:0.084107\n",
      "Epoch:325  Batch:4/9  loss:0.069561\n",
      "Epoch:325  Batch:5/9  loss:0.066868\n",
      "Epoch:325  Batch:6/9  loss:0.067571\n",
      "Epoch:325  Batch:7/9  loss:0.074880\n",
      "Epoch:325  Batch:8/9  loss:0.074011\n",
      "Epoch:325  Batch:9/9  loss:0.103941\n",
      "start train epoch: 326\n",
      "Epoch:326  Batch:1/9  loss:0.066312\n",
      "Epoch:326  Batch:2/9  loss:0.075493\n",
      "Epoch:326  Batch:3/9  loss:0.077597\n",
      "Epoch:326  Batch:4/9  loss:0.065340\n",
      "Epoch:326  Batch:5/9  loss:0.071052\n",
      "Epoch:326  Batch:6/9  loss:0.075207\n",
      "Epoch:326  Batch:7/9  loss:0.082587\n",
      "Epoch:326  Batch:8/9  loss:0.066184\n",
      "Epoch:326  Batch:9/9  loss:0.089984\n",
      "start train epoch: 327\n",
      "Epoch:327  Batch:1/9  loss:0.068160\n",
      "Epoch:327  Batch:2/9  loss:0.069465\n",
      "Epoch:327  Batch:3/9  loss:0.067016\n",
      "Epoch:327  Batch:4/9  loss:0.072168\n",
      "Epoch:327  Batch:5/9  loss:0.063624\n",
      "Epoch:327  Batch:6/9  loss:0.080735\n",
      "Epoch:327  Batch:7/9  loss:0.080913\n",
      "Epoch:327  Batch:8/9  loss:0.075556\n",
      "Epoch:327  Batch:9/9  loss:0.069432\n",
      "start train epoch: 328\n",
      "Epoch:328  Batch:1/9  loss:0.071602\n",
      "Epoch:328  Batch:2/9  loss:0.065591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:328  Batch:3/9  loss:0.067027\n",
      "Epoch:328  Batch:4/9  loss:0.073541\n",
      "Epoch:328  Batch:5/9  loss:0.073890\n",
      "Epoch:328  Batch:6/9  loss:0.067763\n",
      "Epoch:328  Batch:7/9  loss:0.072054\n",
      "Epoch:328  Batch:8/9  loss:0.079209\n",
      "Epoch:328  Batch:9/9  loss:0.097347\n",
      "start train epoch: 329\n",
      "Epoch:329  Batch:1/9  loss:0.068484\n",
      "Epoch:329  Batch:2/9  loss:0.071459\n",
      "Epoch:329  Batch:3/9  loss:0.075685\n",
      "Epoch:329  Batch:4/9  loss:0.075132\n",
      "Epoch:329  Batch:5/9  loss:0.073702\n",
      "Epoch:329  Batch:6/9  loss:0.077885\n",
      "Epoch:329  Batch:7/9  loss:0.072346\n",
      "Epoch:329  Batch:8/9  loss:0.078048\n",
      "Epoch:329  Batch:9/9  loss:0.075093\n",
      "start train epoch: 330\n",
      "Epoch:330  Batch:1/9  loss:0.074419\n",
      "Epoch:330  Batch:2/9  loss:0.071706\n",
      "Epoch:330  Batch:3/9  loss:0.086665\n",
      "Epoch:330  Batch:4/9  loss:0.076000\n",
      "Epoch:330  Batch:5/9  loss:0.068551\n",
      "Epoch:330  Batch:6/9  loss:0.059006\n",
      "Epoch:330  Batch:7/9  loss:0.078922\n",
      "Epoch:330  Batch:8/9  loss:0.074070\n",
      "Epoch:330  Batch:9/9  loss:0.081717\n",
      "ACC: 0.96926653\n",
      "TPR: 0.75433224\n",
      "FPR: 0.012392014\n",
      "SN: 0.98760796\n",
      "SP: 0.75433224\n",
      "start train epoch: 331\n",
      "Epoch:331  Batch:1/9  loss:0.058230\n",
      "Epoch:331  Batch:2/9  loss:0.063501\n",
      "Epoch:331  Batch:3/9  loss:0.074845\n",
      "Epoch:331  Batch:4/9  loss:0.086667\n",
      "Epoch:331  Batch:5/9  loss:0.082020\n",
      "Epoch:331  Batch:6/9  loss:0.061566\n",
      "Epoch:331  Batch:7/9  loss:0.092545\n",
      "Epoch:331  Batch:8/9  loss:0.069580\n",
      "Epoch:331  Batch:9/9  loss:0.083714\n",
      "start train epoch: 332\n",
      "Epoch:332  Batch:1/9  loss:0.072995\n",
      "Epoch:332  Batch:2/9  loss:0.073770\n",
      "Epoch:332  Batch:3/9  loss:0.081583\n",
      "Epoch:332  Batch:4/9  loss:0.060509\n",
      "Epoch:332  Batch:5/9  loss:0.075708\n",
      "Epoch:332  Batch:6/9  loss:0.071377\n",
      "Epoch:332  Batch:7/9  loss:0.077085\n",
      "Epoch:332  Batch:8/9  loss:0.079400\n",
      "Epoch:332  Batch:9/9  loss:0.101618\n",
      "start train epoch: 333\n",
      "Epoch:333  Batch:1/9  loss:0.078551\n",
      "Epoch:333  Batch:2/9  loss:0.072675\n",
      "Epoch:333  Batch:3/9  loss:0.073688\n",
      "Epoch:333  Batch:4/9  loss:0.074252\n",
      "Epoch:333  Batch:5/9  loss:0.066090\n",
      "Epoch:333  Batch:6/9  loss:0.077903\n",
      "Epoch:333  Batch:7/9  loss:0.073463\n",
      "Epoch:333  Batch:8/9  loss:0.068639\n",
      "Epoch:333  Batch:9/9  loss:0.070608\n",
      "start train epoch: 334\n",
      "Epoch:334  Batch:1/9  loss:0.082969\n",
      "Epoch:334  Batch:2/9  loss:0.069990\n",
      "Epoch:334  Batch:3/9  loss:0.063884\n",
      "Epoch:334  Batch:4/9  loss:0.081461\n",
      "Epoch:334  Batch:5/9  loss:0.066554\n",
      "Epoch:334  Batch:6/9  loss:0.061841\n",
      "Epoch:334  Batch:7/9  loss:0.070594\n",
      "Epoch:334  Batch:8/9  loss:0.073659\n",
      "Epoch:334  Batch:9/9  loss:0.056357\n",
      "start train epoch: 335\n",
      "Epoch:335  Batch:1/9  loss:0.074325\n",
      "Epoch:335  Batch:2/9  loss:0.078760\n",
      "Epoch:335  Batch:3/9  loss:0.075520\n",
      "Epoch:335  Batch:4/9  loss:0.075572\n",
      "Epoch:335  Batch:5/9  loss:0.068460\n",
      "Epoch:335  Batch:6/9  loss:0.068325\n",
      "Epoch:335  Batch:7/9  loss:0.074048\n",
      "Epoch:335  Batch:8/9  loss:0.068201\n",
      "Epoch:335  Batch:9/9  loss:0.120614\n",
      "start train epoch: 336\n",
      "Epoch:336  Batch:1/9  loss:0.068961\n",
      "Epoch:336  Batch:2/9  loss:0.077571\n",
      "Epoch:336  Batch:3/9  loss:0.068824\n",
      "Epoch:336  Batch:4/9  loss:0.075125\n",
      "Epoch:336  Batch:5/9  loss:0.078462\n",
      "Epoch:336  Batch:6/9  loss:0.074299\n",
      "Epoch:336  Batch:7/9  loss:0.065722\n",
      "Epoch:336  Batch:8/9  loss:0.064127\n",
      "Epoch:336  Batch:9/9  loss:0.138612\n",
      "start train epoch: 337\n",
      "Epoch:337  Batch:1/9  loss:0.080140\n",
      "Epoch:337  Batch:2/9  loss:0.078952\n",
      "Epoch:337  Batch:3/9  loss:0.079001\n",
      "Epoch:337  Batch:4/9  loss:0.077569\n",
      "Epoch:337  Batch:5/9  loss:0.071830\n",
      "Epoch:337  Batch:6/9  loss:0.069544\n",
      "Epoch:337  Batch:7/9  loss:0.076314\n",
      "Epoch:337  Batch:8/9  loss:0.071208\n",
      "Epoch:337  Batch:9/9  loss:0.079722\n",
      "start train epoch: 338\n",
      "Epoch:338  Batch:1/9  loss:0.075784\n",
      "Epoch:338  Batch:2/9  loss:0.072732\n",
      "Epoch:338  Batch:3/9  loss:0.066334\n",
      "Epoch:338  Batch:4/9  loss:0.067976\n",
      "Epoch:338  Batch:5/9  loss:0.068671\n",
      "Epoch:338  Batch:6/9  loss:0.073115\n",
      "Epoch:338  Batch:7/9  loss:0.083054\n",
      "Epoch:338  Batch:8/9  loss:0.084928\n",
      "Epoch:338  Batch:9/9  loss:0.071238\n",
      "start train epoch: 339\n",
      "Epoch:339  Batch:1/9  loss:0.076115\n",
      "Epoch:339  Batch:2/9  loss:0.074859\n",
      "Epoch:339  Batch:3/9  loss:0.065374\n",
      "Epoch:339  Batch:4/9  loss:0.063191\n",
      "Epoch:339  Batch:5/9  loss:0.069603\n",
      "Epoch:339  Batch:6/9  loss:0.070568\n",
      "Epoch:339  Batch:7/9  loss:0.074608\n",
      "Epoch:339  Batch:8/9  loss:0.068231\n",
      "Epoch:339  Batch:9/9  loss:0.066388\n",
      "start train epoch: 340\n",
      "Epoch:340  Batch:1/9  loss:0.071617\n",
      "Epoch:340  Batch:2/9  loss:0.071842\n",
      "Epoch:340  Batch:3/9  loss:0.074965\n",
      "Epoch:340  Batch:4/9  loss:0.077538\n",
      "Epoch:340  Batch:5/9  loss:0.075450\n",
      "Epoch:340  Batch:6/9  loss:0.074075\n",
      "Epoch:340  Batch:7/9  loss:0.075802\n",
      "Epoch:340  Batch:8/9  loss:0.062683\n",
      "Epoch:340  Batch:9/9  loss:0.087888\n",
      "ACC: 0.96927786\n",
      "TPR: 0.77903056\n",
      "FPR: 0.014737747\n",
      "SN: 0.98526216\n",
      "SP: 0.77903056\n",
      "start train epoch: 341\n",
      "Epoch:341  Batch:1/9  loss:0.067021\n",
      "Epoch:341  Batch:2/9  loss:0.071596\n",
      "Epoch:341  Batch:3/9  loss:0.079870\n",
      "Epoch:341  Batch:4/9  loss:0.084621\n",
      "Epoch:341  Batch:5/9  loss:0.075602\n",
      "Epoch:341  Batch:6/9  loss:0.068612\n",
      "Epoch:341  Batch:7/9  loss:0.082538\n",
      "Epoch:341  Batch:8/9  loss:0.071498\n",
      "Epoch:341  Batch:9/9  loss:0.045474\n",
      "start train epoch: 342\n",
      "Epoch:342  Batch:1/9  loss:0.079141\n",
      "Epoch:342  Batch:2/9  loss:0.071535\n",
      "Epoch:342  Batch:3/9  loss:0.072510\n",
      "Epoch:342  Batch:4/9  loss:0.070040\n",
      "Epoch:342  Batch:5/9  loss:0.063284\n",
      "Epoch:342  Batch:6/9  loss:0.073416\n",
      "Epoch:342  Batch:7/9  loss:0.091671\n",
      "Epoch:342  Batch:8/9  loss:0.060629\n",
      "Epoch:342  Batch:9/9  loss:0.053341\n",
      "start train epoch: 343\n",
      "Epoch:343  Batch:1/9  loss:0.081014\n",
      "Epoch:343  Batch:2/9  loss:0.075067\n",
      "Epoch:343  Batch:3/9  loss:0.078161\n",
      "Epoch:343  Batch:4/9  loss:0.079179\n",
      "Epoch:343  Batch:5/9  loss:0.069348\n",
      "Epoch:343  Batch:6/9  loss:0.069699\n",
      "Epoch:343  Batch:7/9  loss:0.072445\n",
      "Epoch:343  Batch:8/9  loss:0.071752\n",
      "Epoch:343  Batch:9/9  loss:0.086302\n",
      "start train epoch: 344\n",
      "Epoch:344  Batch:1/9  loss:0.078337\n",
      "Epoch:344  Batch:2/9  loss:0.064504\n",
      "Epoch:344  Batch:3/9  loss:0.068693\n",
      "Epoch:344  Batch:4/9  loss:0.074287\n",
      "Epoch:344  Batch:5/9  loss:0.065585\n",
      "Epoch:344  Batch:6/9  loss:0.085645\n",
      "Epoch:344  Batch:7/9  loss:0.068979\n",
      "Epoch:344  Batch:8/9  loss:0.074704\n",
      "Epoch:344  Batch:9/9  loss:0.088861\n",
      "start train epoch: 345\n",
      "Epoch:345  Batch:1/9  loss:0.066091\n",
      "Epoch:345  Batch:2/9  loss:0.080371\n",
      "Epoch:345  Batch:3/9  loss:0.069283\n",
      "Epoch:345  Batch:4/9  loss:0.071983\n",
      "Epoch:345  Batch:5/9  loss:0.067465\n",
      "Epoch:345  Batch:6/9  loss:0.073116\n",
      "Epoch:345  Batch:7/9  loss:0.072520\n",
      "Epoch:345  Batch:8/9  loss:0.084412\n",
      "Epoch:345  Batch:9/9  loss:0.077439\n",
      "start train epoch: 346\n",
      "Epoch:346  Batch:1/9  loss:0.088768\n",
      "Epoch:346  Batch:2/9  loss:0.074272\n",
      "Epoch:346  Batch:3/9  loss:0.065982\n",
      "Epoch:346  Batch:4/9  loss:0.083902\n",
      "Epoch:346  Batch:5/9  loss:0.075221\n",
      "Epoch:346  Batch:6/9  loss:0.076531\n",
      "Epoch:346  Batch:7/9  loss:0.082197\n",
      "Epoch:346  Batch:8/9  loss:0.075160\n",
      "Epoch:346  Batch:9/9  loss:0.072662\n",
      "start train epoch: 347\n",
      "Epoch:347  Batch:1/9  loss:0.069499\n",
      "Epoch:347  Batch:2/9  loss:0.071857\n",
      "Epoch:347  Batch:3/9  loss:0.080687\n",
      "Epoch:347  Batch:4/9  loss:0.076240\n",
      "Epoch:347  Batch:5/9  loss:0.081716\n",
      "Epoch:347  Batch:6/9  loss:0.074674\n",
      "Epoch:347  Batch:7/9  loss:0.072210\n",
      "Epoch:347  Batch:8/9  loss:0.081432\n",
      "Epoch:347  Batch:9/9  loss:0.073647\n",
      "start train epoch: 348\n",
      "Epoch:348  Batch:1/9  loss:0.081339\n",
      "Epoch:348  Batch:2/9  loss:0.069528\n",
      "Epoch:348  Batch:3/9  loss:0.066626\n",
      "Epoch:348  Batch:4/9  loss:0.073358\n",
      "Epoch:348  Batch:5/9  loss:0.074226\n",
      "Epoch:348  Batch:6/9  loss:0.084303\n",
      "Epoch:348  Batch:7/9  loss:0.077494\n",
      "Epoch:348  Batch:8/9  loss:0.076157\n",
      "Epoch:348  Batch:9/9  loss:0.074076\n",
      "start train epoch: 349\n",
      "Epoch:349  Batch:1/9  loss:0.067106\n",
      "Epoch:349  Batch:2/9  loss:0.064074\n",
      "Epoch:349  Batch:3/9  loss:0.073216\n",
      "Epoch:349  Batch:4/9  loss:0.093486\n",
      "Epoch:349  Batch:5/9  loss:0.070576\n",
      "Epoch:349  Batch:6/9  loss:0.072476\n",
      "Epoch:349  Batch:7/9  loss:0.070905\n",
      "Epoch:349  Batch:8/9  loss:0.071421\n",
      "Epoch:349  Batch:9/9  loss:0.056909\n",
      "start train epoch: 350\n",
      "Epoch:350  Batch:1/9  loss:0.067433\n",
      "Epoch:350  Batch:2/9  loss:0.074693\n",
      "Epoch:350  Batch:3/9  loss:0.063608\n",
      "Epoch:350  Batch:4/9  loss:0.068247\n",
      "Epoch:350  Batch:5/9  loss:0.067251\n",
      "Epoch:350  Batch:6/9  loss:0.076665\n",
      "Epoch:350  Batch:7/9  loss:0.081167\n",
      "Epoch:350  Batch:8/9  loss:0.075838\n",
      "Epoch:350  Batch:9/9  loss:0.144449\n",
      "ACC: 0.969151\n",
      "TPR: 0.77633077\n",
      "FPR: 0.014505161\n",
      "SN: 0.98549485\n",
      "SP: 0.77633077\n",
      "start train epoch: 351\n",
      "Epoch:351  Batch:1/9  loss:0.079431\n",
      "Epoch:351  Batch:2/9  loss:0.082312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:351  Batch:3/9  loss:0.066196\n",
      "Epoch:351  Batch:4/9  loss:0.073167\n",
      "Epoch:351  Batch:5/9  loss:0.070872\n",
      "Epoch:351  Batch:6/9  loss:0.076410\n",
      "Epoch:351  Batch:7/9  loss:0.076850\n",
      "Epoch:351  Batch:8/9  loss:0.066101\n",
      "Epoch:351  Batch:9/9  loss:0.067936\n",
      "start train epoch: 352\n",
      "Epoch:352  Batch:1/9  loss:0.074536\n",
      "Epoch:352  Batch:2/9  loss:0.072975\n",
      "Epoch:352  Batch:3/9  loss:0.076291\n",
      "Epoch:352  Batch:4/9  loss:0.068262\n",
      "Epoch:352  Batch:5/9  loss:0.072842\n",
      "Epoch:352  Batch:6/9  loss:0.069827\n",
      "Epoch:352  Batch:7/9  loss:0.076996\n",
      "Epoch:352  Batch:8/9  loss:0.068932\n",
      "Epoch:352  Batch:9/9  loss:0.114791\n",
      "start train epoch: 353\n",
      "Epoch:353  Batch:1/9  loss:0.068644\n",
      "Epoch:353  Batch:2/9  loss:0.073030\n",
      "Epoch:353  Batch:3/9  loss:0.081193\n",
      "Epoch:353  Batch:4/9  loss:0.081838\n",
      "Epoch:353  Batch:5/9  loss:0.076376\n",
      "Epoch:353  Batch:6/9  loss:0.069170\n",
      "Epoch:353  Batch:7/9  loss:0.065228\n",
      "Epoch:353  Batch:8/9  loss:0.075241\n",
      "Epoch:353  Batch:9/9  loss:0.075822\n",
      "start train epoch: 354\n",
      "Epoch:354  Batch:1/9  loss:0.078223\n",
      "Epoch:354  Batch:2/9  loss:0.071648\n",
      "Epoch:354  Batch:3/9  loss:0.103139\n",
      "Epoch:354  Batch:4/9  loss:0.075230\n",
      "Epoch:354  Batch:5/9  loss:0.065278\n",
      "Epoch:354  Batch:6/9  loss:0.062240\n",
      "Epoch:354  Batch:7/9  loss:0.092203\n",
      "Epoch:354  Batch:8/9  loss:0.072640\n",
      "Epoch:354  Batch:9/9  loss:0.064713\n",
      "start train epoch: 355\n",
      "Epoch:355  Batch:1/9  loss:0.070315\n",
      "Epoch:355  Batch:2/9  loss:0.066761\n",
      "Epoch:355  Batch:3/9  loss:0.076162\n",
      "Epoch:355  Batch:4/9  loss:0.075612\n",
      "Epoch:355  Batch:5/9  loss:0.068844\n",
      "Epoch:355  Batch:6/9  loss:0.084161\n",
      "Epoch:355  Batch:7/9  loss:0.076776\n",
      "Epoch:355  Batch:8/9  loss:0.083246\n",
      "Epoch:355  Batch:9/9  loss:0.079640\n",
      "start train epoch: 356\n",
      "Epoch:356  Batch:1/9  loss:0.069119\n",
      "Epoch:356  Batch:2/9  loss:0.087242\n",
      "Epoch:356  Batch:3/9  loss:0.063925\n",
      "Epoch:356  Batch:4/9  loss:0.072455\n",
      "Epoch:356  Batch:5/9  loss:0.071307\n",
      "Epoch:356  Batch:6/9  loss:0.082502\n",
      "Epoch:356  Batch:7/9  loss:0.078963\n",
      "Epoch:356  Batch:8/9  loss:0.074185\n",
      "Epoch:356  Batch:9/9  loss:0.088132\n",
      "start train epoch: 357\n",
      "Epoch:357  Batch:1/9  loss:0.072917\n",
      "Epoch:357  Batch:2/9  loss:0.085335\n",
      "Epoch:357  Batch:3/9  loss:0.072171\n",
      "Epoch:357  Batch:4/9  loss:0.082961\n",
      "Epoch:357  Batch:5/9  loss:0.079458\n",
      "Epoch:357  Batch:6/9  loss:0.077879\n",
      "Epoch:357  Batch:7/9  loss:0.068331\n",
      "Epoch:357  Batch:8/9  loss:0.072103\n",
      "Epoch:357  Batch:9/9  loss:0.076034\n",
      "start train epoch: 358\n",
      "Epoch:358  Batch:1/9  loss:0.065944\n",
      "Epoch:358  Batch:2/9  loss:0.068703\n",
      "Epoch:358  Batch:3/9  loss:0.062518\n",
      "Epoch:358  Batch:4/9  loss:0.081224\n",
      "Epoch:358  Batch:5/9  loss:0.088088\n",
      "Epoch:358  Batch:6/9  loss:0.078392\n",
      "Epoch:358  Batch:7/9  loss:0.071313\n",
      "Epoch:358  Batch:8/9  loss:0.080232\n",
      "Epoch:358  Batch:9/9  loss:0.109763\n",
      "start train epoch: 359\n",
      "Epoch:359  Batch:1/9  loss:0.072366\n",
      "Epoch:359  Batch:2/9  loss:0.075540\n",
      "Epoch:359  Batch:3/9  loss:0.080434\n",
      "Epoch:359  Batch:4/9  loss:0.071577\n",
      "Epoch:359  Batch:5/9  loss:0.071198\n",
      "Epoch:359  Batch:6/9  loss:0.073869\n",
      "Epoch:359  Batch:7/9  loss:0.073041\n",
      "Epoch:359  Batch:8/9  loss:0.075503\n",
      "Epoch:359  Batch:9/9  loss:0.085228\n",
      "start train epoch: 360\n",
      "Epoch:360  Batch:1/9  loss:0.075151\n",
      "Epoch:360  Batch:2/9  loss:0.095841\n",
      "Epoch:360  Batch:3/9  loss:0.062204\n",
      "Epoch:360  Batch:4/9  loss:0.066087\n",
      "Epoch:360  Batch:5/9  loss:0.069370\n",
      "Epoch:360  Batch:6/9  loss:0.062238\n",
      "Epoch:360  Batch:7/9  loss:0.066967\n",
      "Epoch:360  Batch:8/9  loss:0.077115\n",
      "Epoch:360  Batch:9/9  loss:0.085849\n",
      "ACC: 0.96952593\n",
      "TPR: 0.7751781\n",
      "FPR: 0.01391878\n",
      "SN: 0.9860812\n",
      "SP: 0.7751781\n",
      "start train epoch: 361\n",
      "Epoch:361  Batch:1/9  loss:0.067368\n",
      "Epoch:361  Batch:2/9  loss:0.083836\n",
      "Epoch:361  Batch:3/9  loss:0.072440\n",
      "Epoch:361  Batch:4/9  loss:0.067041\n",
      "Epoch:361  Batch:5/9  loss:0.076941\n",
      "Epoch:361  Batch:6/9  loss:0.078569\n",
      "Epoch:361  Batch:7/9  loss:0.071078\n",
      "Epoch:361  Batch:8/9  loss:0.076386\n",
      "Epoch:361  Batch:9/9  loss:0.050955\n",
      "start train epoch: 362\n",
      "Epoch:362  Batch:1/9  loss:0.082016\n",
      "Epoch:362  Batch:2/9  loss:0.067793\n",
      "Epoch:362  Batch:3/9  loss:0.060567\n",
      "Epoch:362  Batch:4/9  loss:0.072991\n",
      "Epoch:362  Batch:5/9  loss:0.078788\n",
      "Epoch:362  Batch:6/9  loss:0.068958\n",
      "Epoch:362  Batch:7/9  loss:0.072919\n",
      "Epoch:362  Batch:8/9  loss:0.082534\n",
      "Epoch:362  Batch:9/9  loss:0.092749\n",
      "start train epoch: 363\n",
      "Epoch:363  Batch:1/9  loss:0.076898\n",
      "Epoch:363  Batch:2/9  loss:0.069855\n",
      "Epoch:363  Batch:3/9  loss:0.067628\n",
      "Epoch:363  Batch:4/9  loss:0.073603\n",
      "Epoch:363  Batch:5/9  loss:0.079112\n",
      "Epoch:363  Batch:6/9  loss:0.082838\n",
      "Epoch:363  Batch:7/9  loss:0.069121\n",
      "Epoch:363  Batch:8/9  loss:0.065774\n",
      "Epoch:363  Batch:9/9  loss:0.051754\n",
      "start train epoch: 364\n",
      "Epoch:364  Batch:1/9  loss:0.065365\n",
      "Epoch:364  Batch:2/9  loss:0.087580\n",
      "Epoch:364  Batch:3/9  loss:0.082718\n",
      "Epoch:364  Batch:4/9  loss:0.065409\n",
      "Epoch:364  Batch:5/9  loss:0.066670\n",
      "Epoch:364  Batch:6/9  loss:0.075794\n",
      "Epoch:364  Batch:7/9  loss:0.070341\n",
      "Epoch:364  Batch:8/9  loss:0.069471\n",
      "Epoch:364  Batch:9/9  loss:0.053900\n",
      "start train epoch: 365\n",
      "Epoch:365  Batch:1/9  loss:0.072587\n",
      "Epoch:365  Batch:2/9  loss:0.071069\n",
      "Epoch:365  Batch:3/9  loss:0.060762\n",
      "Epoch:365  Batch:4/9  loss:0.069915\n",
      "Epoch:365  Batch:5/9  loss:0.062180\n",
      "Epoch:365  Batch:6/9  loss:0.072780\n",
      "Epoch:365  Batch:7/9  loss:0.072847\n",
      "Epoch:365  Batch:8/9  loss:0.079940\n",
      "Epoch:365  Batch:9/9  loss:0.094098\n",
      "start train epoch: 366\n",
      "Epoch:366  Batch:1/9  loss:0.078341\n",
      "Epoch:366  Batch:2/9  loss:0.076592\n",
      "Epoch:366  Batch:3/9  loss:0.071051\n",
      "Epoch:366  Batch:4/9  loss:0.084589\n",
      "Epoch:366  Batch:5/9  loss:0.068508\n",
      "Epoch:366  Batch:6/9  loss:0.068396\n",
      "Epoch:366  Batch:7/9  loss:0.065920\n",
      "Epoch:366  Batch:8/9  loss:0.071275\n",
      "Epoch:366  Batch:9/9  loss:0.062570\n",
      "start train epoch: 367\n",
      "Epoch:367  Batch:1/9  loss:0.075661\n",
      "Epoch:367  Batch:2/9  loss:0.069693\n",
      "Epoch:367  Batch:3/9  loss:0.078546\n",
      "Epoch:367  Batch:4/9  loss:0.075434\n",
      "Epoch:367  Batch:5/9  loss:0.063946\n",
      "Epoch:367  Batch:6/9  loss:0.067498\n",
      "Epoch:367  Batch:7/9  loss:0.069204\n",
      "Epoch:367  Batch:8/9  loss:0.064370\n",
      "Epoch:367  Batch:9/9  loss:0.048648\n",
      "start train epoch: 368\n",
      "Epoch:368  Batch:1/9  loss:0.074665\n",
      "Epoch:368  Batch:2/9  loss:0.070710\n",
      "Epoch:368  Batch:3/9  loss:0.073822\n",
      "Epoch:368  Batch:4/9  loss:0.067782\n",
      "Epoch:368  Batch:5/9  loss:0.074973\n",
      "Epoch:368  Batch:6/9  loss:0.063326\n",
      "Epoch:368  Batch:7/9  loss:0.069545\n",
      "Epoch:368  Batch:8/9  loss:0.075759\n",
      "Epoch:368  Batch:9/9  loss:0.051929\n",
      "start train epoch: 369\n",
      "Epoch:369  Batch:1/9  loss:0.077264\n",
      "Epoch:369  Batch:2/9  loss:0.076420\n",
      "Epoch:369  Batch:3/9  loss:0.074110\n",
      "Epoch:369  Batch:4/9  loss:0.075899\n",
      "Epoch:369  Batch:5/9  loss:0.071599\n",
      "Epoch:369  Batch:6/9  loss:0.062277\n",
      "Epoch:369  Batch:7/9  loss:0.068012\n",
      "Epoch:369  Batch:8/9  loss:0.067511\n",
      "Epoch:369  Batch:9/9  loss:0.080885\n",
      "start train epoch: 370\n",
      "Epoch:370  Batch:1/9  loss:0.067153\n",
      "Epoch:370  Batch:2/9  loss:0.067931\n",
      "Epoch:370  Batch:3/9  loss:0.075975\n",
      "Epoch:370  Batch:4/9  loss:0.066519\n",
      "Epoch:370  Batch:5/9  loss:0.069036\n",
      "Epoch:370  Batch:6/9  loss:0.068273\n",
      "Epoch:370  Batch:7/9  loss:0.065287\n",
      "Epoch:370  Batch:8/9  loss:0.083240\n",
      "Epoch:370  Batch:9/9  loss:0.088090\n",
      "ACC: 0.9697381\n",
      "TPR: 0.7536491\n",
      "FPR: 0.011799925\n",
      "SN: 0.9882\n",
      "SP: 0.7536491\n",
      "start train epoch: 371\n",
      "Epoch:371  Batch:1/9  loss:0.075846\n",
      "Epoch:371  Batch:2/9  loss:0.067292\n",
      "Epoch:371  Batch:3/9  loss:0.063329\n",
      "Epoch:371  Batch:4/9  loss:0.065631\n",
      "Epoch:371  Batch:5/9  loss:0.071644\n",
      "Epoch:371  Batch:6/9  loss:0.077220\n",
      "Epoch:371  Batch:7/9  loss:0.070141\n",
      "Epoch:371  Batch:8/9  loss:0.072144\n",
      "Epoch:371  Batch:9/9  loss:0.050564\n",
      "start train epoch: 372\n",
      "Epoch:372  Batch:1/9  loss:0.063785\n",
      "Epoch:372  Batch:2/9  loss:0.066422\n",
      "Epoch:372  Batch:3/9  loss:0.068044\n",
      "Epoch:372  Batch:4/9  loss:0.063952\n",
      "Epoch:372  Batch:5/9  loss:0.070130\n",
      "Epoch:372  Batch:6/9  loss:0.074504\n",
      "Epoch:372  Batch:7/9  loss:0.072846\n",
      "Epoch:372  Batch:8/9  loss:0.079073\n",
      "Epoch:372  Batch:9/9  loss:0.089707\n",
      "start train epoch: 373\n",
      "Epoch:373  Batch:1/9  loss:0.068895\n",
      "Epoch:373  Batch:2/9  loss:0.079874\n",
      "Epoch:373  Batch:3/9  loss:0.062702\n",
      "Epoch:373  Batch:4/9  loss:0.074079\n",
      "Epoch:373  Batch:5/9  loss:0.070132\n",
      "Epoch:373  Batch:6/9  loss:0.067703\n",
      "Epoch:373  Batch:7/9  loss:0.075924\n",
      "Epoch:373  Batch:8/9  loss:0.070246\n",
      "Epoch:373  Batch:9/9  loss:0.070608\n",
      "start train epoch: 374\n",
      "Epoch:374  Batch:1/9  loss:0.070694\n",
      "Epoch:374  Batch:2/9  loss:0.064840\n",
      "Epoch:374  Batch:3/9  loss:0.067421\n",
      "Epoch:374  Batch:4/9  loss:0.078604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:374  Batch:5/9  loss:0.075316\n",
      "Epoch:374  Batch:6/9  loss:0.064983\n",
      "Epoch:374  Batch:7/9  loss:0.064971\n",
      "Epoch:374  Batch:8/9  loss:0.080030\n",
      "Epoch:374  Batch:9/9  loss:0.079326\n",
      "start train epoch: 375\n",
      "Epoch:375  Batch:1/9  loss:0.069782\n",
      "Epoch:375  Batch:2/9  loss:0.074124\n",
      "Epoch:375  Batch:3/9  loss:0.068639\n",
      "Epoch:375  Batch:4/9  loss:0.074689\n",
      "Epoch:375  Batch:5/9  loss:0.071870\n",
      "Epoch:375  Batch:6/9  loss:0.062576\n",
      "Epoch:375  Batch:7/9  loss:0.080946\n",
      "Epoch:375  Batch:8/9  loss:0.056183\n",
      "Epoch:375  Batch:9/9  loss:0.067967\n",
      "start train epoch: 376\n",
      "Epoch:376  Batch:1/9  loss:0.062541\n",
      "Epoch:376  Batch:2/9  loss:0.079769\n",
      "Epoch:376  Batch:3/9  loss:0.066127\n",
      "Epoch:376  Batch:4/9  loss:0.079134\n",
      "Epoch:376  Batch:5/9  loss:0.073374\n",
      "Epoch:376  Batch:6/9  loss:0.069945\n",
      "Epoch:376  Batch:7/9  loss:0.074885\n",
      "Epoch:376  Batch:8/9  loss:0.069003\n",
      "Epoch:376  Batch:9/9  loss:0.067445\n",
      "start train epoch: 377\n",
      "Epoch:377  Batch:1/9  loss:0.065108\n",
      "Epoch:377  Batch:2/9  loss:0.077112\n",
      "Epoch:377  Batch:3/9  loss:0.068693\n",
      "Epoch:377  Batch:4/9  loss:0.079234\n",
      "Epoch:377  Batch:5/9  loss:0.071867\n",
      "Epoch:377  Batch:6/9  loss:0.066369\n",
      "Epoch:377  Batch:7/9  loss:0.070670\n",
      "Epoch:377  Batch:8/9  loss:0.069599\n",
      "Epoch:377  Batch:9/9  loss:0.128906\n",
      "start train epoch: 378\n",
      "Epoch:378  Batch:1/9  loss:0.071687\n",
      "Epoch:378  Batch:2/9  loss:0.084255\n",
      "Epoch:378  Batch:3/9  loss:0.077774\n",
      "Epoch:378  Batch:4/9  loss:0.077671\n",
      "Epoch:378  Batch:5/9  loss:0.078980\n",
      "Epoch:378  Batch:6/9  loss:0.071868\n",
      "Epoch:378  Batch:7/9  loss:0.072943\n",
      "Epoch:378  Batch:8/9  loss:0.074797\n",
      "Epoch:378  Batch:9/9  loss:0.056069\n",
      "start train epoch: 379\n",
      "Epoch:379  Batch:1/9  loss:0.068042\n",
      "Epoch:379  Batch:2/9  loss:0.090692\n",
      "Epoch:379  Batch:3/9  loss:0.072044\n",
      "Epoch:379  Batch:4/9  loss:0.082165\n",
      "Epoch:379  Batch:5/9  loss:0.070172\n",
      "Epoch:379  Batch:6/9  loss:0.066231\n",
      "Epoch:379  Batch:7/9  loss:0.077807\n",
      "Epoch:379  Batch:8/9  loss:0.074670\n",
      "Epoch:379  Batch:9/9  loss:0.058893\n",
      "start train epoch: 380\n",
      "Epoch:380  Batch:1/9  loss:0.069454\n",
      "Epoch:380  Batch:2/9  loss:0.071788\n",
      "Epoch:380  Batch:3/9  loss:0.075996\n",
      "Epoch:380  Batch:4/9  loss:0.078622\n",
      "Epoch:380  Batch:5/9  loss:0.081818\n",
      "Epoch:380  Batch:6/9  loss:0.064517\n",
      "Epoch:380  Batch:7/9  loss:0.070845\n",
      "Epoch:380  Batch:8/9  loss:0.079824\n",
      "Epoch:380  Batch:9/9  loss:0.064693\n",
      "ACC: 0.9681951\n",
      "TPR: 0.7555201\n",
      "FPR: 0.013930242\n",
      "SN: 0.98606986\n",
      "SP: 0.7555201\n",
      "start train epoch: 381\n",
      "Epoch:381  Batch:1/9  loss:0.073144\n",
      "Epoch:381  Batch:2/9  loss:0.076705\n",
      "Epoch:381  Batch:3/9  loss:0.075237\n",
      "Epoch:381  Batch:4/9  loss:0.068695\n",
      "Epoch:381  Batch:5/9  loss:0.076540\n",
      "Epoch:381  Batch:6/9  loss:0.072965\n",
      "Epoch:381  Batch:7/9  loss:0.080175\n",
      "Epoch:381  Batch:8/9  loss:0.082541\n",
      "Epoch:381  Batch:9/9  loss:0.074097\n",
      "start train epoch: 382\n",
      "Epoch:382  Batch:1/9  loss:0.070376\n",
      "Epoch:382  Batch:2/9  loss:0.069751\n",
      "Epoch:382  Batch:3/9  loss:0.090510\n",
      "Epoch:382  Batch:4/9  loss:0.067244\n",
      "Epoch:382  Batch:5/9  loss:0.073669\n",
      "Epoch:382  Batch:6/9  loss:0.081295\n",
      "Epoch:382  Batch:7/9  loss:0.075702\n",
      "Epoch:382  Batch:8/9  loss:0.072041\n",
      "Epoch:382  Batch:9/9  loss:0.071924\n",
      "start train epoch: 383\n",
      "Epoch:383  Batch:1/9  loss:0.080339\n",
      "Epoch:383  Batch:2/9  loss:0.068769\n",
      "Epoch:383  Batch:3/9  loss:0.068742\n",
      "Epoch:383  Batch:4/9  loss:0.085327\n",
      "Epoch:383  Batch:5/9  loss:0.064485\n",
      "Epoch:383  Batch:6/9  loss:0.076768\n",
      "Epoch:383  Batch:7/9  loss:0.071391\n",
      "Epoch:383  Batch:8/9  loss:0.077157\n",
      "Epoch:383  Batch:9/9  loss:0.094056\n",
      "start train epoch: 384\n",
      "Epoch:384  Batch:1/9  loss:0.063397\n",
      "Epoch:384  Batch:2/9  loss:0.070916\n",
      "Epoch:384  Batch:3/9  loss:0.072979\n",
      "Epoch:384  Batch:4/9  loss:0.078434\n",
      "Epoch:384  Batch:5/9  loss:0.071157\n",
      "Epoch:384  Batch:6/9  loss:0.076022\n",
      "Epoch:384  Batch:7/9  loss:0.080161\n",
      "Epoch:384  Batch:8/9  loss:0.072254\n",
      "Epoch:384  Batch:9/9  loss:0.078722\n",
      "start train epoch: 385\n",
      "Epoch:385  Batch:1/9  loss:0.072359\n",
      "Epoch:385  Batch:2/9  loss:0.059841\n",
      "Epoch:385  Batch:3/9  loss:0.077277\n",
      "Epoch:385  Batch:4/9  loss:0.069172\n",
      "Epoch:385  Batch:5/9  loss:0.086709\n",
      "Epoch:385  Batch:6/9  loss:0.073048\n",
      "Epoch:385  Batch:7/9  loss:0.072552\n",
      "Epoch:385  Batch:8/9  loss:0.067717\n",
      "Epoch:385  Batch:9/9  loss:0.078907\n",
      "start train epoch: 386\n",
      "Epoch:386  Batch:1/9  loss:0.076879\n",
      "Epoch:386  Batch:2/9  loss:0.067753\n",
      "Epoch:386  Batch:3/9  loss:0.066307\n",
      "Epoch:386  Batch:4/9  loss:0.067310\n",
      "Epoch:386  Batch:5/9  loss:0.071283\n",
      "Epoch:386  Batch:6/9  loss:0.073140\n",
      "Epoch:386  Batch:7/9  loss:0.084100\n",
      "Epoch:386  Batch:8/9  loss:0.070169\n",
      "Epoch:386  Batch:9/9  loss:0.076448\n",
      "start train epoch: 387\n",
      "Epoch:387  Batch:1/9  loss:0.077929\n",
      "Epoch:387  Batch:2/9  loss:0.072063\n",
      "Epoch:387  Batch:3/9  loss:0.080923\n",
      "Epoch:387  Batch:4/9  loss:0.070695\n",
      "Epoch:387  Batch:5/9  loss:0.075616\n",
      "Epoch:387  Batch:6/9  loss:0.067364\n",
      "Epoch:387  Batch:7/9  loss:0.065493\n",
      "Epoch:387  Batch:8/9  loss:0.064187\n",
      "Epoch:387  Batch:9/9  loss:0.077951\n",
      "start train epoch: 388\n",
      "Epoch:388  Batch:1/9  loss:0.070337\n",
      "Epoch:388  Batch:2/9  loss:0.072968\n",
      "Epoch:388  Batch:3/9  loss:0.070610\n",
      "Epoch:388  Batch:4/9  loss:0.075052\n",
      "Epoch:388  Batch:5/9  loss:0.078814\n",
      "Epoch:388  Batch:6/9  loss:0.070061\n",
      "Epoch:388  Batch:7/9  loss:0.073687\n",
      "Epoch:388  Batch:8/9  loss:0.071111\n",
      "Epoch:388  Batch:9/9  loss:0.060923\n",
      "start train epoch: 389\n",
      "Epoch:389  Batch:1/9  loss:0.077338\n",
      "Epoch:389  Batch:2/9  loss:0.075541\n",
      "Epoch:389  Batch:3/9  loss:0.065793\n",
      "Epoch:389  Batch:4/9  loss:0.065164\n",
      "Epoch:389  Batch:5/9  loss:0.068671\n",
      "Epoch:389  Batch:6/9  loss:0.074606\n",
      "Epoch:389  Batch:7/9  loss:0.074483\n",
      "Epoch:389  Batch:8/9  loss:0.071881\n",
      "Epoch:389  Batch:9/9  loss:0.075318\n",
      "start train epoch: 390\n",
      "Epoch:390  Batch:1/9  loss:0.076059\n",
      "Epoch:390  Batch:2/9  loss:0.078328\n",
      "Epoch:390  Batch:3/9  loss:0.072844\n",
      "Epoch:390  Batch:4/9  loss:0.072398\n",
      "Epoch:390  Batch:5/9  loss:0.078142\n",
      "Epoch:390  Batch:6/9  loss:0.057886\n",
      "Epoch:390  Batch:7/9  loss:0.077961\n",
      "Epoch:390  Batch:8/9  loss:0.060898\n",
      "Epoch:390  Batch:9/9  loss:0.067836\n",
      "ACC: 0.9693039\n",
      "TPR: 0.74724245\n",
      "FPR: 0.011894816\n",
      "SN: 0.98810524\n",
      "SP: 0.74724245\n",
      "start train epoch: 391\n",
      "Epoch:391  Batch:1/9  loss:0.079492\n",
      "Epoch:391  Batch:2/9  loss:0.067864\n",
      "Epoch:391  Batch:3/9  loss:0.072727\n",
      "Epoch:391  Batch:4/9  loss:0.080015\n",
      "Epoch:391  Batch:5/9  loss:0.058939\n",
      "Epoch:391  Batch:6/9  loss:0.074760\n",
      "Epoch:391  Batch:7/9  loss:0.078388\n",
      "Epoch:391  Batch:8/9  loss:0.081527\n",
      "Epoch:391  Batch:9/9  loss:0.094211\n",
      "start train epoch: 392\n",
      "Epoch:392  Batch:1/9  loss:0.073747\n",
      "Epoch:392  Batch:2/9  loss:0.080034\n",
      "Epoch:392  Batch:3/9  loss:0.083371\n",
      "Epoch:392  Batch:4/9  loss:0.067906\n",
      "Epoch:392  Batch:5/9  loss:0.080798\n",
      "Epoch:392  Batch:6/9  loss:0.071027\n",
      "Epoch:392  Batch:7/9  loss:0.069058\n",
      "Epoch:392  Batch:8/9  loss:0.063112\n",
      "Epoch:392  Batch:9/9  loss:0.066133\n",
      "start train epoch: 393\n",
      "Epoch:393  Batch:1/9  loss:0.066666\n",
      "Epoch:393  Batch:2/9  loss:0.072683\n",
      "Epoch:393  Batch:3/9  loss:0.074850\n",
      "Epoch:393  Batch:4/9  loss:0.080504\n",
      "Epoch:393  Batch:5/9  loss:0.075248\n",
      "Epoch:393  Batch:6/9  loss:0.068028\n",
      "Epoch:393  Batch:7/9  loss:0.065731\n",
      "Epoch:393  Batch:8/9  loss:0.076454\n",
      "Epoch:393  Batch:9/9  loss:0.070562\n",
      "start train epoch: 394\n",
      "Epoch:394  Batch:1/9  loss:0.072656\n",
      "Epoch:394  Batch:2/9  loss:0.075008\n",
      "Epoch:394  Batch:3/9  loss:0.067490\n",
      "Epoch:394  Batch:4/9  loss:0.083197\n",
      "Epoch:394  Batch:5/9  loss:0.080468\n",
      "Epoch:394  Batch:6/9  loss:0.081933\n",
      "Epoch:394  Batch:7/9  loss:0.066489\n",
      "Epoch:394  Batch:8/9  loss:0.064758\n",
      "Epoch:394  Batch:9/9  loss:0.056289\n",
      "start train epoch: 395\n",
      "Epoch:395  Batch:1/9  loss:0.068454\n",
      "Epoch:395  Batch:2/9  loss:0.080342\n",
      "Epoch:395  Batch:3/9  loss:0.066388\n",
      "Epoch:395  Batch:4/9  loss:0.066018\n",
      "Epoch:395  Batch:5/9  loss:0.090927\n",
      "Epoch:395  Batch:6/9  loss:0.074947\n",
      "Epoch:395  Batch:7/9  loss:0.075464\n",
      "Epoch:395  Batch:8/9  loss:0.074373\n",
      "Epoch:395  Batch:9/9  loss:0.092645\n",
      "start train epoch: 396\n",
      "Epoch:396  Batch:1/9  loss:0.068184\n",
      "Epoch:396  Batch:2/9  loss:0.072915\n",
      "Epoch:396  Batch:3/9  loss:0.078301\n",
      "Epoch:396  Batch:4/9  loss:0.076086\n",
      "Epoch:396  Batch:5/9  loss:0.080346\n",
      "Epoch:396  Batch:6/9  loss:0.074759\n",
      "Epoch:396  Batch:7/9  loss:0.076874\n",
      "Epoch:396  Batch:8/9  loss:0.074403\n",
      "Epoch:396  Batch:9/9  loss:0.111923\n",
      "start train epoch: 397\n",
      "Epoch:397  Batch:1/9  loss:0.066683\n",
      "Epoch:397  Batch:2/9  loss:0.086147\n",
      "Epoch:397  Batch:3/9  loss:0.071290\n",
      "Epoch:397  Batch:4/9  loss:0.069586\n",
      "Epoch:397  Batch:5/9  loss:0.078480\n",
      "Epoch:397  Batch:6/9  loss:0.078484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:397  Batch:7/9  loss:0.075103\n",
      "Epoch:397  Batch:8/9  loss:0.070267\n",
      "Epoch:397  Batch:9/9  loss:0.105285\n",
      "start train epoch: 398\n",
      "Epoch:398  Batch:1/9  loss:0.075960\n",
      "Epoch:398  Batch:2/9  loss:0.071550\n",
      "Epoch:398  Batch:3/9  loss:0.074647\n",
      "Epoch:398  Batch:4/9  loss:0.080258\n",
      "Epoch:398  Batch:5/9  loss:0.073049\n",
      "Epoch:398  Batch:6/9  loss:0.070241\n",
      "Epoch:398  Batch:7/9  loss:0.068988\n",
      "Epoch:398  Batch:8/9  loss:0.077974\n",
      "Epoch:398  Batch:9/9  loss:0.086069\n",
      "start train epoch: 399\n",
      "Epoch:399  Batch:1/9  loss:0.075027\n",
      "Epoch:399  Batch:2/9  loss:0.079083\n",
      "Epoch:399  Batch:3/9  loss:0.063061\n",
      "Epoch:399  Batch:4/9  loss:0.070188\n",
      "Epoch:399  Batch:5/9  loss:0.081093\n",
      "Epoch:399  Batch:6/9  loss:0.074548\n",
      "Epoch:399  Batch:7/9  loss:0.070969\n",
      "Epoch:399  Batch:8/9  loss:0.077128\n",
      "Epoch:399  Batch:9/9  loss:0.097599\n",
      "start train epoch: 400\n",
      "Epoch:400  Batch:1/9  loss:0.065499\n",
      "Epoch:400  Batch:2/9  loss:0.071390\n",
      "Epoch:400  Batch:3/9  loss:0.077844\n",
      "Epoch:400  Batch:4/9  loss:0.079088\n",
      "Epoch:400  Batch:5/9  loss:0.073173\n",
      "Epoch:400  Batch:6/9  loss:0.078497\n",
      "Epoch:400  Batch:7/9  loss:0.070975\n",
      "Epoch:400  Batch:8/9  loss:0.071726\n",
      "Epoch:400  Batch:9/9  loss:0.072568\n",
      "ACC: 0.9692799\n",
      "TPR: 0.7972378\n",
      "FPR: 0.01614182\n",
      "SN: 0.9838581\n",
      "SP: 0.7972378\n",
      "start train epoch: 401\n",
      "Epoch:401  Batch:1/9  loss:0.073594\n",
      "Epoch:401  Batch:2/9  loss:0.083630\n",
      "Epoch:401  Batch:3/9  loss:0.069440\n",
      "Epoch:401  Batch:4/9  loss:0.063047\n",
      "Epoch:401  Batch:5/9  loss:0.068372\n",
      "Epoch:401  Batch:6/9  loss:0.065756\n",
      "Epoch:401  Batch:7/9  loss:0.066180\n",
      "Epoch:401  Batch:8/9  loss:0.068157\n",
      "Epoch:401  Batch:9/9  loss:0.080433\n",
      "start train epoch: 402\n",
      "Epoch:402  Batch:1/9  loss:0.072843\n",
      "Epoch:402  Batch:2/9  loss:0.072133\n",
      "Epoch:402  Batch:3/9  loss:0.064344\n",
      "Epoch:402  Batch:4/9  loss:0.079099\n",
      "Epoch:402  Batch:5/9  loss:0.081187\n",
      "Epoch:402  Batch:6/9  loss:0.078361\n",
      "Epoch:402  Batch:7/9  loss:0.069286\n",
      "Epoch:402  Batch:8/9  loss:0.066207\n",
      "Epoch:402  Batch:9/9  loss:0.097618\n",
      "start train epoch: 403\n",
      "Epoch:403  Batch:1/9  loss:0.075251\n",
      "Epoch:403  Batch:2/9  loss:0.068928\n",
      "Epoch:403  Batch:3/9  loss:0.065598\n",
      "Epoch:403  Batch:4/9  loss:0.066399\n",
      "Epoch:403  Batch:5/9  loss:0.078698\n",
      "Epoch:403  Batch:6/9  loss:0.068233\n",
      "Epoch:403  Batch:7/9  loss:0.061821\n",
      "Epoch:403  Batch:8/9  loss:0.084292\n",
      "Epoch:403  Batch:9/9  loss:0.096567\n",
      "start train epoch: 404\n",
      "Epoch:404  Batch:1/9  loss:0.067172\n",
      "Epoch:404  Batch:2/9  loss:0.087227\n",
      "Epoch:404  Batch:3/9  loss:0.063302\n",
      "Epoch:404  Batch:4/9  loss:0.073486\n",
      "Epoch:404  Batch:5/9  loss:0.078803\n",
      "Epoch:404  Batch:6/9  loss:0.070858\n",
      "Epoch:404  Batch:7/9  loss:0.065486\n",
      "Epoch:404  Batch:8/9  loss:0.071106\n",
      "Epoch:404  Batch:9/9  loss:0.055854\n",
      "start train epoch: 405\n",
      "Epoch:405  Batch:1/9  loss:0.070038\n",
      "Epoch:405  Batch:2/9  loss:0.062944\n",
      "Epoch:405  Batch:3/9  loss:0.071346\n",
      "Epoch:405  Batch:4/9  loss:0.081783\n",
      "Epoch:405  Batch:5/9  loss:0.065063\n",
      "Epoch:405  Batch:6/9  loss:0.068435\n",
      "Epoch:405  Batch:7/9  loss:0.068586\n",
      "Epoch:405  Batch:8/9  loss:0.075922\n",
      "Epoch:405  Batch:9/9  loss:0.069042\n",
      "start train epoch: 406\n",
      "Epoch:406  Batch:1/9  loss:0.074009\n",
      "Epoch:406  Batch:2/9  loss:0.066784\n",
      "Epoch:406  Batch:3/9  loss:0.077360\n",
      "Epoch:406  Batch:4/9  loss:0.070428\n",
      "Epoch:406  Batch:5/9  loss:0.065734\n",
      "Epoch:406  Batch:6/9  loss:0.074751\n",
      "Epoch:406  Batch:7/9  loss:0.074591\n",
      "Epoch:406  Batch:8/9  loss:0.068041\n",
      "Epoch:406  Batch:9/9  loss:0.068249\n",
      "start train epoch: 407\n",
      "Epoch:407  Batch:1/9  loss:0.068140\n",
      "Epoch:407  Batch:2/9  loss:0.067643\n",
      "Epoch:407  Batch:3/9  loss:0.068218\n",
      "Epoch:407  Batch:4/9  loss:0.066583\n",
      "Epoch:407  Batch:5/9  loss:0.063082\n",
      "Epoch:407  Batch:6/9  loss:0.084785\n",
      "Epoch:407  Batch:7/9  loss:0.070670\n",
      "Epoch:407  Batch:8/9  loss:0.073538\n",
      "Epoch:407  Batch:9/9  loss:0.051613\n",
      "start train epoch: 408\n",
      "Epoch:408  Batch:1/9  loss:0.063927\n",
      "Epoch:408  Batch:2/9  loss:0.066774\n",
      "Epoch:408  Batch:3/9  loss:0.083054\n",
      "Epoch:408  Batch:4/9  loss:0.054993\n",
      "Epoch:408  Batch:5/9  loss:0.065967\n",
      "Epoch:408  Batch:6/9  loss:0.073517\n",
      "Epoch:408  Batch:7/9  loss:0.077577\n",
      "Epoch:408  Batch:8/9  loss:0.072521\n",
      "Epoch:408  Batch:9/9  loss:0.111819\n",
      "start train epoch: 409\n",
      "Epoch:409  Batch:1/9  loss:0.071400\n",
      "Epoch:409  Batch:2/9  loss:0.072577\n",
      "Epoch:409  Batch:3/9  loss:0.066961\n",
      "Epoch:409  Batch:4/9  loss:0.076064\n",
      "Epoch:409  Batch:5/9  loss:0.065760\n",
      "Epoch:409  Batch:6/9  loss:0.065515\n",
      "Epoch:409  Batch:7/9  loss:0.068556\n",
      "Epoch:409  Batch:8/9  loss:0.083043\n",
      "Epoch:409  Batch:9/9  loss:0.086577\n",
      "start train epoch: 410\n",
      "Epoch:410  Batch:1/9  loss:0.072119\n",
      "Epoch:410  Batch:2/9  loss:0.078811\n",
      "Epoch:410  Batch:3/9  loss:0.073572\n",
      "Epoch:410  Batch:4/9  loss:0.072957\n",
      "Epoch:410  Batch:5/9  loss:0.074454\n",
      "Epoch:410  Batch:6/9  loss:0.073791\n",
      "Epoch:410  Batch:7/9  loss:0.070517\n",
      "Epoch:410  Batch:8/9  loss:0.067314\n",
      "Epoch:410  Batch:9/9  loss:0.084180\n",
      "ACC: 0.9692829\n",
      "TPR: 0.7809133\n",
      "FPR: 0.014810352\n",
      "SN: 0.9851897\n",
      "SP: 0.7809133\n",
      "start train epoch: 411\n",
      "Epoch:411  Batch:1/9  loss:0.070074\n",
      "Epoch:411  Batch:2/9  loss:0.066972\n",
      "Epoch:411  Batch:3/9  loss:0.075373\n",
      "Epoch:411  Batch:4/9  loss:0.076524\n",
      "Epoch:411  Batch:5/9  loss:0.075415\n",
      "Epoch:411  Batch:6/9  loss:0.066990\n",
      "Epoch:411  Batch:7/9  loss:0.062667\n",
      "Epoch:411  Batch:8/9  loss:0.079490\n",
      "Epoch:411  Batch:9/9  loss:0.092356\n",
      "start train epoch: 412\n",
      "Epoch:412  Batch:1/9  loss:0.070066\n",
      "Epoch:412  Batch:2/9  loss:0.084622\n",
      "Epoch:412  Batch:3/9  loss:0.067592\n",
      "Epoch:412  Batch:4/9  loss:0.074026\n",
      "Epoch:412  Batch:5/9  loss:0.078841\n",
      "Epoch:412  Batch:6/9  loss:0.074922\n",
      "Epoch:412  Batch:7/9  loss:0.064061\n",
      "Epoch:412  Batch:8/9  loss:0.067471\n",
      "Epoch:412  Batch:9/9  loss:0.061289\n",
      "start train epoch: 413\n",
      "Epoch:413  Batch:1/9  loss:0.065723\n",
      "Epoch:413  Batch:2/9  loss:0.080670\n",
      "Epoch:413  Batch:3/9  loss:0.080934\n",
      "Epoch:413  Batch:4/9  loss:0.080673\n",
      "Epoch:413  Batch:5/9  loss:0.065351\n",
      "Epoch:413  Batch:6/9  loss:0.061076\n",
      "Epoch:413  Batch:7/9  loss:0.087248\n",
      "Epoch:413  Batch:8/9  loss:0.070511\n",
      "Epoch:413  Batch:9/9  loss:0.060760\n",
      "start train epoch: 414\n",
      "Epoch:414  Batch:1/9  loss:0.070268\n",
      "Epoch:414  Batch:2/9  loss:0.072977\n",
      "Epoch:414  Batch:3/9  loss:0.066764\n",
      "Epoch:414  Batch:4/9  loss:0.063366\n",
      "Epoch:414  Batch:5/9  loss:0.083075\n",
      "Epoch:414  Batch:6/9  loss:0.071167\n",
      "Epoch:414  Batch:7/9  loss:0.076178\n",
      "Epoch:414  Batch:8/9  loss:0.075190\n",
      "Epoch:414  Batch:9/9  loss:0.072574\n",
      "start train epoch: 415\n",
      "Epoch:415  Batch:1/9  loss:0.076684\n",
      "Epoch:415  Batch:2/9  loss:0.086621\n",
      "Epoch:415  Batch:3/9  loss:0.065544\n",
      "Epoch:415  Batch:4/9  loss:0.064611\n",
      "Epoch:415  Batch:5/9  loss:0.072191\n",
      "Epoch:415  Batch:6/9  loss:0.070552\n",
      "Epoch:415  Batch:7/9  loss:0.079325\n",
      "Epoch:415  Batch:8/9  loss:0.067843\n",
      "Epoch:415  Batch:9/9  loss:0.070978\n",
      "start train epoch: 416\n",
      "Epoch:416  Batch:1/9  loss:0.059872\n",
      "Epoch:416  Batch:2/9  loss:0.084800\n",
      "Epoch:416  Batch:3/9  loss:0.077546\n",
      "Epoch:416  Batch:4/9  loss:0.074725\n",
      "Epoch:416  Batch:5/9  loss:0.069355\n",
      "Epoch:416  Batch:6/9  loss:0.072561\n",
      "Epoch:416  Batch:7/9  loss:0.072625\n",
      "Epoch:416  Batch:8/9  loss:0.067479\n",
      "Epoch:416  Batch:9/9  loss:0.077975\n",
      "start train epoch: 417\n",
      "Epoch:417  Batch:1/9  loss:0.086751\n",
      "Epoch:417  Batch:2/9  loss:0.070186\n",
      "Epoch:417  Batch:3/9  loss:0.070748\n",
      "Epoch:417  Batch:4/9  loss:0.064200\n",
      "Epoch:417  Batch:5/9  loss:0.059986\n",
      "Epoch:417  Batch:6/9  loss:0.067677\n",
      "Epoch:417  Batch:7/9  loss:0.072453\n",
      "Epoch:417  Batch:8/9  loss:0.076999\n",
      "Epoch:417  Batch:9/9  loss:0.071468\n",
      "start train epoch: 418\n",
      "Epoch:418  Batch:1/9  loss:0.070717\n",
      "Epoch:418  Batch:2/9  loss:0.072207\n",
      "Epoch:418  Batch:3/9  loss:0.065698\n",
      "Epoch:418  Batch:4/9  loss:0.069267\n",
      "Epoch:418  Batch:5/9  loss:0.065369\n",
      "Epoch:418  Batch:6/9  loss:0.066403\n",
      "Epoch:418  Batch:7/9  loss:0.079875\n",
      "Epoch:418  Batch:8/9  loss:0.080078\n",
      "Epoch:418  Batch:9/9  loss:0.047229\n",
      "start train epoch: 419\n",
      "Epoch:419  Batch:1/9  loss:0.066128\n",
      "Epoch:419  Batch:2/9  loss:0.066976\n",
      "Epoch:419  Batch:3/9  loss:0.071416\n",
      "Epoch:419  Batch:4/9  loss:0.077300\n",
      "Epoch:419  Batch:5/9  loss:0.072580\n",
      "Epoch:419  Batch:6/9  loss:0.063168\n",
      "Epoch:419  Batch:7/9  loss:0.066846\n",
      "Epoch:419  Batch:8/9  loss:0.066148\n",
      "Epoch:419  Batch:9/9  loss:0.069105\n",
      "start train epoch: 420\n",
      "Epoch:420  Batch:1/9  loss:0.068117\n",
      "Epoch:420  Batch:2/9  loss:0.070227\n",
      "Epoch:420  Batch:3/9  loss:0.077411\n",
      "Epoch:420  Batch:4/9  loss:0.074234\n",
      "Epoch:420  Batch:5/9  loss:0.070398\n",
      "Epoch:420  Batch:6/9  loss:0.057739\n",
      "Epoch:420  Batch:7/9  loss:0.079758\n",
      "Epoch:420  Batch:8/9  loss:0.071195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:420  Batch:9/9  loss:0.052680\n",
      "ACC: 0.96942735\n",
      "TPR: 0.7972061\n",
      "FPR: 0.015924765\n",
      "SN: 0.9840752\n",
      "SP: 0.7972061\n",
      "start train epoch: 421\n",
      "Epoch:421  Batch:1/9  loss:0.075546\n",
      "Epoch:421  Batch:2/9  loss:0.075490\n",
      "Epoch:421  Batch:3/9  loss:0.067894\n",
      "Epoch:421  Batch:4/9  loss:0.079441\n",
      "Epoch:421  Batch:5/9  loss:0.068980\n",
      "Epoch:421  Batch:6/9  loss:0.067298\n",
      "Epoch:421  Batch:7/9  loss:0.065724\n",
      "Epoch:421  Batch:8/9  loss:0.073840\n",
      "Epoch:421  Batch:9/9  loss:0.073656\n",
      "start train epoch: 422\n",
      "Epoch:422  Batch:1/9  loss:0.068442\n",
      "Epoch:422  Batch:2/9  loss:0.068995\n",
      "Epoch:422  Batch:3/9  loss:0.070657\n",
      "Epoch:422  Batch:4/9  loss:0.070434\n",
      "Epoch:422  Batch:5/9  loss:0.071545\n",
      "Epoch:422  Batch:6/9  loss:0.081612\n",
      "Epoch:422  Batch:7/9  loss:0.074112\n",
      "Epoch:422  Batch:8/9  loss:0.074523\n",
      "Epoch:422  Batch:9/9  loss:0.075284\n",
      "start train epoch: 423\n",
      "Epoch:423  Batch:1/9  loss:0.077525\n",
      "Epoch:423  Batch:2/9  loss:0.065246\n",
      "Epoch:423  Batch:3/9  loss:0.071523\n",
      "Epoch:423  Batch:4/9  loss:0.087372\n",
      "Epoch:423  Batch:5/9  loss:0.073255\n",
      "Epoch:423  Batch:6/9  loss:0.074531\n",
      "Epoch:423  Batch:7/9  loss:0.071525\n",
      "Epoch:423  Batch:8/9  loss:0.066384\n",
      "Epoch:423  Batch:9/9  loss:0.105397\n",
      "start train epoch: 424\n",
      "Epoch:424  Batch:1/9  loss:0.066644\n",
      "Epoch:424  Batch:2/9  loss:0.078343\n",
      "Epoch:424  Batch:3/9  loss:0.076149\n",
      "Epoch:424  Batch:4/9  loss:0.065718\n",
      "Epoch:424  Batch:5/9  loss:0.066297\n",
      "Epoch:424  Batch:6/9  loss:0.082435\n",
      "Epoch:424  Batch:7/9  loss:0.069935\n",
      "Epoch:424  Batch:8/9  loss:0.075576\n",
      "Epoch:424  Batch:9/9  loss:0.083208\n",
      "start train epoch: 425\n",
      "Epoch:425  Batch:1/9  loss:0.069229\n",
      "Epoch:425  Batch:2/9  loss:0.068059\n",
      "Epoch:425  Batch:3/9  loss:0.071619\n",
      "Epoch:425  Batch:4/9  loss:0.073316\n",
      "Epoch:425  Batch:5/9  loss:0.084405\n",
      "Epoch:425  Batch:6/9  loss:0.062054\n",
      "Epoch:425  Batch:7/9  loss:0.082039\n",
      "Epoch:425  Batch:8/9  loss:0.068715\n",
      "Epoch:425  Batch:9/9  loss:0.069856\n",
      "start train epoch: 426\n",
      "Epoch:426  Batch:1/9  loss:0.074013\n",
      "Epoch:426  Batch:2/9  loss:0.071257\n",
      "Epoch:426  Batch:3/9  loss:0.075277\n",
      "Epoch:426  Batch:4/9  loss:0.083591\n",
      "Epoch:426  Batch:5/9  loss:0.064690\n",
      "Epoch:426  Batch:6/9  loss:0.075883\n",
      "Epoch:426  Batch:7/9  loss:0.080426\n",
      "Epoch:426  Batch:8/9  loss:0.063168\n",
      "Epoch:426  Batch:9/9  loss:0.114941\n",
      "start train epoch: 427\n",
      "Epoch:427  Batch:1/9  loss:0.078412\n",
      "Epoch:427  Batch:2/9  loss:0.073114\n",
      "Epoch:427  Batch:3/9  loss:0.071510\n",
      "Epoch:427  Batch:4/9  loss:0.070070\n",
      "Epoch:427  Batch:5/9  loss:0.063151\n",
      "Epoch:427  Batch:6/9  loss:0.075098\n",
      "Epoch:427  Batch:7/9  loss:0.064776\n",
      "Epoch:427  Batch:8/9  loss:0.082912\n",
      "Epoch:427  Batch:9/9  loss:0.100415\n",
      "start train epoch: 428\n",
      "Epoch:428  Batch:1/9  loss:0.070897\n",
      "Epoch:428  Batch:2/9  loss:0.073828\n",
      "Epoch:428  Batch:3/9  loss:0.069045\n",
      "Epoch:428  Batch:4/9  loss:0.071132\n",
      "Epoch:428  Batch:5/9  loss:0.070646\n",
      "Epoch:428  Batch:6/9  loss:0.070855\n",
      "Epoch:428  Batch:7/9  loss:0.076294\n",
      "Epoch:428  Batch:8/9  loss:0.076687\n",
      "Epoch:428  Batch:9/9  loss:0.045102\n",
      "start train epoch: 429\n",
      "Epoch:429  Batch:1/9  loss:0.084552\n",
      "Epoch:429  Batch:2/9  loss:0.066974\n",
      "Epoch:429  Batch:3/9  loss:0.071349\n",
      "Epoch:429  Batch:4/9  loss:0.067609\n",
      "Epoch:429  Batch:5/9  loss:0.065800\n",
      "Epoch:429  Batch:6/9  loss:0.064932\n",
      "Epoch:429  Batch:7/9  loss:0.075455\n",
      "Epoch:429  Batch:8/9  loss:0.081169\n",
      "Epoch:429  Batch:9/9  loss:0.131833\n",
      "start train epoch: 430\n",
      "Epoch:430  Batch:1/9  loss:0.068058\n",
      "Epoch:430  Batch:2/9  loss:0.068983\n",
      "Epoch:430  Batch:3/9  loss:0.072048\n",
      "Epoch:430  Batch:4/9  loss:0.068758\n",
      "Epoch:430  Batch:5/9  loss:0.071207\n",
      "Epoch:430  Batch:6/9  loss:0.084878\n",
      "Epoch:430  Batch:7/9  loss:0.071141\n",
      "Epoch:430  Batch:8/9  loss:0.065881\n",
      "Epoch:430  Batch:9/9  loss:0.072663\n",
      "ACC: 0.96955043\n",
      "TPR: 0.77425796\n",
      "FPR: 0.013706082\n",
      "SN: 0.98629415\n",
      "SP: 0.77425796\n",
      "start train epoch: 431\n",
      "Epoch:431  Batch:1/9  loss:0.070849\n",
      "Epoch:431  Batch:2/9  loss:0.072365\n",
      "Epoch:431  Batch:3/9  loss:0.072995\n",
      "Epoch:431  Batch:4/9  loss:0.062026\n",
      "Epoch:431  Batch:5/9  loss:0.079466\n",
      "Epoch:431  Batch:6/9  loss:0.062768\n",
      "Epoch:431  Batch:7/9  loss:0.064283\n",
      "Epoch:431  Batch:8/9  loss:0.080136\n",
      "Epoch:431  Batch:9/9  loss:0.112570\n",
      "start train epoch: 432\n",
      "Epoch:432  Batch:1/9  loss:0.072823\n",
      "Epoch:432  Batch:2/9  loss:0.071039\n",
      "Epoch:432  Batch:3/9  loss:0.084007\n",
      "Epoch:432  Batch:4/9  loss:0.074414\n",
      "Epoch:432  Batch:5/9  loss:0.077859\n",
      "Epoch:432  Batch:6/9  loss:0.070487\n",
      "Epoch:432  Batch:7/9  loss:0.070201\n",
      "Epoch:432  Batch:8/9  loss:0.064813\n",
      "Epoch:432  Batch:9/9  loss:0.068701\n",
      "start train epoch: 433\n",
      "Epoch:433  Batch:1/9  loss:0.080836\n",
      "Epoch:433  Batch:2/9  loss:0.077204\n",
      "Epoch:433  Batch:3/9  loss:0.075004\n",
      "Epoch:433  Batch:4/9  loss:0.068350\n",
      "Epoch:433  Batch:5/9  loss:0.065027\n",
      "Epoch:433  Batch:6/9  loss:0.066753\n",
      "Epoch:433  Batch:7/9  loss:0.083367\n",
      "Epoch:433  Batch:8/9  loss:0.073677\n",
      "Epoch:433  Batch:9/9  loss:0.098572\n",
      "start train epoch: 434\n",
      "Epoch:434  Batch:1/9  loss:0.077487\n",
      "Epoch:434  Batch:2/9  loss:0.071421\n",
      "Epoch:434  Batch:3/9  loss:0.078640\n",
      "Epoch:434  Batch:4/9  loss:0.065368\n",
      "Epoch:434  Batch:5/9  loss:0.068303\n",
      "Epoch:434  Batch:6/9  loss:0.067675\n",
      "Epoch:434  Batch:7/9  loss:0.075899\n",
      "Epoch:434  Batch:8/9  loss:0.064244\n",
      "Epoch:434  Batch:9/9  loss:0.082117\n",
      "start train epoch: 435\n",
      "Epoch:435  Batch:1/9  loss:0.073204\n",
      "Epoch:435  Batch:2/9  loss:0.067593\n",
      "Epoch:435  Batch:3/9  loss:0.064211\n",
      "Epoch:435  Batch:4/9  loss:0.078223\n",
      "Epoch:435  Batch:5/9  loss:0.063239\n",
      "Epoch:435  Batch:6/9  loss:0.076030\n",
      "Epoch:435  Batch:7/9  loss:0.082525\n",
      "Epoch:435  Batch:8/9  loss:0.066197\n",
      "Epoch:435  Batch:9/9  loss:0.052207\n",
      "start train epoch: 436\n",
      "Epoch:436  Batch:1/9  loss:0.065528\n",
      "Epoch:436  Batch:2/9  loss:0.073465\n",
      "Epoch:436  Batch:3/9  loss:0.073728\n",
      "Epoch:436  Batch:4/9  loss:0.067141\n",
      "Epoch:436  Batch:5/9  loss:0.070990\n",
      "Epoch:436  Batch:6/9  loss:0.071300\n",
      "Epoch:436  Batch:7/9  loss:0.071358\n",
      "Epoch:436  Batch:8/9  loss:0.072853\n",
      "Epoch:436  Batch:9/9  loss:0.053463\n",
      "start train epoch: 437\n",
      "Epoch:437  Batch:1/9  loss:0.062693\n",
      "Epoch:437  Batch:2/9  loss:0.069369\n",
      "Epoch:437  Batch:3/9  loss:0.067671\n",
      "Epoch:437  Batch:4/9  loss:0.069413\n",
      "Epoch:437  Batch:5/9  loss:0.063611\n",
      "Epoch:437  Batch:6/9  loss:0.083940\n",
      "Epoch:437  Batch:7/9  loss:0.067364\n",
      "Epoch:437  Batch:8/9  loss:0.074513\n",
      "Epoch:437  Batch:9/9  loss:0.075839\n",
      "start train epoch: 438\n",
      "Epoch:438  Batch:1/9  loss:0.075165\n",
      "Epoch:438  Batch:2/9  loss:0.067195\n",
      "Epoch:438  Batch:3/9  loss:0.079874\n",
      "Epoch:438  Batch:4/9  loss:0.065439\n",
      "Epoch:438  Batch:5/9  loss:0.061481\n",
      "Epoch:438  Batch:6/9  loss:0.063372\n",
      "Epoch:438  Batch:7/9  loss:0.078169\n",
      "Epoch:438  Batch:8/9  loss:0.076917\n",
      "Epoch:438  Batch:9/9  loss:0.075588\n",
      "start train epoch: 439\n",
      "Epoch:439  Batch:1/9  loss:0.070629\n",
      "Epoch:439  Batch:2/9  loss:0.073817\n",
      "Epoch:439  Batch:3/9  loss:0.079979\n",
      "Epoch:439  Batch:4/9  loss:0.070189\n",
      "Epoch:439  Batch:5/9  loss:0.070052\n",
      "Epoch:439  Batch:6/9  loss:0.067964\n",
      "Epoch:439  Batch:7/9  loss:0.074996\n",
      "Epoch:439  Batch:8/9  loss:0.063414\n",
      "Epoch:439  Batch:9/9  loss:0.083168\n",
      "start train epoch: 440\n",
      "Epoch:440  Batch:1/9  loss:0.080980\n",
      "Epoch:440  Batch:2/9  loss:0.060779\n",
      "Epoch:440  Batch:3/9  loss:0.067986\n",
      "Epoch:440  Batch:4/9  loss:0.064901\n",
      "Epoch:440  Batch:5/9  loss:0.073551\n",
      "Epoch:440  Batch:6/9  loss:0.074117\n",
      "Epoch:440  Batch:7/9  loss:0.069760\n",
      "Epoch:440  Batch:8/9  loss:0.072517\n",
      "Epoch:440  Batch:9/9  loss:0.097054\n",
      "ACC: 0.96985716\n",
      "TPR: 0.7488789\n",
      "FPR: 0.011304852\n",
      "SN: 0.98869526\n",
      "SP: 0.7488789\n",
      "start train epoch: 441\n",
      "Epoch:441  Batch:1/9  loss:0.077384\n",
      "Epoch:441  Batch:2/9  loss:0.066632\n",
      "Epoch:441  Batch:3/9  loss:0.082931\n",
      "Epoch:441  Batch:4/9  loss:0.065115\n",
      "Epoch:441  Batch:5/9  loss:0.077170\n",
      "Epoch:441  Batch:6/9  loss:0.068377\n",
      "Epoch:441  Batch:7/9  loss:0.063535\n",
      "Epoch:441  Batch:8/9  loss:0.079308\n",
      "Epoch:441  Batch:9/9  loss:0.048449\n",
      "start train epoch: 442\n",
      "Epoch:442  Batch:1/9  loss:0.067848\n",
      "Epoch:442  Batch:2/9  loss:0.083277\n",
      "Epoch:442  Batch:3/9  loss:0.069433\n",
      "Epoch:442  Batch:4/9  loss:0.066456\n",
      "Epoch:442  Batch:5/9  loss:0.069841\n",
      "Epoch:442  Batch:6/9  loss:0.072304\n",
      "Epoch:442  Batch:7/9  loss:0.069749\n",
      "Epoch:442  Batch:8/9  loss:0.072996\n",
      "Epoch:442  Batch:9/9  loss:0.052288\n",
      "start train epoch: 443\n",
      "Epoch:443  Batch:1/9  loss:0.070004\n",
      "Epoch:443  Batch:2/9  loss:0.073948\n",
      "Epoch:443  Batch:3/9  loss:0.079197\n",
      "Epoch:443  Batch:4/9  loss:0.071333\n",
      "Epoch:443  Batch:5/9  loss:0.058032\n",
      "Epoch:443  Batch:6/9  loss:0.073233\n",
      "Epoch:443  Batch:7/9  loss:0.072163\n",
      "Epoch:443  Batch:8/9  loss:0.074122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:443  Batch:9/9  loss:0.043169\n",
      "start train epoch: 444\n",
      "Epoch:444  Batch:1/9  loss:0.070865\n",
      "Epoch:444  Batch:2/9  loss:0.069525\n",
      "Epoch:444  Batch:3/9  loss:0.068406\n",
      "Epoch:444  Batch:4/9  loss:0.075109\n",
      "Epoch:444  Batch:5/9  loss:0.071010\n",
      "Epoch:444  Batch:6/9  loss:0.078546\n",
      "Epoch:444  Batch:7/9  loss:0.068306\n",
      "Epoch:444  Batch:8/9  loss:0.066991\n",
      "Epoch:444  Batch:9/9  loss:0.072748\n",
      "start train epoch: 445\n",
      "Epoch:445  Batch:1/9  loss:0.058275\n",
      "Epoch:445  Batch:2/9  loss:0.077969\n",
      "Epoch:445  Batch:3/9  loss:0.072695\n",
      "Epoch:445  Batch:4/9  loss:0.070682\n",
      "Epoch:445  Batch:5/9  loss:0.070945\n",
      "Epoch:445  Batch:6/9  loss:0.062766\n",
      "Epoch:445  Batch:7/9  loss:0.075804\n",
      "Epoch:445  Batch:8/9  loss:0.068843\n",
      "Epoch:445  Batch:9/9  loss:0.075454\n",
      "start train epoch: 446\n",
      "Epoch:446  Batch:1/9  loss:0.068887\n",
      "Epoch:446  Batch:2/9  loss:0.064632\n",
      "Epoch:446  Batch:3/9  loss:0.064792\n",
      "Epoch:446  Batch:4/9  loss:0.072081\n",
      "Epoch:446  Batch:5/9  loss:0.083298\n",
      "Epoch:446  Batch:6/9  loss:0.067186\n",
      "Epoch:446  Batch:7/9  loss:0.070218\n",
      "Epoch:446  Batch:8/9  loss:0.062702\n",
      "Epoch:446  Batch:9/9  loss:0.084056\n",
      "start train epoch: 447\n",
      "Epoch:447  Batch:1/9  loss:0.073157\n",
      "Epoch:447  Batch:2/9  loss:0.064527\n",
      "Epoch:447  Batch:3/9  loss:0.069428\n",
      "Epoch:447  Batch:4/9  loss:0.074915\n",
      "Epoch:447  Batch:5/9  loss:0.081159\n",
      "Epoch:447  Batch:6/9  loss:0.077857\n",
      "Epoch:447  Batch:7/9  loss:0.067231\n",
      "Epoch:447  Batch:8/9  loss:0.061461\n",
      "Epoch:447  Batch:9/9  loss:0.070509\n",
      "start train epoch: 448\n",
      "Epoch:448  Batch:1/9  loss:0.076432\n",
      "Epoch:448  Batch:2/9  loss:0.069334\n",
      "Epoch:448  Batch:3/9  loss:0.062323\n",
      "Epoch:448  Batch:4/9  loss:0.066044\n",
      "Epoch:448  Batch:5/9  loss:0.069855\n",
      "Epoch:448  Batch:6/9  loss:0.083487\n",
      "Epoch:448  Batch:7/9  loss:0.070987\n",
      "Epoch:448  Batch:8/9  loss:0.066423\n",
      "Epoch:448  Batch:9/9  loss:0.070736\n",
      "start train epoch: 449\n",
      "Epoch:449  Batch:1/9  loss:0.081194\n",
      "Epoch:449  Batch:2/9  loss:0.075086\n",
      "Epoch:449  Batch:3/9  loss:0.070872\n",
      "Epoch:449  Batch:4/9  loss:0.080751\n",
      "Epoch:449  Batch:5/9  loss:0.071512\n",
      "Epoch:449  Batch:6/9  loss:0.059185\n",
      "Epoch:449  Batch:7/9  loss:0.070877\n",
      "Epoch:449  Batch:8/9  loss:0.063072\n",
      "Epoch:449  Batch:9/9  loss:0.057012\n",
      "start train epoch: 450\n",
      "Epoch:450  Batch:1/9  loss:0.069573\n",
      "Epoch:450  Batch:2/9  loss:0.059140\n",
      "Epoch:450  Batch:3/9  loss:0.065001\n",
      "Epoch:450  Batch:4/9  loss:0.068184\n",
      "Epoch:450  Batch:5/9  loss:0.073575\n",
      "Epoch:450  Batch:6/9  loss:0.068627\n",
      "Epoch:450  Batch:7/9  loss:0.082162\n",
      "Epoch:450  Batch:8/9  loss:0.070232\n",
      "Epoch:450  Batch:9/9  loss:0.076604\n",
      "ACC: 0.9691517\n",
      "TPR: 0.7975405\n",
      "FPR: 0.016298356\n",
      "SN: 0.9837016\n",
      "SP: 0.7975405\n",
      "start train epoch: 451\n",
      "Epoch:451  Batch:1/9  loss:0.061493\n",
      "Epoch:451  Batch:2/9  loss:0.065645\n",
      "Epoch:451  Batch:3/9  loss:0.071625\n",
      "Epoch:451  Batch:4/9  loss:0.067227\n",
      "Epoch:451  Batch:5/9  loss:0.077339\n",
      "Epoch:451  Batch:6/9  loss:0.069862\n",
      "Epoch:451  Batch:7/9  loss:0.087013\n",
      "Epoch:451  Batch:8/9  loss:0.066756\n",
      "Epoch:451  Batch:9/9  loss:0.116359\n",
      "start train epoch: 452\n",
      "Epoch:452  Batch:1/9  loss:0.066268\n",
      "Epoch:452  Batch:2/9  loss:0.067505\n",
      "Epoch:452  Batch:3/9  loss:0.067020\n",
      "Epoch:452  Batch:4/9  loss:0.075106\n",
      "Epoch:452  Batch:5/9  loss:0.066087\n",
      "Epoch:452  Batch:6/9  loss:0.065571\n",
      "Epoch:452  Batch:7/9  loss:0.079322\n",
      "Epoch:452  Batch:8/9  loss:0.069485\n",
      "Epoch:452  Batch:9/9  loss:0.051012\n",
      "start train epoch: 453\n",
      "Epoch:453  Batch:1/9  loss:0.063190\n",
      "Epoch:453  Batch:2/9  loss:0.063523\n",
      "Epoch:453  Batch:3/9  loss:0.073892\n",
      "Epoch:453  Batch:4/9  loss:0.055197\n",
      "Epoch:453  Batch:5/9  loss:0.075040\n",
      "Epoch:453  Batch:6/9  loss:0.067194\n",
      "Epoch:453  Batch:7/9  loss:0.084732\n",
      "Epoch:453  Batch:8/9  loss:0.066242\n",
      "Epoch:453  Batch:9/9  loss:0.147569\n",
      "start train epoch: 454\n",
      "Epoch:454  Batch:1/9  loss:0.057086\n",
      "Epoch:454  Batch:2/9  loss:0.070133\n",
      "Epoch:454  Batch:3/9  loss:0.082220\n",
      "Epoch:454  Batch:4/9  loss:0.082895\n",
      "Epoch:454  Batch:5/9  loss:0.083617\n",
      "Epoch:454  Batch:6/9  loss:0.075631\n",
      "Epoch:454  Batch:7/9  loss:0.072621\n",
      "Epoch:454  Batch:8/9  loss:0.075540\n",
      "Epoch:454  Batch:9/9  loss:0.048343\n",
      "start train epoch: 455\n",
      "Epoch:455  Batch:1/9  loss:0.077164\n",
      "Epoch:455  Batch:2/9  loss:0.066861\n",
      "Epoch:455  Batch:3/9  loss:0.065858\n",
      "Epoch:455  Batch:4/9  loss:0.081972\n",
      "Epoch:455  Batch:5/9  loss:0.074073\n",
      "Epoch:455  Batch:6/9  loss:0.078873\n",
      "Epoch:455  Batch:7/9  loss:0.068729\n",
      "Epoch:455  Batch:8/9  loss:0.069275\n",
      "Epoch:455  Batch:9/9  loss:0.076985\n",
      "start train epoch: 456\n",
      "Epoch:456  Batch:1/9  loss:0.067517\n",
      "Epoch:456  Batch:2/9  loss:0.076121\n",
      "Epoch:456  Batch:3/9  loss:0.071243\n",
      "Epoch:456  Batch:4/9  loss:0.070650\n",
      "Epoch:456  Batch:5/9  loss:0.075063\n",
      "Epoch:456  Batch:6/9  loss:0.070111\n",
      "Epoch:456  Batch:7/9  loss:0.079698\n",
      "Epoch:456  Batch:8/9  loss:0.064787\n",
      "Epoch:456  Batch:9/9  loss:0.070634\n",
      "start train epoch: 457\n",
      "Epoch:457  Batch:1/9  loss:0.067203\n",
      "Epoch:457  Batch:2/9  loss:0.063404\n",
      "Epoch:457  Batch:3/9  loss:0.086037\n",
      "Epoch:457  Batch:4/9  loss:0.070218\n",
      "Epoch:457  Batch:5/9  loss:0.063784\n",
      "Epoch:457  Batch:6/9  loss:0.063981\n",
      "Epoch:457  Batch:7/9  loss:0.074428\n",
      "Epoch:457  Batch:8/9  loss:0.075900\n",
      "Epoch:457  Batch:9/9  loss:0.083024\n",
      "start train epoch: 458\n",
      "Epoch:458  Batch:1/9  loss:0.062080\n",
      "Epoch:458  Batch:2/9  loss:0.070810\n",
      "Epoch:458  Batch:3/9  loss:0.067563\n",
      "Epoch:458  Batch:4/9  loss:0.081464\n",
      "Epoch:458  Batch:5/9  loss:0.066549\n",
      "Epoch:458  Batch:6/9  loss:0.081134\n",
      "Epoch:458  Batch:7/9  loss:0.067053\n",
      "Epoch:458  Batch:8/9  loss:0.066492\n",
      "Epoch:458  Batch:9/9  loss:0.044984\n",
      "start train epoch: 459\n",
      "Epoch:459  Batch:1/9  loss:0.076802\n",
      "Epoch:459  Batch:2/9  loss:0.067127\n",
      "Epoch:459  Batch:3/9  loss:0.064323\n",
      "Epoch:459  Batch:4/9  loss:0.060806\n",
      "Epoch:459  Batch:5/9  loss:0.071820\n",
      "Epoch:459  Batch:6/9  loss:0.082142\n",
      "Epoch:459  Batch:7/9  loss:0.067323\n",
      "Epoch:459  Batch:8/9  loss:0.070989\n",
      "Epoch:459  Batch:9/9  loss:0.081720\n",
      "start train epoch: 460\n",
      "Epoch:460  Batch:1/9  loss:0.068899\n",
      "Epoch:460  Batch:2/9  loss:0.063613\n",
      "Epoch:460  Batch:3/9  loss:0.069533\n",
      "Epoch:460  Batch:4/9  loss:0.067187\n",
      "Epoch:460  Batch:5/9  loss:0.067899\n",
      "Epoch:460  Batch:6/9  loss:0.069507\n",
      "Epoch:460  Batch:7/9  loss:0.071514\n",
      "Epoch:460  Batch:8/9  loss:0.080862\n",
      "Epoch:460  Batch:9/9  loss:0.071923\n",
      "ACC: 0.96974117\n",
      "TPR: 0.77727795\n",
      "FPR: 0.013736397\n",
      "SN: 0.9862635\n",
      "SP: 0.77727795\n",
      "start train epoch: 461\n",
      "Epoch:461  Batch:1/9  loss:0.055813\n",
      "Epoch:461  Batch:2/9  loss:0.065514\n",
      "Epoch:461  Batch:3/9  loss:0.076680\n",
      "Epoch:461  Batch:4/9  loss:0.070218\n",
      "Epoch:461  Batch:5/9  loss:0.082846\n",
      "Epoch:461  Batch:6/9  loss:0.069175\n",
      "Epoch:461  Batch:7/9  loss:0.068252\n",
      "Epoch:461  Batch:8/9  loss:0.079827\n",
      "Epoch:461  Batch:9/9  loss:0.069712\n",
      "start train epoch: 462\n",
      "Epoch:462  Batch:1/9  loss:0.077401\n",
      "Epoch:462  Batch:2/9  loss:0.068710\n",
      "Epoch:462  Batch:3/9  loss:0.067707\n",
      "Epoch:462  Batch:4/9  loss:0.070178\n",
      "Epoch:462  Batch:5/9  loss:0.073023\n",
      "Epoch:462  Batch:6/9  loss:0.062261\n",
      "Epoch:462  Batch:7/9  loss:0.069480\n",
      "Epoch:462  Batch:8/9  loss:0.088592\n",
      "Epoch:462  Batch:9/9  loss:0.068641\n",
      "start train epoch: 463\n",
      "Epoch:463  Batch:1/9  loss:0.067808\n",
      "Epoch:463  Batch:2/9  loss:0.065968\n",
      "Epoch:463  Batch:3/9  loss:0.077189\n",
      "Epoch:463  Batch:4/9  loss:0.066479\n",
      "Epoch:463  Batch:5/9  loss:0.063681\n",
      "Epoch:463  Batch:6/9  loss:0.073978\n",
      "Epoch:463  Batch:7/9  loss:0.080239\n",
      "Epoch:463  Batch:8/9  loss:0.063605\n",
      "Epoch:463  Batch:9/9  loss:0.042638\n",
      "start train epoch: 464\n",
      "Epoch:464  Batch:1/9  loss:0.064348\n",
      "Epoch:464  Batch:2/9  loss:0.068379\n",
      "Epoch:464  Batch:3/9  loss:0.074038\n",
      "Epoch:464  Batch:4/9  loss:0.066904\n",
      "Epoch:464  Batch:5/9  loss:0.062721\n",
      "Epoch:464  Batch:6/9  loss:0.068289\n",
      "Epoch:464  Batch:7/9  loss:0.082522\n",
      "Epoch:464  Batch:8/9  loss:0.063841\n",
      "Epoch:464  Batch:9/9  loss:0.064740\n",
      "start train epoch: 465\n",
      "Epoch:465  Batch:1/9  loss:0.073337\n",
      "Epoch:465  Batch:2/9  loss:0.071254\n",
      "Epoch:465  Batch:3/9  loss:0.062491\n",
      "Epoch:465  Batch:4/9  loss:0.067581\n",
      "Epoch:465  Batch:5/9  loss:0.072454\n",
      "Epoch:465  Batch:6/9  loss:0.060818\n",
      "Epoch:465  Batch:7/9  loss:0.063584\n",
      "Epoch:465  Batch:8/9  loss:0.071396\n",
      "Epoch:465  Batch:9/9  loss:0.092034\n",
      "start train epoch: 466\n",
      "Epoch:466  Batch:1/9  loss:0.062474\n",
      "Epoch:466  Batch:2/9  loss:0.069685\n",
      "Epoch:466  Batch:3/9  loss:0.077640\n",
      "Epoch:466  Batch:4/9  loss:0.077754\n",
      "Epoch:466  Batch:5/9  loss:0.068033\n",
      "Epoch:466  Batch:6/9  loss:0.069068\n",
      "Epoch:466  Batch:7/9  loss:0.070923\n",
      "Epoch:466  Batch:8/9  loss:0.057558\n",
      "Epoch:466  Batch:9/9  loss:0.082826\n",
      "start train epoch: 467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:467  Batch:1/9  loss:0.070876\n",
      "Epoch:467  Batch:2/9  loss:0.071423\n",
      "Epoch:467  Batch:3/9  loss:0.068135\n",
      "Epoch:467  Batch:4/9  loss:0.069077\n",
      "Epoch:467  Batch:5/9  loss:0.069600\n",
      "Epoch:467  Batch:6/9  loss:0.060435\n",
      "Epoch:467  Batch:7/9  loss:0.065078\n",
      "Epoch:467  Batch:8/9  loss:0.066184\n",
      "Epoch:467  Batch:9/9  loss:0.105227\n",
      "start train epoch: 468\n",
      "Epoch:468  Batch:1/9  loss:0.069099\n",
      "Epoch:468  Batch:2/9  loss:0.068288\n",
      "Epoch:468  Batch:3/9  loss:0.066837\n",
      "Epoch:468  Batch:4/9  loss:0.079101\n",
      "Epoch:468  Batch:5/9  loss:0.078706\n",
      "Epoch:468  Batch:6/9  loss:0.064813\n",
      "Epoch:468  Batch:7/9  loss:0.077706\n",
      "Epoch:468  Batch:8/9  loss:0.057089\n",
      "Epoch:468  Batch:9/9  loss:0.078664\n",
      "start train epoch: 469\n",
      "Epoch:469  Batch:1/9  loss:0.080063\n",
      "Epoch:469  Batch:2/9  loss:0.058461\n",
      "Epoch:469  Batch:3/9  loss:0.065864\n",
      "Epoch:469  Batch:4/9  loss:0.066263\n",
      "Epoch:469  Batch:5/9  loss:0.074204\n",
      "Epoch:469  Batch:6/9  loss:0.081455\n",
      "Epoch:469  Batch:7/9  loss:0.062821\n",
      "Epoch:469  Batch:8/9  loss:0.070911\n",
      "Epoch:469  Batch:9/9  loss:0.053377\n",
      "start train epoch: 470\n",
      "Epoch:470  Batch:1/9  loss:0.061253\n",
      "Epoch:470  Batch:2/9  loss:0.080745\n",
      "Epoch:470  Batch:3/9  loss:0.067043\n",
      "Epoch:470  Batch:4/9  loss:0.066543\n",
      "Epoch:470  Batch:5/9  loss:0.063386\n",
      "Epoch:470  Batch:6/9  loss:0.076493\n",
      "Epoch:470  Batch:7/9  loss:0.064422\n",
      "Epoch:470  Batch:8/9  loss:0.074716\n",
      "Epoch:470  Batch:9/9  loss:0.063256\n",
      "ACC: 0.9690933\n",
      "TPR: 0.8022547\n",
      "FPR: 0.016708747\n",
      "SN: 0.98329115\n",
      "SP: 0.8022547\n",
      "start train epoch: 471\n",
      "Epoch:471  Batch:1/9  loss:0.081538\n",
      "Epoch:471  Batch:2/9  loss:0.076681\n",
      "Epoch:471  Batch:3/9  loss:0.068398\n",
      "Epoch:471  Batch:4/9  loss:0.056308\n",
      "Epoch:471  Batch:5/9  loss:0.062183\n",
      "Epoch:471  Batch:6/9  loss:0.061314\n",
      "Epoch:471  Batch:7/9  loss:0.073105\n",
      "Epoch:471  Batch:8/9  loss:0.071315\n",
      "Epoch:471  Batch:9/9  loss:0.089637\n",
      "start train epoch: 472\n",
      "Epoch:472  Batch:1/9  loss:0.072128\n",
      "Epoch:472  Batch:2/9  loss:0.068952\n",
      "Epoch:472  Batch:3/9  loss:0.067849\n",
      "Epoch:472  Batch:4/9  loss:0.085255\n",
      "Epoch:472  Batch:5/9  loss:0.067486\n",
      "Epoch:472  Batch:6/9  loss:0.066950\n",
      "Epoch:472  Batch:7/9  loss:0.066892\n",
      "Epoch:472  Batch:8/9  loss:0.059871\n",
      "Epoch:472  Batch:9/9  loss:0.087422\n",
      "start train epoch: 473\n",
      "Epoch:473  Batch:1/9  loss:0.064161\n",
      "Epoch:473  Batch:2/9  loss:0.068039\n",
      "Epoch:473  Batch:3/9  loss:0.069537\n",
      "Epoch:473  Batch:4/9  loss:0.069256\n",
      "Epoch:473  Batch:5/9  loss:0.072178\n",
      "Epoch:473  Batch:6/9  loss:0.071164\n",
      "Epoch:473  Batch:7/9  loss:0.066420\n",
      "Epoch:473  Batch:8/9  loss:0.079029\n",
      "Epoch:473  Batch:9/9  loss:0.079207\n",
      "start train epoch: 474\n",
      "Epoch:474  Batch:1/9  loss:0.074032\n",
      "Epoch:474  Batch:2/9  loss:0.073547\n",
      "Epoch:474  Batch:3/9  loss:0.067752\n",
      "Epoch:474  Batch:4/9  loss:0.081572\n",
      "Epoch:474  Batch:5/9  loss:0.064493\n",
      "Epoch:474  Batch:6/9  loss:0.070543\n",
      "Epoch:474  Batch:7/9  loss:0.075395\n",
      "Epoch:474  Batch:8/9  loss:0.059085\n",
      "Epoch:474  Batch:9/9  loss:0.079409\n",
      "start train epoch: 475\n",
      "Epoch:475  Batch:1/9  loss:0.080233\n",
      "Epoch:475  Batch:2/9  loss:0.076998\n",
      "Epoch:475  Batch:3/9  loss:0.072034\n",
      "Epoch:475  Batch:4/9  loss:0.060890\n",
      "Epoch:475  Batch:5/9  loss:0.063329\n",
      "Epoch:475  Batch:6/9  loss:0.087120\n",
      "Epoch:475  Batch:7/9  loss:0.071129\n",
      "Epoch:475  Batch:8/9  loss:0.066975\n",
      "Epoch:475  Batch:9/9  loss:0.045612\n",
      "start train epoch: 476\n",
      "Epoch:476  Batch:1/9  loss:0.073306\n",
      "Epoch:476  Batch:2/9  loss:0.065613\n",
      "Epoch:476  Batch:3/9  loss:0.059441\n",
      "Epoch:476  Batch:4/9  loss:0.078433\n",
      "Epoch:476  Batch:5/9  loss:0.071932\n",
      "Epoch:476  Batch:6/9  loss:0.071293\n",
      "Epoch:476  Batch:7/9  loss:0.066056\n",
      "Epoch:476  Batch:8/9  loss:0.067062\n",
      "Epoch:476  Batch:9/9  loss:0.050663\n",
      "start train epoch: 477\n",
      "Epoch:477  Batch:1/9  loss:0.073948\n",
      "Epoch:477  Batch:2/9  loss:0.073966\n",
      "Epoch:477  Batch:3/9  loss:0.069739\n",
      "Epoch:477  Batch:4/9  loss:0.078887\n",
      "Epoch:477  Batch:5/9  loss:0.073588\n",
      "Epoch:477  Batch:6/9  loss:0.065910\n",
      "Epoch:477  Batch:7/9  loss:0.069532\n",
      "Epoch:477  Batch:8/9  loss:0.074407\n",
      "Epoch:477  Batch:9/9  loss:0.043442\n",
      "start train epoch: 478\n",
      "Epoch:478  Batch:1/9  loss:0.068107\n",
      "Epoch:478  Batch:2/9  loss:0.063428\n",
      "Epoch:478  Batch:3/9  loss:0.058613\n",
      "Epoch:478  Batch:4/9  loss:0.071962\n",
      "Epoch:478  Batch:5/9  loss:0.078651\n",
      "Epoch:478  Batch:6/9  loss:0.070470\n",
      "Epoch:478  Batch:7/9  loss:0.073442\n",
      "Epoch:478  Batch:8/9  loss:0.069518\n",
      "Epoch:478  Batch:9/9  loss:0.043745\n",
      "start train epoch: 479\n",
      "Epoch:479  Batch:1/9  loss:0.071549\n",
      "Epoch:479  Batch:2/9  loss:0.080477\n",
      "Epoch:479  Batch:3/9  loss:0.057434\n",
      "Epoch:479  Batch:4/9  loss:0.079490\n",
      "Epoch:479  Batch:5/9  loss:0.072810\n",
      "Epoch:479  Batch:6/9  loss:0.077090\n",
      "Epoch:479  Batch:7/9  loss:0.063552\n",
      "Epoch:479  Batch:8/9  loss:0.062707\n",
      "Epoch:479  Batch:9/9  loss:0.076640\n",
      "start train epoch: 480\n",
      "Epoch:480  Batch:1/9  loss:0.066340\n",
      "Epoch:480  Batch:2/9  loss:0.079352\n",
      "Epoch:480  Batch:3/9  loss:0.062136\n",
      "Epoch:480  Batch:4/9  loss:0.066952\n",
      "Epoch:480  Batch:5/9  loss:0.071691\n",
      "Epoch:480  Batch:6/9  loss:0.054169\n",
      "Epoch:480  Batch:7/9  loss:0.067955\n",
      "Epoch:480  Batch:8/9  loss:0.086273\n",
      "Epoch:480  Batch:9/9  loss:0.095065\n",
      "ACC: 0.96904284\n",
      "TPR: 0.7701371\n",
      "FPR: 0.013986311\n",
      "SN: 0.98601395\n",
      "SP: 0.7701371\n",
      "start train epoch: 481\n",
      "Epoch:481  Batch:1/9  loss:0.073611\n",
      "Epoch:481  Batch:2/9  loss:0.071165\n",
      "Epoch:481  Batch:3/9  loss:0.066910\n",
      "Epoch:481  Batch:4/9  loss:0.072294\n",
      "Epoch:481  Batch:5/9  loss:0.073905\n",
      "Epoch:481  Batch:6/9  loss:0.072361\n",
      "Epoch:481  Batch:7/9  loss:0.065797\n",
      "Epoch:481  Batch:8/9  loss:0.070949\n",
      "Epoch:481  Batch:9/9  loss:0.074884\n",
      "start train epoch: 482\n",
      "Epoch:482  Batch:1/9  loss:0.075304\n",
      "Epoch:482  Batch:2/9  loss:0.063612\n",
      "Epoch:482  Batch:3/9  loss:0.083659\n",
      "Epoch:482  Batch:4/9  loss:0.071346\n",
      "Epoch:482  Batch:5/9  loss:0.067485\n",
      "Epoch:482  Batch:6/9  loss:0.063014\n",
      "Epoch:482  Batch:7/9  loss:0.063663\n",
      "Epoch:482  Batch:8/9  loss:0.076144\n",
      "Epoch:482  Batch:9/9  loss:0.079508\n",
      "start train epoch: 483\n",
      "Epoch:483  Batch:1/9  loss:0.076736\n",
      "Epoch:483  Batch:2/9  loss:0.070451\n",
      "Epoch:483  Batch:3/9  loss:0.064150\n",
      "Epoch:483  Batch:4/9  loss:0.075388\n",
      "Epoch:483  Batch:5/9  loss:0.070433\n",
      "Epoch:483  Batch:6/9  loss:0.060995\n",
      "Epoch:483  Batch:7/9  loss:0.076188\n",
      "Epoch:483  Batch:8/9  loss:0.064896\n",
      "Epoch:483  Batch:9/9  loss:0.074196\n",
      "start train epoch: 484\n",
      "Epoch:484  Batch:1/9  loss:0.070175\n",
      "Epoch:484  Batch:2/9  loss:0.070126\n",
      "Epoch:484  Batch:3/9  loss:0.068236\n",
      "Epoch:484  Batch:4/9  loss:0.063527\n",
      "Epoch:484  Batch:5/9  loss:0.063544\n",
      "Epoch:484  Batch:6/9  loss:0.070406\n",
      "Epoch:484  Batch:7/9  loss:0.075442\n",
      "Epoch:484  Batch:8/9  loss:0.071359\n",
      "Epoch:484  Batch:9/9  loss:0.080487\n",
      "start train epoch: 485\n",
      "Epoch:485  Batch:1/9  loss:0.078011\n",
      "Epoch:485  Batch:2/9  loss:0.068701\n",
      "Epoch:485  Batch:3/9  loss:0.071324\n",
      "Epoch:485  Batch:4/9  loss:0.068327\n",
      "Epoch:485  Batch:5/9  loss:0.065877\n",
      "Epoch:485  Batch:6/9  loss:0.056091\n",
      "Epoch:485  Batch:7/9  loss:0.072866\n",
      "Epoch:485  Batch:8/9  loss:0.071374\n",
      "Epoch:485  Batch:9/9  loss:0.099507\n",
      "start train epoch: 486\n",
      "Epoch:486  Batch:1/9  loss:0.067405\n",
      "Epoch:486  Batch:2/9  loss:0.069273\n",
      "Epoch:486  Batch:3/9  loss:0.071116\n",
      "Epoch:486  Batch:4/9  loss:0.065293\n",
      "Epoch:486  Batch:5/9  loss:0.079520\n",
      "Epoch:486  Batch:6/9  loss:0.072982\n",
      "Epoch:486  Batch:7/9  loss:0.063000\n",
      "Epoch:486  Batch:8/9  loss:0.069934\n",
      "Epoch:486  Batch:9/9  loss:0.138214\n",
      "start train epoch: 487\n",
      "Epoch:487  Batch:1/9  loss:0.068830\n",
      "Epoch:487  Batch:2/9  loss:0.077188\n",
      "Epoch:487  Batch:3/9  loss:0.070944\n",
      "Epoch:487  Batch:4/9  loss:0.066081\n",
      "Epoch:487  Batch:5/9  loss:0.078805\n",
      "Epoch:487  Batch:6/9  loss:0.065141\n",
      "Epoch:487  Batch:7/9  loss:0.070632\n",
      "Epoch:487  Batch:8/9  loss:0.073131\n",
      "Epoch:487  Batch:9/9  loss:0.085667\n",
      "start train epoch: 488\n",
      "Epoch:488  Batch:1/9  loss:0.062263\n",
      "Epoch:488  Batch:2/9  loss:0.072389\n",
      "Epoch:488  Batch:3/9  loss:0.072077\n",
      "Epoch:488  Batch:4/9  loss:0.070284\n",
      "Epoch:488  Batch:5/9  loss:0.074808\n",
      "Epoch:488  Batch:6/9  loss:0.077660\n",
      "Epoch:488  Batch:7/9  loss:0.067856\n",
      "Epoch:488  Batch:8/9  loss:0.077633\n",
      "Epoch:488  Batch:9/9  loss:0.047231\n",
      "start train epoch: 489\n",
      "Epoch:489  Batch:1/9  loss:0.065373\n",
      "Epoch:489  Batch:2/9  loss:0.072716\n",
      "Epoch:489  Batch:3/9  loss:0.084656\n",
      "Epoch:489  Batch:4/9  loss:0.067105\n",
      "Epoch:489  Batch:5/9  loss:0.070242\n",
      "Epoch:489  Batch:6/9  loss:0.066228\n",
      "Epoch:489  Batch:7/9  loss:0.080603\n",
      "Epoch:489  Batch:8/9  loss:0.063811\n",
      "Epoch:489  Batch:9/9  loss:0.041372\n",
      "start train epoch: 490\n",
      "Epoch:490  Batch:1/9  loss:0.072328\n",
      "Epoch:490  Batch:2/9  loss:0.069961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:490  Batch:3/9  loss:0.073920\n",
      "Epoch:490  Batch:4/9  loss:0.058654\n",
      "Epoch:490  Batch:5/9  loss:0.070058\n",
      "Epoch:490  Batch:6/9  loss:0.080595\n",
      "Epoch:490  Batch:7/9  loss:0.070531\n",
      "Epoch:490  Batch:8/9  loss:0.064810\n",
      "Epoch:490  Batch:9/9  loss:0.046427\n",
      "ACC: 0.96968627\n",
      "TPR: 0.7652383\n",
      "FPR: 0.012752902\n",
      "SN: 0.987247\n",
      "SP: 0.7652383\n",
      "start train epoch: 491\n",
      "Epoch:491  Batch:1/9  loss:0.063741\n",
      "Epoch:491  Batch:2/9  loss:0.072802\n",
      "Epoch:491  Batch:3/9  loss:0.068836\n",
      "Epoch:491  Batch:4/9  loss:0.072589\n",
      "Epoch:491  Batch:5/9  loss:0.070749\n",
      "Epoch:491  Batch:6/9  loss:0.063525\n",
      "Epoch:491  Batch:7/9  loss:0.069849\n",
      "Epoch:491  Batch:8/9  loss:0.066524\n",
      "Epoch:491  Batch:9/9  loss:0.068929\n",
      "start train epoch: 492\n",
      "Epoch:492  Batch:1/9  loss:0.072890\n",
      "Epoch:492  Batch:2/9  loss:0.056590\n",
      "Epoch:492  Batch:3/9  loss:0.071223\n",
      "Epoch:492  Batch:4/9  loss:0.076582\n",
      "Epoch:492  Batch:5/9  loss:0.070251\n",
      "Epoch:492  Batch:6/9  loss:0.064702\n",
      "Epoch:492  Batch:7/9  loss:0.062743\n",
      "Epoch:492  Batch:8/9  loss:0.078666\n",
      "Epoch:492  Batch:9/9  loss:0.064539\n",
      "start train epoch: 493\n",
      "Epoch:493  Batch:1/9  loss:0.066237\n",
      "Epoch:493  Batch:2/9  loss:0.072546\n",
      "Epoch:493  Batch:3/9  loss:0.069845\n",
      "Epoch:493  Batch:4/9  loss:0.064767\n",
      "Epoch:493  Batch:5/9  loss:0.064637\n",
      "Epoch:493  Batch:6/9  loss:0.071888\n",
      "Epoch:493  Batch:7/9  loss:0.066888\n",
      "Epoch:493  Batch:8/9  loss:0.072710\n",
      "Epoch:493  Batch:9/9  loss:0.043148\n",
      "start train epoch: 494\n",
      "Epoch:494  Batch:1/9  loss:0.074091\n",
      "Epoch:494  Batch:2/9  loss:0.068852\n",
      "Epoch:494  Batch:3/9  loss:0.080538\n",
      "Epoch:494  Batch:4/9  loss:0.070149\n",
      "Epoch:494  Batch:5/9  loss:0.061685\n",
      "Epoch:494  Batch:6/9  loss:0.061045\n",
      "Epoch:494  Batch:7/9  loss:0.069000\n",
      "Epoch:494  Batch:8/9  loss:0.066872\n",
      "Epoch:494  Batch:9/9  loss:0.058667\n",
      "start train epoch: 495\n",
      "Epoch:495  Batch:1/9  loss:0.077250\n",
      "Epoch:495  Batch:2/9  loss:0.061049\n",
      "Epoch:495  Batch:3/9  loss:0.075390\n",
      "Epoch:495  Batch:4/9  loss:0.065709\n",
      "Epoch:495  Batch:5/9  loss:0.071143\n",
      "Epoch:495  Batch:6/9  loss:0.054181\n",
      "Epoch:495  Batch:7/9  loss:0.063569\n",
      "Epoch:495  Batch:8/9  loss:0.073447\n",
      "Epoch:495  Batch:9/9  loss:0.076788\n",
      "start train epoch: 496\n",
      "Epoch:496  Batch:1/9  loss:0.068256\n",
      "Epoch:496  Batch:2/9  loss:0.058128\n",
      "Epoch:496  Batch:3/9  loss:0.069717\n",
      "Epoch:496  Batch:4/9  loss:0.065664\n",
      "Epoch:496  Batch:5/9  loss:0.068870\n",
      "Epoch:496  Batch:6/9  loss:0.079552\n",
      "Epoch:496  Batch:7/9  loss:0.074831\n",
      "Epoch:496  Batch:8/9  loss:0.066015\n",
      "Epoch:496  Batch:9/9  loss:0.154780\n",
      "start train epoch: 497\n",
      "Epoch:497  Batch:1/9  loss:0.064543\n",
      "Epoch:497  Batch:2/9  loss:0.057835\n",
      "Epoch:497  Batch:3/9  loss:0.068433\n",
      "Epoch:497  Batch:4/9  loss:0.075235\n",
      "Epoch:497  Batch:5/9  loss:0.066907\n",
      "Epoch:497  Batch:6/9  loss:0.068188\n",
      "Epoch:497  Batch:7/9  loss:0.067765\n",
      "Epoch:497  Batch:8/9  loss:0.075855\n",
      "Epoch:497  Batch:9/9  loss:0.101443\n",
      "start train epoch: 498\n",
      "Epoch:498  Batch:1/9  loss:0.066142\n",
      "Epoch:498  Batch:2/9  loss:0.070799\n",
      "Epoch:498  Batch:3/9  loss:0.072904\n",
      "Epoch:498  Batch:4/9  loss:0.069071\n",
      "Epoch:498  Batch:5/9  loss:0.080206\n",
      "Epoch:498  Batch:6/9  loss:0.067564\n",
      "Epoch:498  Batch:7/9  loss:0.067924\n",
      "Epoch:498  Batch:8/9  loss:0.071454\n",
      "Epoch:498  Batch:9/9  loss:0.061099\n",
      "start train epoch: 499\n",
      "Epoch:499  Batch:1/9  loss:0.074071\n",
      "Epoch:499  Batch:2/9  loss:0.072000\n",
      "Epoch:499  Batch:3/9  loss:0.060812\n",
      "Epoch:499  Batch:4/9  loss:0.076547\n",
      "Epoch:499  Batch:5/9  loss:0.062923\n",
      "Epoch:499  Batch:6/9  loss:0.074582\n",
      "Epoch:499  Batch:7/9  loss:0.062477\n",
      "Epoch:499  Batch:8/9  loss:0.064976\n",
      "Epoch:499  Batch:9/9  loss:0.043273\n",
      "start train epoch: 500\n",
      "Epoch:500  Batch:1/9  loss:0.070847\n",
      "Epoch:500  Batch:2/9  loss:0.067105\n",
      "Epoch:500  Batch:3/9  loss:0.082226\n",
      "Epoch:500  Batch:4/9  loss:0.070195\n",
      "Epoch:500  Batch:5/9  loss:0.062360\n",
      "Epoch:500  Batch:6/9  loss:0.060449\n",
      "Epoch:500  Batch:7/9  loss:0.069539\n",
      "Epoch:500  Batch:8/9  loss:0.073827\n",
      "Epoch:500  Batch:9/9  loss:0.074612\n",
      "ACC: 0.9700912\n",
      "TPR: 0.7770713\n",
      "FPR: 0.0134572815\n",
      "SN: 0.9865425\n",
      "SP: 0.7770713\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "loss_plot = [0]\n",
    "for e in range(1, epochs + 1):\n",
    "    loss_plot = loss_plot + train(e)\n",
    "    if e % 10 == 0:\n",
    "        acc = test()\n",
    "        if acc > best_acc:\n",
    "            if best_acc != 0:\n",
    "                os.remove(os.path.join(weights_path,\n",
    "                         'net_%s_%s_%s_%f.pth'%(dataset,loss_fuc,net_name,best_acc)))\n",
    "            torch.save(net.state_dict(),os.path.join(weights_path,\n",
    "                         'net_%s_%s_%s_%f.pth'%(dataset,loss_fuc,net_name,acc)))  \n",
    "            best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22dd1f4e518>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_plot[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_plot():\n",
    "    net.eval()\n",
    "    res = []\n",
    "    for i, (x,y) in enumerate(testloader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.cuda(async=True)\n",
    "        y = y.cuda(async=True)\n",
    "        x = net(x)\n",
    "        \n",
    "        x = torch.sigmoid(x).squeeze()\n",
    "        y = y.squeeze().int().long().cpu().detach().numpy()\n",
    "        \n",
    "        x = torch.where(x > 0.5, torch.tensor(1).cuda(), torch.tensor(0).cuda()).cpu().detach().numpy()\n",
    "        \n",
    "        acc = np.sum(np.where(x == y,1,0)) / np.sum(np.where(x == x,1,0))\n",
    "        res.append(acc)\n",
    "        im = cv2.merge([x*255,y*255,y*255])\n",
    "        plt.imsave(os.path.join(image_path,(str(i)+'_'+'%4f'%acc+'.png')),im.astype('uint8'), format=\"png\")\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = os.path.join(weights_path,\n",
    "                         'net_%s_%s_%s_%f.pth'%(dataset,loss_fuc,net_name,best_acc))\n",
    "pre_params = torch.load(resume)\n",
    "net.load_state_dict(pre_params)\n",
    "res = test_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9670842013888888\n",
      "0.9737951388888888\n",
      "0.9749584573412698\n",
      "0.9682054759837962\n"
     ]
    }
   ],
   "source": [
    "res = np.array(res)\n",
    "print(np.mean(res[0:20])) # DRIVE\n",
    "print(np.mean(res[20:30])) # STARE\n",
    "print(np.mean(res[30:44])) # CHASEDB1\n",
    "print(np.mean(res[44:68])) # HRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.970046\n",
      "TPR: 0.77560943\n",
      "FPR: 0.013365276\n",
      "SN: 0.98663455\n",
      "SP: 0.77560943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(0.970046, dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pt] *",
   "language": "python",
   "name": "conda-env-pt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
